<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><front><journal-meta><journal-id journal-id-type="nlm-ta">Iperception</journal-id><journal-id journal-id-type="iso-abbrev">Iperception</journal-id><journal-id journal-id-type="publisher-id">IPE</journal-id><journal-id journal-id-type="hwp">spipe</journal-id><journal-title-group><journal-title>i-Perception</journal-title></journal-title-group><issn pub-type="epub">2041-6695</issn><publisher><publisher-name>SAGE Publications</publisher-name><publisher-loc>Sage UK: London, England</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29774139</article-id><article-id pub-id-type="pmc">5950935</article-id><article-id pub-id-type="doi">10.1177/2041669518755806</article-id><article-id pub-id-type="publisher-id">10.1177_2041669518755806</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Line-Drawn Scenes Provide Sufficient Information for Discrimination of Threat and Mere Negativity</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Boshyan</surname><given-names>Jasmine</given-names></name><xref ref-type="corresp" rid="corresp1-2041669518755806"></xref></contrib><aff id="aff1-2041669518755806">Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA, USA; Department of Radiology, Harvard Medical School, Boston, MA, USA</aff></contrib-group><contrib-group><contrib contrib-type="author"><name><surname>Feldman Barrett</surname><given-names>Lisa</given-names></name></contrib><aff id="aff2-2041669518755806">Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA, USA; Department of Psychology, Northeastern University, Boston, MA, USA; Department of Psychiatry, Massachusetts General Hospital, Charlestown, MA, USA</aff></contrib-group><contrib-group><contrib contrib-type="author"><name><surname>Betz</surname><given-names>Nicole</given-names></name></contrib><aff id="aff3-2041669518755806">Department of Psychology, Northeastern University, Boston, MA, USA</aff></contrib-group><contrib-group><contrib contrib-type="author"><name><surname>Adams</surname><given-names>Reginald B.</given-names><suffix>Jr.</suffix></name></contrib><aff id="aff4-2041669518755806">Department of Psychology, The <institution-wrap><institution-id institution-id-type="Ringgold">8082</institution-id><institution content-type="university">Pennsylvania State University</institution></institution-wrap>, University Park, PA, USA</aff></contrib-group><contrib-group><contrib contrib-type="author"><name><surname>Kveraga</surname><given-names>Kestutis</given-names></name></contrib><aff id="aff5-2041669518755806">Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA, USA; Department of Radiology, Harvard Medical School, Boston, MA, USA</aff></contrib-group><author-notes><corresp id="corresp1-2041669518755806">Jasmine Boshyan, Department of Radiology, Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Charlestown, MA 02129, USA. Email: <email>jboshyan@gmail.com</email></corresp></author-notes><pub-date pub-type="epub"><day>12</day><month>2</month><year>2018</year></pub-date><pub-date pub-type="collection"><season>Jan-Feb</season><year>2018</year></pub-date><volume>9</volume><issue>1</issue><elocation-id>2041669518755806</elocation-id><history><date date-type="received"><day>5</day><month>10</month><year>2017</year></date><date date-type="accepted"><day>2</day><month>1</month><year>2018</year></date></history><permissions><copyright-statement>© The Author(s) 2018</copyright-statement><copyright-year>2018</copyright-year><copyright-holder content-type="society">SAGE Publications Ltd. Manuscript content on this site is licensed under Creative Commons Licenses</copyright-holder><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>Creative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 4.0 License (<ext-link ext-link-type="uri" xlink:href="http://www.creativecommons.org/licenses/by/4.0/">http://www.creativecommons.org/licenses/by/4.0/</ext-link>) which permits any use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (<ext-link ext-link-type="uri" xlink:href="https://us.sagepub.com/en-us/nam/open-access-at-sage">https://us.sagepub.com/en-us/nam/open-access-at-sage</ext-link>).</license-p></license></permissions><abstract><p><offsets xml_i="4832" xml_f="6098" txt_i="11" txt_f="1277">Previous work using color photographic scenes has shown that human observers are keenly sensitive to different types of threatening and negative stimuli and reliably classify them by the presence, and spatial and temporal directions of threat. To test whether such distinctions can be extracted from impoverished visual information, we used 500 line drawings made by hand-tracing the original set of photographic scenes. Sixty participants rated the scenes on spatial and temporal dimensions of threat. Based on these ratings, trend analysis revealed five scene categories that were comparable to those identified for the matching color photographic scenes. Another 61 participants were randomly assigned to rate the valence or arousal evoked by the line drawings. The line drawings perceived to be the most negative were also perceived to be the most arousing, replicating the finding for color photographic scenes. We demonstrate here that humans are very sensitive to the spatial and temporal directions of threat even when they must extract this information from simple line drawings, and rate the line drawings very similarly to matched color photographs. The set of 500 hand-traced line-drawing scenes has been made freely available to the research community: </offsets><ext-link ext-link-type="uri" xlink:href="http://www.kveragalab.org/threat.html"><offsets xml_i="6179" xml_f="6216" txt_i="1277" txt_f="1314">http://www.kveragalab.org/threat.html</offsets></ext-link><offsets xml_i="6227" xml_f="6228" txt_i="1314" txt_f="1315">.</offsets></p></abstract><kwd-group><kwd>threat perception</kwd><kwd>line drawings</kwd><kwd>affect</kwd><kwd>emotion</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>January-February 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-2041669518755806"><title><offsets xml_i="6583" xml_f="6595" txt_i="1323" txt_f="1335">Introduction</offsets></title><p><offsets xml_i="6606" xml_f="6835" txt_i="1336" txt_f="1565">Our visual system has been honed by the need for survival. From a continuous flood of visual information, our eyes and brain quickly extract meaning and scan for signs of danger, as rapid recognition of threat promotes survival (</offsets><xref rid="bibr36-2041669518755806" ref-type="bibr"><offsets xml_i="6887" xml_f="6899" txt_i="1565" txt_f="1577">LeDoux, 2012</offsets></xref><offsets xml_i="6906" xml_f="7017" txt_i="1577" txt_f="1688">). Previous studies have shown that stimuli are automatically represented in terms of their affective valence (</offsets><xref rid="bibr2-2041669518755806" ref-type="bibr"><offsets xml_i="7068" xml_f="7081" txt_i="1688" txt_f="1701">Barrett, 2006</offsets></xref><offsets xml_i="7088" xml_f="7090" txt_i="1701" txt_f="1703">; </offsets><xref rid="bibr16-2041669518755806" ref-type="bibr"><offsets xml_i="7142" xml_f="7187" txt_i="1703" txt_f="1744">Duckworth, Bargh, Garcia, &amp; Chaiken, 2002</offsets></xref><offsets xml_i="7194" xml_f="7426" txt_i="1744" txt_f="1976">). But dimensional approaches to affective perception that map the valence and arousal of stimuli do not distinguish between unpleasant images that are perceived as aversive and threatening and those that are not (for a review, see </offsets><xref rid="bibr3-2041669518755806" ref-type="bibr"><offsets xml_i="7477" xml_f="7509" txt_i="1976" txt_f="2004">Barrett &amp; Bliss-Moreau, 2009</offsets></xref><offsets xml_i="7516" xml_f="7518" txt_i="2004" txt_f="2006">; </offsets><xref rid="bibr4-2041669518755806" ref-type="bibr"><offsets xml_i="7569" xml_f="7596" txt_i="2006" txt_f="2029">Barrett &amp; Russell, 1999</offsets></xref><offsets xml_i="7603" xml_f="7605" txt_i="2029" txt_f="2031">; </offsets><xref rid="bibr32-2041669518755806" ref-type="bibr"><offsets xml_i="7657" xml_f="7682" txt_i="2031" txt_f="2052">Larsen &amp; Diener, 1992</offsets></xref><offsets xml_i="7689" xml_f="7691" txt_i="2052" txt_f="2054">; </offsets><xref rid="bibr56-2041669518755806" ref-type="bibr"><offsets xml_i="7743" xml_f="7756" txt_i="2054" txt_f="2067">Russell, 1980</offsets></xref><offsets xml_i="7763" xml_f="7765" txt_i="2067" txt_f="2069">; </offsets><xref rid="bibr63-2041669518755806" ref-type="bibr"><offsets xml_i="7817" xml_f="7844" txt_i="2069" txt_f="2092">Watson &amp; Tellegen, 1985</offsets></xref><offsets xml_i="7851" xml_f="8027" txt_i="2092" txt_f="2268">). We have shown that not all negative stimuli are threatening, and that merely negative, but not threatening, stimuli evoke qualitatively different brain activation patterns (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="8079" xml_f="8099" txt_i="2268" txt_f="2288">Kveraga et al., 2015</offsets></xref><offsets xml_i="8106" xml_f="8584" txt_i="2288" txt_f="2766">). For example, imminent threat and accident scenes are both unpleasant situations, but responses to these types of images are quite different. While detecting imminent danger is critical for immediate survival, identifying appetitive stimuli and learning to avoid potential future threats are essential for long-term wellness and survival. Indeed, a recent study has confirmed that human observers exhibit “morbid curiosity” for socially negative, but not threatening, images (</offsets><xref rid="bibr52-2041669518755806" ref-type="bibr"><offsets xml_i="8636" xml_f="8652" txt_i="2766" txt_f="2782">Oosterwijk, 2017</offsets></xref><offsets xml_i="8659" xml_f="8661" txt_i="2782" txt_f="2784">).</offsets></p><p><offsets xml_i="8668" xml_f="8816" txt_i="2785" txt_f="2933">It has been proposed that responses to some types of threat stimuli such as spiders, snakes, and angry faces may be innate and shaped by evolution (</offsets><xref rid="bibr10-2041669518755806" ref-type="bibr"><offsets xml_i="8868" xml_f="8904" txt_i="2933" txt_f="2965">Brosch, Pourtois, &amp; Sander, 2010</offsets></xref><offsets xml_i="8911" xml_f="8913" txt_i="2965" txt_f="2967">; </offsets><xref rid="bibr24-2041669518755806" ref-type="bibr"><offsets xml_i="8965" xml_f="8977" txt_i="2967" txt_f="2979">Isbell, 2006</offsets></xref><offsets xml_i="8984" xml_f="8986" txt_i="2979" txt_f="2981">; </offsets><xref rid="bibr35-2041669518755806" ref-type="bibr"><offsets xml_i="9038" xml_f="9053" txt_i="2981" txt_f="2996">Le et al., 2013</offsets></xref><offsets xml_i="9060" xml_f="9062" txt_i="2996" txt_f="2998">; </offsets><xref rid="bibr47-2041669518755806" ref-type="bibr"><offsets xml_i="9114" xml_f="9146" txt_i="2998" txt_f="3026">New, Cosmides, &amp; Tooby, 2007</offsets></xref><offsets xml_i="9153" xml_f="9155" txt_i="3026" txt_f="3028">; </offsets><xref rid="bibr58-2041669518755806" ref-type="bibr"><offsets xml_i="9207" xml_f="9221" txt_i="3028" txt_f="3042">Seligman, 1971</offsets></xref><offsets xml_i="9228" xml_f="9347" txt_i="3042" txt_f="3161">). For example, it has been demonstrated that spiders and snakes are detected more rapidly than mushrooms and flowers (</offsets><xref rid="bibr49-2041669518755806" ref-type="bibr"><offsets xml_i="9399" xml_f="9432" txt_i="3161" txt_f="3190">Öhman, Flykt, &amp; Esteves, 2001</offsets></xref><offsets xml_i="9439" xml_f="9513" txt_i="3190" txt_f="3264">) and angry faces are detected faster than neutral faces and happy faces (</offsets><xref rid="bibr18-2041669518755806" ref-type="bibr"><offsets xml_i="9565" xml_f="9602" txt_i="3264" txt_f="3297">Eastwood, Smilek, &amp; Merikle, 2001</offsets></xref><offsets xml_i="9609" xml_f="9611" txt_i="3297" txt_f="3299">; </offsets><xref rid="bibr21-2041669518755806" ref-type="bibr"><offsets xml_i="9663" xml_f="9688" txt_i="3299" txt_f="3320">Hansen &amp; Hansen, 1988</offsets></xref><offsets xml_i="9695" xml_f="9697" txt_i="3320" txt_f="3322">; </offsets><xref rid="bibr22-2041669518755806" ref-type="bibr"><offsets xml_i="9749" xml_f="9764" txt_i="3322" txt_f="3337">Horstmann, 2007</offsets></xref><offsets xml_i="9771" xml_f="9773" txt_i="3337" txt_f="3339">; </offsets><xref rid="bibr61-2041669518755806" ref-type="bibr"><offsets xml_i="9825" xml_f="9861" txt_i="3339" txt_f="3371">Tipples, Atkinson, &amp; Young, 2002</offsets></xref><offsets xml_i="9868" xml_f="9946" txt_i="3371" txt_f="3449">). However, the latter effect is clearly seen in schematic, line-drawn faces (</offsets><xref rid="bibr51-2041669518755806" ref-type="bibr"><offsets xml_i="9998" xml_f="10049" txt_i="3449" txt_f="3496">Öhman, Soares, Juth, Lindström, &amp; Esteves, 2012</offsets></xref><offsets xml_i="10056" xml_f="10180" txt_i="3496" txt_f="3620">), but not necessarily in photographic faces because of the higher salience, or “vividness”, of happy, smiling faces (e.g., </offsets><xref rid="bibr5-2041669518755806" ref-type="bibr"><offsets xml_i="10231" xml_f="10285" txt_i="3620" txt_f="3670">Becker, Anderson, Mortensen, Neufeld, &amp; Neel, 2011</offsets></xref><offsets xml_i="10292" xml_f="10294" txt_i="3670" txt_f="3672">; </offsets><xref rid="bibr6-2041669518755806" ref-type="bibr"><offsets xml_i="10345" xml_f="10374" txt_i="3672" txt_f="3697">Becker &amp; Srinivasan, 2014</offsets></xref><offsets xml_i="10381" xml_f="10428" txt_i="3697" txt_f="3744">). Similar results were reported for children (</offsets><xref rid="bibr37-2041669518755806" ref-type="bibr"><offsets xml_i="10480" xml_f="10491" txt_i="3744" txt_f="3755">LoBue, 2009</offsets></xref><offsets xml_i="10498" xml_f="10500" txt_i="3755" txt_f="3757">, </offsets><xref rid="bibr38-2041669518755806" ref-type="bibr"><offsets xml_i="10552" xml_f="10557" txt_i="3757" txt_f="3762">2010a</offsets></xref><offsets xml_i="10564" xml_f="10566" txt_i="3762" txt_f="3764">; </offsets><xref rid="bibr40-2041669518755806" ref-type="bibr"><offsets xml_i="10618" xml_f="10644" txt_i="3764" txt_f="3786">LoBue &amp; DeLoache, 2008</offsets></xref><offsets xml_i="10651" xml_f="10666" txt_i="3786" txt_f="3801">) and infants (</offsets><xref rid="bibr41-2041669518755806" ref-type="bibr"><offsets xml_i="10718" xml_f="10744" txt_i="3801" txt_f="3823">LoBue &amp; DeLoache, 2010</offsets></xref><offsets xml_i="10751" xml_f="10828" txt_i="3823" txt_f="3900">). Threatening faces are processed faster than are other facial expressions (</offsets><xref rid="bibr57-2041669518755806" ref-type="bibr"><offsets xml_i="10880" xml_f="10899" txt_i="3900" txt_f="3919">Schupp et al., 2004</offsets></xref><offsets xml_i="10906" xml_f="11035" txt_i="3919" txt_f="4048">). In addition, saccadic eye movements orient more quickly to images of threatening compared to neutral faces and body postures (</offsets><xref rid="bibr1-2041669518755806" ref-type="bibr"><offsets xml_i="11086" xml_f="11136" txt_i="4048" txt_f="4094">Bannerman, Milders, de Gelder, &amp; Sahraie, 2009</offsets></xref><offsets xml_i="11143" xml_f="11202" txt_i="4094" txt_f="4153">) as well as towards emotional compared to neutral scenes (</offsets><xref rid="bibr48-2041669518755806" ref-type="bibr"><offsets xml_i="11254" xml_f="11289" txt_i="4153" txt_f="4184">Nummenmaa, Hyona, &amp; Calvo, 2009</offsets></xref><offsets xml_i="11296" xml_f="11587" txt_i="4184" txt_f="4475">). While these studies support the view that spiders, snakes, and angry faces belong to a special class of stimuli that are perceptually prioritized due to their importance for survival, adults have been also shown to quickly detect modern threats, such as guns, knives, and syringes (e.g., </offsets><xref rid="bibr9-2041669518755806" ref-type="bibr"><offsets xml_i="11638" xml_f="11654" txt_i="4475" txt_f="4491">Blanchette, 2006</offsets></xref><offsets xml_i="11661" xml_f="11688" txt_i="4491" txt_f="4518">). Using the same stimuli, </offsets><xref rid="bibr39-2041669518755806" ref-type="bibr"><offsets xml_i="11740" xml_f="11753" txt_i="4518" txt_f="4531">LoBue (2010b)</offsets></xref><offsets xml_i="11760" xml_f="12178" txt_i="4531" txt_f="4949"> reported that children only detected the syringes particularly quickly. These findings suggest that humans learn to detect novel threatening stimuli efficiently as a result of negative experiences. Together the research suggests that learning plays a vital role in threat perception. Humans and other primates not only have biases for the rapid detection of evolutionarily ancient threats such as snakes and spiders (</offsets><xref rid="bibr24-2041669518755806" ref-type="bibr"><offsets xml_i="12230" xml_f="12242" txt_i="4949" txt_f="4961">Isbell, 2006</offsets></xref><offsets xml_i="12249" xml_f="12363" txt_i="4961" txt_f="5075">) but also have the flexibility to learn to efficiently detect new threats that are specific to our environments (</offsets><xref rid="bibr41-2041669518755806" ref-type="bibr"><offsets xml_i="12415" xml_f="12451" txt_i="5075" txt_f="5107">LoBue, Rakison, &amp; DeLoache, 2010</offsets></xref><offsets xml_i="12458" xml_f="12460" txt_i="5107" txt_f="5109">).</offsets></p><p><offsets xml_i="12467" xml_f="12547" txt_i="5110" txt_f="5190">In a recent study focusing on how humans perceive and process negative stimuli (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="12599" xml_f="12619" txt_i="5190" txt_f="5210">Kveraga et al., 2015</offsets></xref><offsets xml_i="12626" xml_f="12927" txt_i="5210" txt_f="5511">), we presented color photographic scenes, including both natural threats (e.g., snakes, spiders, and carnivorans) as well as manmade threats (e.g., humans pointing guns and knives) classified a priori into four categories: Direct Threat, Indirect Threat, Threat Aftermath, and Low Threat situations (</offsets><xref ref-type="fig" rid="fig1-2041669518755806"><offsets xml_i="12976" xml_f="12987" txt_i="5511" txt_f="5522">Figure 1(a)</offsets></xref><offsets xml_i="12994" xml_f="13802" txt_i="5522" txt_f="6330">). We demonstrated that humans discriminate these four types of stimuli quickly and accurately. The images containing direct, immediate threats were recognized most quickly, while Threat Aftermath (merely negative) scene images without imminent threats were processed much more slowly, with responses lagging behind even Low Threat images. In addition, we found that threatening and merely negative scene images activated different, though somewhat overlapping, networks of brain regions. Specifically, the scene images depicting threat situations differentially activated the amygdalae, periaqueductal gray, and orbitofrontal cortex, while merely negative, Threat Aftermath scenes evoked stronger activity in the parahippocampal, retrosplenial, medial and lateral prefrontal, and lateral temporal cortices (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="13854" xml_f="13874" txt_i="6330" txt_f="6350">Kveraga et al., 2015</offsets></xref><offsets xml_i="13881" xml_f="13883" txt_i="6350" txt_f="6352">; </offsets><xref ref-type="fig" rid="fig2-2041669518755806"><offsets xml_i="13932" xml_f="13940" txt_i="6352" txt_f="6360">Figure 2</offsets></xref><offsets xml_i="13947" xml_f="13950" txt_i="6360" txt_f="6363">).
</offsets><fig id="fig1-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="14029" xml_f="14038" txt_i="6363" txt_f="6372">Figure 1.</offsets></label><caption><p><offsets xml_i="14058" xml_f="14115" txt_i="6372" txt_f="6429">(a) Examples of color photographic scene stimuli used in </offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="14167" xml_f="14188" txt_i="6429" txt_f="6450">Kveraga et al. (2015)</offsets></xref><offsets xml_i="14195" xml_f="14357" txt_i="6450" txt_f="6612"> depicting human and animal Direct Threat, Indirect Threat, Threat Aftermath, and Low Threat situations. (b) Line-drawing scene stimuli used in the current study.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig1"></graphic></fig><offsets xml_i="14439" xml_f="14440" txt_i="6613" txt_f="6614">
</offsets><fig id="fig2-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="14519" xml_f="14528" txt_i="6614" txt_f="6623">Figure 2.</offsets></label><caption><p><offsets xml_i="14548" xml_f="14648" txt_i="6623" txt_f="6723">Eight unique patterns capturing 500 images in our stimulus set based on trend analysis. Patterns 1 (</offsets><italic><offsets xml_i="14656" xml_f="14657" txt_i="6723" txt_f="6724">n</offsets></italic><offsets xml_i="14666" xml_f="14677" txt_i="6724" txt_f="6735"> = 85), 2 (</offsets><italic><offsets xml_i="14685" xml_f="14686" txt_i="6735" txt_f="6736">n</offsets></italic><offsets xml_i="14695" xml_f="14710" txt_i="6736" txt_f="6751"> = 34), and 3 (</offsets><italic><offsets xml_i="14718" xml_f="14719" txt_i="6751" txt_f="6752">n</offsets></italic><offsets xml_i="14728" xml_f="14840" txt_i="6752" txt_f="6864"> = 51) all captured images that depicted scenes posing high threat to the observer, receiving high ratings from </offsets><italic><offsets xml_i="14848" xml_f="14859" txt_i="6864" txt_f="6875">Harm to you</offsets></italic><offsets xml_i="14868" xml_f="14893" txt_i="6875" txt_f="6900"> group. Both Patterns 4 (</offsets><italic><offsets xml_i="14901" xml_f="14902" txt_i="6900" txt_f="6901">n</offsets></italic><offsets xml_i="14911" xml_f="14925" txt_i="6901" txt_f="6915"> = 80) and 5 (</offsets><italic><offsets xml_i="14933" xml_f="14934" txt_i="6915" txt_f="6916">n</offsets></italic><offsets xml_i="14943" xml_f="15050" txt_i="6916" txt_f="7023"> = 97) captured images depicting scenes posing high threat to someone else, receiving highest ratings from </offsets><italic><offsets xml_i="15058" xml_f="15071" txt_i="7023" txt_f="7036">Harm to other</offsets></italic><offsets xml_i="15080" xml_f="15100" txt_i="7036" txt_f="7056"> group. Patterns 6 (</offsets><italic><offsets xml_i="15108" xml_f="15109" txt_i="7056" txt_f="7057">n</offsets></italic><offsets xml_i="15118" xml_f="15132" txt_i="7057" txt_f="7071"> = 59) and 7 (</offsets><italic><offsets xml_i="15140" xml_f="15141" txt_i="7071" txt_f="7072">n</offsets></italic><offsets xml_i="15150" xml_f="15294" txt_i="7072" txt_f="7216"> = 23) both captured images depicting scenes where harm (physical, psychological, or both) has already happened, receiving highest ratings from </offsets><italic><offsets xml_i="15302" xml_f="15311" txt_i="7216" txt_f="7225">Past harm</offsets></italic><offsets xml_i="15320" xml_f="15348" txt_i="7225" txt_f="7253"> group. Finally, Pattern 8 (</offsets><italic><offsets xml_i="15356" xml_f="15357" txt_i="7253" txt_f="7254">n</offsets></italic><offsets xml_i="15366" xml_f="15506" txt_i="7254" txt_f="7394"> = 71) captured images depicting low level of threat either to the observer or someone else that were rated equally low by all three groups.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig2"></graphic></fig></p><p><offsets xml_i="15595" xml_f="15860" txt_i="7396" txt_f="7661">Line drawings have been long used as a tool for studying object and scene perception because they are much easier to systematically manipulate (e.g., altering eye gaze, body poses, presence or absence of a certain object and so on) compared to photographic images (</offsets><xref rid="bibr8-2041669518755806" ref-type="bibr"><offsets xml_i="15911" xml_f="15956" txt_i="7661" txt_f="7702">Biederman, Mezzanotte, &amp; Rabinowitz, 1982</offsets></xref><offsets xml_i="15963" xml_f="15965" txt_i="7702" txt_f="7704">; </offsets><xref rid="bibr29-2041669518755806" ref-type="bibr"><offsets xml_i="16017" xml_f="16050" txt_i="7704" txt_f="7733">Kveraga, Boshyan, &amp; Bar, 2007</offsets></xref><offsets xml_i="16057" xml_f="16059" txt_i="7733" txt_f="7735">; </offsets><xref rid="bibr53-2041669518755806" ref-type="bibr"><offsets xml_i="16111" xml_f="16123" txt_i="7735" txt_f="7747">Palmer, 1975</offsets></xref><offsets xml_i="16130" xml_f="16132" txt_i="7747" txt_f="7749">; </offsets><xref rid="bibr62-2041669518755806" ref-type="bibr"><offsets xml_i="16184" xml_f="16229" txt_i="7749" txt_f="7790">Walther, Chai, Caddigan, Beck, &amp; Li, 2011</offsets></xref><offsets xml_i="16236" xml_f="16278" txt_i="7790" txt_f="7832">). For example, in their seminal studies, </offsets><xref rid="bibr8-2041669518755806" ref-type="bibr"><offsets xml_i="16329" xml_f="16352" txt_i="7832" txt_f="7855">Biederman et al. (1982)</offsets></xref><offsets xml_i="16359" xml_f="16364" txt_i="7855" txt_f="7860"> and </offsets><xref rid="bibr53-2041669518755806" ref-type="bibr"><offsets xml_i="16416" xml_f="16429" txt_i="7860" txt_f="7873">Palmer (1975)</offsets></xref><offsets xml_i="16436" xml_f="16550" txt_i="7873" txt_f="7987"> demonstrated the effects of context on object recognition by manipulating line-drawing scenes. In another study, </offsets><xref rid="bibr29-2041669518755806" ref-type="bibr"><offsets xml_i="16602" xml_f="16623" txt_i="7987" txt_f="8008">Kveraga et al. (2007)</offsets></xref><offsets xml_i="16630" xml_f="16775" txt_i="8008" txt_f="8153"> used line drawings to investigate the contribution of the magnocellular and parvocellular visual pathways to object recognition. More recently, </offsets><xref rid="bibr62-2041669518755806" ref-type="bibr"><offsets xml_i="16827" xml_f="16848" txt_i="8153" txt_f="8174">Walther et al. (2011)</offsets></xref><offsets xml_i="16855" xml_f="17305" txt_i="8174" txt_f="8624"> reported that despite the marked difference in nonaffective scene statistics, they were able to decode scene category from fMRI data for nonaffective line dawings just as well as from activity for color photographs, in primary visual cortex through parahippocampal place area and retrosplenial cortex. Even more remarkably, in these regions, error patterns for decoding from line drawings were very similar to those obtained using color photographs.</offsets></p><p><offsets xml_i="17312" xml_f="17489" txt_i="8625" txt_f="8802">Several general and specialized visual stimulus sets have been developed to facilitate behavioral research on emotion, such as the International Affective Picture System (IAPS; </offsets><xref rid="bibr31-2041669518755806" ref-type="bibr"><offsets xml_i="17541" xml_f="17576" txt_i="8802" txt_f="8833">Lang, Bradley, &amp; Cuthbert, 2005</offsets></xref><offsets xml_i="17583" xml_f="17632" txt_i="8833" txt_f="8882">), the Geneva Affective Picture Database (GAPED; </offsets><xref rid="bibr13-2041669518755806" ref-type="bibr"><offsets xml_i="17684" xml_f="17715" txt_i="8882" txt_f="8909">Dan-Glauser &amp; Scherer, 2011</offsets></xref><offsets xml_i="17722" xml_f="17779" txt_i="8909" txt_f="8966">), and the Open Affective Standardized Image Set (OASIS; </offsets><xref rid="bibr26-2041669518755806" ref-type="bibr"><offsets xml_i="17831" xml_f="17864" txt_i="8966" txt_f="8995">Kurdi, Lozano, &amp; Banaji, 2017</offsets></xref><offsets xml_i="17871" xml_f="18618" txt_i="8995" txt_f="9742">). IAPS images, for example, have been used in several thousand research studies since they were first made available to the research community. However, IAPS images are subject to copyright restrictions that prohibit their usage in online research studies. Because of this, researchers conducting online studies were forced to create visual stimuli in an ad hoc manner, which was time-consuming, inefficient, and limited the comparability and generalizability of research findings. The OASIS database was specifically developed to address this problem by providing an open-access standardized stimulus set containing affective images with corresponding normative affective ratings, which similarly to the IAPS included a broad spectrum of themes.</offsets></p><p><offsets xml_i="18625" xml_f="19363" txt_i="9743" txt_f="10481">Even though it has been previously demonstrated that line-drawing images are a useful tool for studying objects and scenes, no line-drawn stimuli set of affective scenes exists to date. The goals of the present study were twofold: (a) to test whether distinctions in affective scene context that allow humans to discriminate different dimensions of threat and negativity can be extracted from very basic, impoverished visual information such as line drawings and (b) to compile a set of open-access images varying in their threat value that differ little in low-level features and are easier to manipulate compared to photographic images to facilitate studies of visual threat perception in neurotypical, as well as clinical, populations.</offsets></p></sec><sec sec-type="methods" id="sec2-2041669518755806"><title><offsets xml_i="19431" xml_f="19437" txt_i="10483" txt_f="10489">Method</offsets></title><sec id="sec3-2041669518755806" sec-type="subjects"><title><offsets xml_i="19504" xml_f="19516" txt_i="10490" txt_f="10502">Participants</offsets></title><sec id="sec4-2041669518755806"><title><offsets xml_i="19563" xml_f="19570" txt_i="10503" txt_f="10510">Study 1</offsets></title><p><offsets xml_i="19581" xml_f="19908" txt_i="10511" txt_f="10838">Sixty participants were recruited from Northeastern University and were rewarded with course credit for their participation. Eight participants were removed from the analyses due to poor performance (see Supplemental Tables 1 and 2 for details). The remaining 52 participants (27 males and 25 females) had a mean age of 19.49 (</offsets><italic><offsets xml_i="19916" xml_f="19918" txt_i="10838" txt_f="10840">SD</offsets></italic><offsets xml_i="19927" xml_f="19997" txt_i="10840" txt_f="10910"> = 1.50). Participants reported their ethnicity as European American (</offsets><italic><offsets xml_i="20005" xml_f="20006" txt_i="10910" txt_f="10911">n</offsets></italic><offsets xml_i="20015" xml_f="20030" txt_i="10911" txt_f="10926"> = 31), Asian (</offsets><italic><offsets xml_i="20038" xml_f="20039" txt_i="10926" txt_f="10927">n</offsets></italic><offsets xml_i="20048" xml_f="20078" txt_i="10927" txt_f="10957"> = 15), and African American (</offsets><italic><offsets xml_i="20086" xml_f="20087" txt_i="10957" txt_f="10958">n</offsets></italic><offsets xml_i="20096" xml_f="20152" txt_i="10958" txt_f="11014"> = 1). Five participants chose not to report their race.</offsets></p></sec><sec id="sec5-2041669518755806"><title><offsets xml_i="20201" xml_f="20208" txt_i="11016" txt_f="11023">Study 2</offsets></title><p><offsets xml_i="20219" xml_f="20510" txt_i="11024" txt_f="11315">Sixty-one participants were recruited from the Pennsylvania State University and were rewarded with course credit for their participation. One participant was removed from the analyses due to poor performance. The remaining 60 participants (29 males and 31 females) had a mean age of 19.28 (</offsets><italic><offsets xml_i="20518" xml_f="20520" txt_i="11315" txt_f="11317">SD</offsets></italic><offsets xml_i="20529" xml_f="20599" txt_i="11317" txt_f="11387"> = 1.22). Participants reported their ethnicity as European American (</offsets><italic><offsets xml_i="20607" xml_f="20608" txt_i="11387" txt_f="11388">n</offsets></italic><offsets xml_i="20617" xml_f="20632" txt_i="11388" txt_f="11403"> = 34), Asian (</offsets><italic><offsets xml_i="20640" xml_f="20641" txt_i="11403" txt_f="11404">n</offsets></italic><offsets xml_i="20650" xml_f="20676" txt_i="11404" txt_f="11430"> = 13), African American (</offsets><italic><offsets xml_i="20684" xml_f="20685" txt_i="11430" txt_f="11431">n</offsets></italic><offsets xml_i="20694" xml_f="20724" txt_i="11431" txt_f="11461"> = 9), and Hispanic American (</offsets><italic><offsets xml_i="20732" xml_f="20733" txt_i="11461" txt_f="11462">n</offsets></italic><offsets xml_i="20742" xml_f="20797" txt_i="11462" txt_f="11517"> = 2). Two participants chose not to report their race.</offsets></p></sec></sec><sec id="sec6-2041669518755806"><title><offsets xml_i="20852" xml_f="20858" txt_i="11520" txt_f="11526">Images</offsets></title><p><offsets xml_i="20869" xml_f="21013" txt_i="11527" txt_f="11671">We previously collected a set of 509 color photographic images depicting negative and neutral situations from Internet searches. As reported in </offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="21065" xml_f="21086" txt_i="11671" txt_f="11692">Kveraga et al. (2015)</offsets></xref><offsets xml_i="21093" xml_f="21698" txt_i="11692" txt_f="12297">, prior to collecting any data, we had classified these images into four categories based on our initial impressions: (a) negative, Direct Threat (from the viewpoint of the observer); (b) negative, Indirect Threat (predominantly to others); (c) negative, Threat Aftermath (a possible past threat, but not a threat any longer); and (d) neutral, Low Threat. We selected 500 out of these images to create line drawings by hand-tracing the main contours of agents (humans and animals), objects, and backgrounds. The line drawings were 700 × 700 pixels, with a black foreground and white background (e.g., see </offsets><xref ref-type="fig" rid="fig1-2041669518755806"><offsets xml_i="21747" xml_f="21756" txt_i="12297" txt_f="12306">Figure 1b</offsets></xref><offsets xml_i="21763" xml_f="21765" txt_i="12306" txt_f="12308">).</offsets></p></sec><sec id="sec7-2041669518755806" sec-type="methods"><title><offsets xml_i="21833" xml_f="21842" txt_i="12310" txt_f="12319">Procedure</offsets></title><sec id="sec8-2041669518755806"><title><offsets xml_i="21889" xml_f="21896" txt_i="12320" txt_f="12327">Study 1</offsets></title><p><offsets xml_i="21907" xml_f="22154" txt_i="12328" txt_f="12575">Participants were invited to the laboratory where they first read and signed the consent form. They were then randomly assigned to one of three groups. Each group of participants only responded to one of the questions on a scale from 1 to 6 (from </offsets><italic><offsets xml_i="22162" xml_f="22166" txt_i="12575" txt_f="12579">none</offsets></italic><offsets xml_i="22175" xml_f="22179" txt_i="12579" txt_f="12583"> to </offsets><italic><offsets xml_i="22187" xml_f="22194" txt_i="12583" txt_f="12590">extreme</offsets></italic><offsets xml_i="22203" xml_f="22441" txt_i="12590" txt_f="12828">). Five hundred line-drawing scene images were presented in a random order, and one of the following three questions was presented below each picture: (a) “How much harm might you be about to suffer if this was your view in this scene?” (</offsets><italic><offsets xml_i="22449" xml_f="22460" txt_i="12828" txt_f="12839">Harm to you</offsets></italic><offsets xml_i="22469" xml_f="22562" txt_i="12839" txt_f="12932"> group), (b) “How much harm might someone else (not you) be about to suffer in this scene?” (</offsets><italic><offsets xml_i="22570" xml_f="22583" txt_i="12932" txt_f="12945">Harm to other</offsets></italic><offsets xml_i="22592" xml_f="22692" txt_i="12945" txt_f="13045"> group), and (c) “How much harm might someone else (not you) have already suffered in this scene?” (</offsets><italic><offsets xml_i="22700" xml_f="22709" txt_i="13045" txt_f="13054">Past harm</offsets></italic><offsets xml_i="22718" xml_f="22934" txt_i="13054" txt_f="13270"> group). Participants could view each stimulus as long as they wanted and enter their rating using keys 1 to 6 on the keyboard. The rating scale was placed below the image and the points of the scale were labeled as </offsets><italic><offsets xml_i="22942" xml_f="22946" txt_i="13270" txt_f="13274">None</offsets></italic><offsets xml_i="22955" xml_f="22957" txt_i="13274" txt_f="13276">, </offsets><italic><offsets xml_i="22965" xml_f="22971" txt_i="13276" txt_f="13282">Little</offsets></italic><offsets xml_i="22980" xml_f="22982" txt_i="13282" txt_f="13284">, </offsets><italic><offsets xml_i="22990" xml_f="22994" txt_i="13284" txt_f="13288">Some</offsets></italic><offsets xml_i="23003" xml_f="23005" txt_i="13288" txt_f="13290">, </offsets><italic><offsets xml_i="23013" xml_f="23024" txt_i="13290" txt_f="13301">Quite a lot</offsets></italic><offsets xml_i="23033" xml_f="23035" txt_i="13301" txt_f="13303">, </offsets><italic><offsets xml_i="23043" xml_f="23052" txt_i="13303" txt_f="13312">Even more</offsets></italic><offsets xml_i="23061" xml_f="23067" txt_i="13312" txt_f="13318">, and </offsets><italic><offsets xml_i="23075" xml_f="23082" txt_i="13318" txt_f="13325">Extreme</offsets></italic><offsets xml_i="23091" xml_f="24022" txt_i="13325" txt_f="14256">. Entering the rating replaced the current stimulus with the next one. In order to discourage participants from rushing through the ratings, the program would not move to the next image if the response was made sooner than 500 ms after stimulus presentation. Instead, the image would stay on the screen for at least 500 ms, and participants would have to repeat their response in order to proceed to the next image. Even though a 500 ms threshold was employed to discourage participants from speeding, we also collected reaction times (RT) to screen for participants who nevertheless speeded through the task or took an extraordinarily long time to respond, as compared to other participants. After rating all the images, participants were asked to fill out a demographic information form, debriefed, and thanked for their time. All procedures were approved by the Northeastern University Institutional Review Board (IRB#11-03-35).</offsets></p></sec><sec id="sec9-2041669518755806"><title><offsets xml_i="24071" xml_f="24078" txt_i="14258" txt_f="14265">Study 2</offsets></title><p><offsets xml_i="24089" xml_f="24506" txt_i="14266" txt_f="14683">Participants were invited to the laboratory where they first read and signed the consent form. They were then randomly assigned to rate five hundred line-drawing scene images (presented in an individually randomized order) on only the valence dimension or only the arousal dimension using a 7-point Likert scale. We used image-focused instructions for valence and arousal ratings following the procedure described in </offsets><xref rid="bibr26-2041669518755806" ref-type="bibr"><offsets xml_i="24558" xml_f="24577" txt_i="14683" txt_f="14702">Kurdi et al. (2017)</offsets></xref><offsets xml_i="24584" xml_f="24877" txt_i="14702" txt_f="14995">. Participants could view each stimulus as long as they wanted and enter their rating using keys 1 to 7 on the keyboard. The rating scale was placed below the image. For the valence dimension, the word “Valence” was displayed above the rating scale and the points of the scale were labeled as </offsets><italic><offsets xml_i="24885" xml_f="24898" txt_i="14995" txt_f="15008">Very positive</offsets></italic><offsets xml_i="24907" xml_f="24909" txt_i="15008" txt_f="15010">, </offsets><italic><offsets xml_i="24917" xml_f="24936" txt_i="15010" txt_f="15029">Moderately positive</offsets></italic><offsets xml_i="24945" xml_f="24947" txt_i="15029" txt_f="15031">, </offsets><italic><offsets xml_i="24955" xml_f="24972" txt_i="15031" txt_f="15048">Somewhat positive</offsets></italic><offsets xml_i="24981" xml_f="24983" txt_i="15048" txt_f="15050">, </offsets><italic><offsets xml_i="24991" xml_f="24998" txt_i="15050" txt_f="15057">Neutral</offsets></italic><offsets xml_i="25007" xml_f="25009" txt_i="15057" txt_f="15059">, </offsets><italic><offsets xml_i="25017" xml_f="25034" txt_i="15059" txt_f="15076">Somewhat negative</offsets></italic><offsets xml_i="25043" xml_f="25045" txt_i="15076" txt_f="15078">, </offsets><italic><offsets xml_i="25053" xml_f="25072" txt_i="15078" txt_f="15097">Moderately negative</offsets></italic><offsets xml_i="25081" xml_f="25087" txt_i="15097" txt_f="15103">, and </offsets><italic><offsets xml_i="25095" xml_f="25108" txt_i="15103" txt_f="15116">Very negative</offsets></italic><offsets xml_i="25117" xml_f="25246" txt_i="15116" txt_f="15245">. For the arousal dimension, the word “Arousal” was displayed above the rating scale and the points of the scale were labeled as </offsets><italic><offsets xml_i="25254" xml_f="25262" txt_i="15245" txt_f="15253">Very low</offsets></italic><offsets xml_i="25271" xml_f="25273" txt_i="15253" txt_f="15255">, </offsets><italic><offsets xml_i="25281" xml_f="25295" txt_i="15255" txt_f="15269">Moderately low</offsets></italic><offsets xml_i="25304" xml_f="25306" txt_i="15269" txt_f="15271">, </offsets><italic><offsets xml_i="25314" xml_f="25326" txt_i="15271" txt_f="15283">Somewhat low</offsets></italic><offsets xml_i="25335" xml_f="25337" txt_i="15283" txt_f="15285">, </offsets><italic><offsets xml_i="25345" xml_f="25365" txt_i="15285" txt_f="15305">Neither low nor high</offsets></italic><offsets xml_i="25374" xml_f="25376" txt_i="15305" txt_f="15307">, </offsets><italic><offsets xml_i="25384" xml_f="25397" txt_i="15307" txt_f="15320">Somewhat high</offsets></italic><offsets xml_i="25406" xml_f="25408" txt_i="15320" txt_f="15322">, </offsets><italic><offsets xml_i="25416" xml_f="25431" txt_i="15322" txt_f="15337">Moderately high</offsets></italic><offsets xml_i="25440" xml_f="25446" txt_i="15337" txt_f="15343">, and </offsets><italic><offsets xml_i="25454" xml_f="25463" txt_i="15343" txt_f="15352">Very high</offsets></italic><offsets xml_i="25472" xml_f="25787" txt_i="15352" txt_f="15667">. Entering the rating replaced the current stimulus with the next one. After rating all the images, participants were asked to fill out a demographic information form, debriefed, and thanked for their time. All procedures were approved by the Pennsylvania State University Institutional Review Board (IRB#00005514).</offsets></p></sec></sec></sec><sec sec-type="results" id="sec10-2041669518755806"><title><offsets xml_i="25868" xml_f="25875" txt_i="15671" txt_f="15678">Results</offsets></title><sec id="sec11-2041669518755806"><title><offsets xml_i="25923" xml_f="25930" txt_i="15679" txt_f="15686">Study 1</offsets></title><p><offsets xml_i="25941" xml_f="26037" txt_i="15687" txt_f="15783">The RT data were first examined to screen for evidence of speeding through the task. One-sample </offsets><italic><offsets xml_i="26045" xml_f="26046" txt_i="15783" txt_f="15784">t</offsets></italic><offsets xml_i="26055" xml_f="26269" txt_i="15784" txt_f="15998"> tests comparing mean RT of each participant to the mean RT of their respective groups revealed that two participants were significantly faster as compared to other participants in their corresponding groups (both </offsets><italic><offsets xml_i="26277" xml_f="26278" txt_i="15998" txt_f="15999">p</offsets></italic><offsets xml_i="26287" xml_f="26520" txt_i="15999" txt_f="16232">s = .0001). Thus, we excluded their data from further analyses. In addition, we examined the RT distribution of each participant, removing any responses that were 2 standard deviations above the mean RT of corresponding participant (</offsets><xref rid="bibr55-2041669518755806" ref-type="bibr"><offsets xml_i="26572" xml_f="26586" txt_i="16232" txt_f="16246">Ratcliff, 1993</offsets></xref><offsets xml_i="26593" xml_f="26958" txt_i="16246" txt_f="16611">). This procedure resulted in the removal of 3.73% of the data. Next, we examined interrater reliability for each group. This analysis identified six additional participants whose responses were significantly different from the responses of other participants in their respective groups. The resulting mean interreliability across all three rating groups was .979 (</offsets><italic><offsets xml_i="26966" xml_f="26977" txt_i="16611" txt_f="16622">Harm to you</offsets></italic><offsets xml_i="26986" xml_f="26994" txt_i="16622" txt_f="16630"> group: </offsets><italic><offsets xml_i="27002" xml_f="27003" txt_i="16630" txt_f="16631">n</offsets></italic><offsets xml_i="27012" xml_f="27025" txt_i="16631" txt_f="16644"> = 18, .986; </offsets><italic><offsets xml_i="27033" xml_f="27046" txt_i="16644" txt_f="16657">Harm to other</offsets></italic><offsets xml_i="27055" xml_f="27063" txt_i="16657" txt_f="16665"> group: </offsets><italic><offsets xml_i="27071" xml_f="27072" txt_i="16665" txt_f="16666">n</offsets></italic><offsets xml_i="27081" xml_f="27094" txt_i="16666" txt_f="16679"> = 17, .983; </offsets><italic><offsets xml_i="27102" xml_f="27111" txt_i="16679" txt_f="16688">Past harm</offsets></italic><offsets xml_i="27120" xml_f="27128" txt_i="16688" txt_f="16696"> group: </offsets><italic><offsets xml_i="27136" xml_f="27137" txt_i="16696" txt_f="16697">n</offsets></italic><offsets xml_i="27146" xml_f="27159" txt_i="16697" txt_f="16710"> = 17, .969).</offsets><sup><xref ref-type="fn" rid="fn1-2041669518755806"><offsets xml_i="27211" xml_f="27212" txt_i="16710" txt_f="16711">1</offsets></xref></sup></p><sec id="sec12-2041669518755806"><title><offsets xml_i="27269" xml_f="27277" txt_i="16712" txt_f="16720">Patterns</offsets></title><p><offsets xml_i="27288" xml_f="27553" txt_i="16721" txt_f="16986">Means and standard deviations were calculated for each image as rated by each group. We then ran one-way ANOVAs on ratings from the three groups for each image to find the best fitting pattern for each image by fitting eight contrasts capturing different patterns (</offsets><xref ref-type="fig" rid="fig2-2041669518755806"><offsets xml_i="27602" xml_f="27610" txt_i="16986" txt_f="16994">Figure 2</offsets></xref><offsets xml_i="27617" xml_f="27619" txt_i="16994" txt_f="16996">).</offsets><sup><xref ref-type="fn" rid="fn2-2041669518755806"><offsets xml_i="27671" xml_f="27672" txt_i="16996" txt_f="16997">2</offsets></xref></sup><offsets xml_i="27685" xml_f="27851" txt_i="16997" txt_f="17163"> Based on the ratings across the three groups, we identified three patterns of images depicting scenes posing high threat to the observer (Direct Threat). Pattern 1 (</offsets><italic><offsets xml_i="27859" xml_f="27860" txt_i="17163" txt_f="17164">n</offsets></italic><offsets xml_i="27869" xml_f="28066" txt_i="17164" txt_f="17361"> = 85) included images depicting scenes where the observer was the target of potential harm, but where potential harm to someone else was less, and already occurring harm was even less. Pattern 2 (</offsets><italic><offsets xml_i="28074" xml_f="28075" txt_i="17361" txt_f="17362">n</offsets></italic><offsets xml_i="28084" xml_f="28309" txt_i="17362" txt_f="17587"> = 34) included images depicting scenes where the observer was the target of potential harm with lower but equal potential harm to someone else and already occurring harm. Like Patterns 1 and 2, images captured by Pattern 3 (</offsets><italic><offsets xml_i="28317" xml_f="28318" txt_i="17587" txt_f="17588">n</offsets></italic><offsets xml_i="28327" xml_f="28359" txt_i="17588" txt_f="17620"> = 51) received high ratings by </offsets><italic><offsets xml_i="28367" xml_f="28378" txt_i="17620" txt_f="17631">Harm to you</offsets></italic><offsets xml_i="28387" xml_f="28475" txt_i="17631" txt_f="17719"> group. However, unlike the other two patterns, these images were rated equally high by </offsets><italic><offsets xml_i="28483" xml_f="28496" txt_i="17719" txt_f="17732">Harm to other</offsets></italic><offsets xml_i="28505" xml_f="28542" txt_i="17732" txt_f="17769"> group, followed by lower ratings by </offsets><italic><offsets xml_i="28550" xml_f="28559" txt_i="17769" txt_f="17778">Past harm</offsets></italic><offsets xml_i="28568" xml_f="28949" txt_i="17778" txt_f="18159"> group. While examining the content of the scenes in the Direct Threat category we did not see any obvious differences between the images fitting Patterns 1 and 2, whereas stimuli fitting Pattern 3 depicted scenes with deadly weapons pointing directly at the observer. It is worth noting that none of the images fitting Pattern 3 included any animals. In addition, participants in </offsets><italic><offsets xml_i="28957" xml_f="28968" txt_i="18159" txt_f="18170">Harm to you</offsets></italic><offsets xml_i="28977" xml_f="29017" txt_i="18170" txt_f="18210"> group rated stimuli fitting Pattern 3 (</offsets><italic><offsets xml_i="29025" xml_f="29026" txt_i="18210" txt_f="18211">M</offsets></italic><offsets xml_i="29035" xml_f="29044" txt_i="18211" txt_f="18220"> = 5.36, </offsets><italic><offsets xml_i="29052" xml_f="29054" txt_i="18220" txt_f="18222">SD</offsets></italic><offsets xml_i="29063" xml_f="29138" txt_i="18222" txt_f="18297"> = .06) significantly higher as compared to images fitting both Pattern 1 (</offsets><italic><offsets xml_i="29146" xml_f="29147" txt_i="18297" txt_f="18298">M</offsets></italic><offsets xml_i="29156" xml_f="29165" txt_i="18298" txt_f="18307"> = 4.67, </offsets><italic><offsets xml_i="29173" xml_f="29175" txt_i="18307" txt_f="18309">SD</offsets></italic><offsets xml_i="29184" xml_f="29193" txt_i="18309" txt_f="18318"> = .05), </offsets><italic><offsets xml_i="29201" xml_f="29202" txt_i="18318" txt_f="18319">t</offsets></italic><offsets xml_i="29211" xml_f="29220" txt_i="18319" txt_f="18328"> = 8.41, </offsets><italic><offsets xml_i="29228" xml_f="29229" txt_i="18328" txt_f="18329">p</offsets></italic><offsets xml_i="29238" xml_f="29264" txt_i="18329" txt_f="18352"> &lt; .001 and Pattern 2 (</offsets><italic><offsets xml_i="29272" xml_f="29273" txt_i="18352" txt_f="18353">M</offsets></italic><offsets xml_i="29282" xml_f="29291" txt_i="18353" txt_f="18362"> = 4.78, </offsets><italic><offsets xml_i="29299" xml_f="29301" txt_i="18362" txt_f="18364">SD</offsets></italic><offsets xml_i="29310" xml_f="29319" txt_i="18364" txt_f="18373"> = .06), </offsets><italic><offsets xml_i="29327" xml_f="29328" txt_i="18373" txt_f="18374">t</offsets></italic><offsets xml_i="29337" xml_f="29346" txt_i="18374" txt_f="18383"> = 7.73, </offsets><italic><offsets xml_i="29354" xml_f="29355" txt_i="18383" txt_f="18384">p</offsets></italic><offsets xml_i="29364" xml_f="29419" txt_i="18384" txt_f="18436"> &lt; .001, with no difference between the latter two, </offsets><italic><offsets xml_i="29427" xml_f="29428" txt_i="18436" txt_f="18437">t</offsets></italic><offsets xml_i="29437" xml_f="29446" txt_i="18437" txt_f="18446"> = 1.12, </offsets><italic><offsets xml_i="29454" xml_f="29455" txt_i="18446" txt_f="18447">p</offsets></italic><offsets xml_i="29464" xml_f="29561" txt_i="18447" txt_f="18544"> = .265. Thus, we combined the stimuli fitting Patterns 1 and 2 into one Direct Threat category (</offsets><italic><offsets xml_i="29569" xml_f="29570" txt_i="18544" txt_f="18545">n</offsets></italic><offsets xml_i="29579" xml_f="29668" txt_i="18545" txt_f="18634"> = 119), but separated images fitting Pattern 3 into a category we called Deadly Threat (</offsets><italic><offsets xml_i="29676" xml_f="29677" txt_i="18634" txt_f="18635">n</offsets></italic><offsets xml_i="29686" xml_f="29693" txt_i="18635" txt_f="18642"> = 51).</offsets></p><p><offsets xml_i="29700" xml_f="29712" txt_i="18643" txt_f="18655">Patterns 4 (</offsets><italic><offsets xml_i="29720" xml_f="29721" txt_i="18655" txt_f="18656">n</offsets></italic><offsets xml_i="29730" xml_f="29744" txt_i="18656" txt_f="18670"> = 80) and 5 (</offsets><italic><offsets xml_i="29752" xml_f="29753" txt_i="18670" txt_f="18671">n</offsets></italic><offsets xml_i="29762" xml_f="29927" txt_i="18671" txt_f="18836"> = 97) both captured images depicting scenes posing high threat to someone else (Indirect Threat). However, images captured by Pattern 4 received highest ratings by </offsets><italic><offsets xml_i="29935" xml_f="29948" txt_i="18836" txt_f="18849">Harm to other</offsets></italic><offsets xml_i="29957" xml_f="29994" txt_i="18849" txt_f="18886"> group with equally lower ratings by </offsets><italic><offsets xml_i="30002" xml_f="30013" txt_i="18886" txt_f="18897">Harm to you</offsets></italic><offsets xml_i="30022" xml_f="30027" txt_i="18897" txt_f="18902"> and </offsets><italic><offsets xml_i="30035" xml_f="30044" txt_i="18902" txt_f="18911">Past harm</offsets></italic><offsets xml_i="30053" xml_f="30130" txt_i="18911" txt_f="18988"> groups, while images captured by Pattern 5 received equally high ratings by </offsets><italic><offsets xml_i="30138" xml_f="30151" txt_i="18988" txt_f="19001">Harm to other</offsets></italic><offsets xml_i="30160" xml_f="30165" txt_i="19001" txt_f="19006"> and </offsets><italic><offsets xml_i="30173" xml_f="30182" txt_i="19006" txt_f="19015">Past harm</offsets></italic><offsets xml_i="30191" xml_f="30221" txt_i="19015" txt_f="19045"> groups with lower ratings by </offsets><italic><offsets xml_i="30229" xml_f="30240" txt_i="19045" txt_f="19056">Harm to you</offsets></italic><offsets xml_i="30249" xml_f="30354" txt_i="19056" txt_f="19161"> group. No differences in content were found between images fitting Patterns 4 and 5 and participants in </offsets><italic><offsets xml_i="30362" xml_f="30375" txt_i="19161" txt_f="19174">Harm to other</offsets></italic><offsets xml_i="30384" xml_f="30424" txt_i="19174" txt_f="19214"> group rated stimuli fitting Pattern 4 (</offsets><italic><offsets xml_i="30432" xml_f="30433" txt_i="19214" txt_f="19215">M</offsets></italic><offsets xml_i="30442" xml_f="30451" txt_i="19215" txt_f="19224"> = 4.39, </offsets><italic><offsets xml_i="30459" xml_f="30461" txt_i="19224" txt_f="19226">SD</offsets></italic><offsets xml_i="30470" xml_f="30493" txt_i="19226" txt_f="19249"> = .73) and Pattern 5 (</offsets><italic><offsets xml_i="30501" xml_f="30502" txt_i="19249" txt_f="19250">M</offsets></italic><offsets xml_i="30511" xml_f="30520" txt_i="19250" txt_f="19259"> = 4.29, </offsets><italic><offsets xml_i="30528" xml_f="30530" txt_i="19259" txt_f="19261">SD</offsets></italic><offsets xml_i="30539" xml_f="30556" txt_i="19261" txt_f="19278"> = .61) equally, </offsets><italic><offsets xml_i="30564" xml_f="30565" txt_i="19278" txt_f="19279">t</offsets></italic><offsets xml_i="30574" xml_f="30582" txt_i="19279" txt_f="19287"> = .97, </offsets><italic><offsets xml_i="30590" xml_f="30591" txt_i="19287" txt_f="19288">p</offsets></italic><offsets xml_i="30600" xml_f="30697" txt_i="19288" txt_f="19385"> = .334. Hence, we combined the stimuli of these two patterns into one Indirect Threat category (</offsets><italic><offsets xml_i="30705" xml_f="30706" txt_i="19385" txt_f="19386">n</offsets></italic><offsets xml_i="30715" xml_f="30723" txt_i="19386" txt_f="19394"> = 177).</offsets></p><p><offsets xml_i="30730" xml_f="30742" txt_i="19395" txt_f="19407">Patterns 6 (</offsets><italic><offsets xml_i="30750" xml_f="30751" txt_i="19407" txt_f="19408">n</offsets></italic><offsets xml_i="30760" xml_f="30774" txt_i="19408" txt_f="19422"> = 59) and 7 (</offsets><italic><offsets xml_i="30782" xml_f="30783" txt_i="19422" txt_f="19423">n</offsets></italic><offsets xml_i="30792" xml_f="30990" txt_i="19423" txt_f="19621"> = 23) both captured images depicting scenes where harm (physical, psychological, or both) has already happened (Threat Aftermath). Images captured by Patterns 6 and 7 received highest ratings from </offsets><italic><offsets xml_i="30998" xml_f="31007" txt_i="19621" txt_f="19630">Past harm</offsets></italic><offsets xml_i="31016" xml_f="31047" txt_i="19630" txt_f="19661"> group and lowest ratings from </offsets><italic><offsets xml_i="31055" xml_f="31066" txt_i="19661" txt_f="19672">Harm to you</offsets></italic><offsets xml_i="31075" xml_f="31092" txt_i="19672" txt_f="19689"> group. However, </offsets><italic><offsets xml_i="31100" xml_f="31113" txt_i="19689" txt_f="19702">Harm to other</offsets></italic><offsets xml_i="31122" xml_f="31181" txt_i="19702" txt_f="19761"> group rated images characterized by Pattern 6 higher than </offsets><italic><offsets xml_i="31189" xml_f="31200" txt_i="19761" txt_f="19772">Harm to you</offsets></italic><offsets xml_i="31209" xml_f="31231" txt_i="19772" txt_f="19794"> group but lower than </offsets><italic><offsets xml_i="31239" xml_f="31248" txt_i="19794" txt_f="19803">Past harm</offsets></italic><offsets xml_i="31257" xml_f="31326" txt_i="19803" txt_f="19872"> group, while they rated images captured by Pattern 7 equally low as </offsets><italic><offsets xml_i="31334" xml_f="31345" txt_i="19872" txt_f="19883">Harm to you</offsets></italic><italic><offsets xml_i="31362" xml_f="31371" txt_i="19883" txt_f="19892">Past harm</offsets></italic><offsets xml_i="31380" xml_f="31412" txt_i="19892" txt_f="19924"> group for images in Pattern 6 (</offsets><italic><offsets xml_i="31420" xml_f="31421" txt_i="19924" txt_f="19925">M</offsets></italic><offsets xml_i="31430" xml_f="31439" txt_i="19925" txt_f="19934"> = 4.34, </offsets><italic><offsets xml_i="31447" xml_f="31449" txt_i="19934" txt_f="19936">SD</offsets></italic><offsets xml_i="31458" xml_f="31481" txt_i="19936" txt_f="19959"> = .95) and Pattern 7 (</offsets><italic><offsets xml_i="31489" xml_f="31490" txt_i="19959" txt_f="19960">M</offsets></italic><offsets xml_i="31499" xml_f="31508" txt_i="19960" txt_f="19969"> = 4.25, </offsets><italic><offsets xml_i="31516" xml_f="31518" txt_i="19969" txt_f="19971">SD</offsets></italic><offsets xml_i="31527" xml_f="31536" txt_i="19971" txt_f="19980"> = .66), </offsets><italic><offsets xml_i="31544" xml_f="31545" txt_i="19980" txt_f="19981">t</offsets></italic><offsets xml_i="31554" xml_f="31562" txt_i="19981" txt_f="19989"> = .42, </offsets><italic><offsets xml_i="31570" xml_f="31571" txt_i="19989" txt_f="19990">p</offsets></italic><offsets xml_i="31580" xml_f="31650" txt_i="19990" txt_f="20060"> = .680, we combined these images into one Threat Aftermath category (</offsets><italic><offsets xml_i="31658" xml_f="31659" txt_i="20060" txt_f="20061">n</offsets></italic><offsets xml_i="31668" xml_f="31675" txt_i="20061" txt_f="20068"> = 82).</offsets></p><p><offsets xml_i="31682" xml_f="31702" txt_i="20069" txt_f="20089">Finally, Pattern 8 (</offsets><italic><offsets xml_i="31710" xml_f="31711" txt_i="20089" txt_f="20090">n</offsets></italic><offsets xml_i="31720" xml_f="31925" txt_i="20090" txt_f="20295"> = 71) captured images depicting low level of threat either to the observer or someone else (Low Threat; e.g., an image of a woman walking a dog on a leash) that were rated equally low by all three groups.</offsets></p></sec><sec id="sec13-2041669518755806"><title><offsets xml_i="31975" xml_f="31991" txt_i="20297" txt_f="20313">Image categories</offsets></title><p><offsets xml_i="32002" xml_f="32060" txt_i="20314" txt_f="20372">Based on trend analyses we created five image categories (</offsets><xref ref-type="fig" rid="fig3-2041669518755806"><offsets xml_i="32109" xml_f="32117" txt_i="20372" txt_f="20380">Figure 3</offsets></xref><offsets xml_i="32124" xml_f="32127" txt_i="20380" txt_f="20383">). </offsets><italic><offsets xml_i="32135" xml_f="32148" txt_i="20383" txt_f="20396">Deadly Threat</offsets></italic><offsets xml_i="32157" xml_f="32168" txt_i="20396" txt_f="20407"> category (</offsets><italic><offsets xml_i="32176" xml_f="32177" txt_i="20407" txt_f="20408">n</offsets></italic><offsets xml_i="32186" xml_f="32454" txt_i="20408" txt_f="20676"> = 51) included images depicting scenes with deadly weapons pointing directly at the observer with equal potential harm to someone else, but lower possibility of harm already occurring. It is worth noting that none of the images in this category included any animals. </offsets><italic><offsets xml_i="32462" xml_f="32475" txt_i="20676" txt_f="20689">Direct Threat</offsets></italic><offsets xml_i="32484" xml_f="32495" txt_i="20689" txt_f="20700"> category (</offsets><italic><offsets xml_i="32503" xml_f="32504" txt_i="20700" txt_f="20701">n</offsets></italic><offsets xml_i="32513" xml_f="32700" txt_i="20701" txt_f="20888"> = 119) included images depicting scenes where the observer was the target of potential harm, but where potential harm to someone else was less, and already occurring harm was even less. </offsets><italic><offsets xml_i="32708" xml_f="32723" txt_i="20888" txt_f="20903">Indirect Threat</offsets></italic><offsets xml_i="32732" xml_f="32743" txt_i="20903" txt_f="20914"> category (</offsets><italic><offsets xml_i="32751" xml_f="32752" txt_i="20914" txt_f="20915">n</offsets></italic><offsets xml_i="32761" xml_f="32929" txt_i="20915" txt_f="21083"> = 177) included images depicting scenes with highest harm to someone else, lower possibility of harm already occurring, and the lowest potential harm to the observer. </offsets><italic><offsets xml_i="32937" xml_f="32953" txt_i="21083" txt_f="21099">Threat Aftermath</offsets></italic><offsets xml_i="32962" xml_f="32973" txt_i="21099" txt_f="21110"> category (</offsets><italic><offsets xml_i="32981" xml_f="32982" txt_i="21110" txt_f="21111">n</offsets></italic><offsets xml_i="32991" xml_f="33199" txt_i="21111" txt_f="21319"> = 82) included images depicting scenes where past harm (physical, psychological, or both) has already occurred, with lower potential harm to someone else, and lowest potential harm to the observer. Finally, </offsets><italic><offsets xml_i="33207" xml_f="33217" txt_i="21319" txt_f="21329">Low Threat</offsets></italic><offsets xml_i="33226" xml_f="33237" txt_i="21329" txt_f="21340"> category (</offsets><italic><offsets xml_i="33245" xml_f="33246" txt_i="21340" txt_f="21341">n</offsets></italic><offsets xml_i="33255" xml_f="33398" txt_i="21341" txt_f="21484"> = 71) included images depicting low level of harm to the observer or someone else, as well as low possibility of past harm already occurring.
</offsets><fig id="fig3-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="33477" xml_f="33486" txt_i="21484" txt_f="21493">Figure 3.</offsets></label><caption><p><offsets xml_i="33506" xml_f="33578" txt_i="21493" txt_f="21565">Five distinct image categories with corresponding prototypical examples.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig3"></graphic></fig></p></sec><sec id="sec14-2041669518755806"><title><offsets xml_i="33710" xml_f="33722" txt_i="21568" txt_f="21580">Mean ratings</offsets></title><p><offsets xml_i="33733" xml_f="34103" txt_i="21581" txt_f="21951">To assess the statistical significance of the differences in the ratings, we ran a 3 (rating group) × 5 (image category) repeated-measures ANOVA. In order to account for eventual biases due to unbalanced numbers of stimuli in each image category, we used Type II calculation for obtaining sums of squares.The analysis revealed a significant main effect of rating group (</offsets><italic><offsets xml_i="34111" xml_f="34112" txt_i="21951" txt_f="21952">F</offsets></italic><offsets xml_i="34121" xml_f="34139" txt_i="21952" txt_f="21970">(2,990) = 122.48, </offsets><italic><offsets xml_i="34147" xml_f="34148" txt_i="21970" txt_f="21971">p</offsets></italic><offsets xml_i="34157" xml_f="34169" txt_i="21971" txt_f="21980"> &lt; .001, </offsets><italic><offsets xml_i="34177" xml_f="34178" txt_i="21980" txt_f="21981">η</offsets></italic><sup><offsets xml_i="34192" xml_f="34193" txt_i="21981" txt_f="21982">2</offsets></sup><sub><italic><offsets xml_i="34212" xml_f="34213" txt_i="21982" txt_f="21983">p</offsets></italic></sub><offsets xml_i="34228" xml_f="34242" txt_i="21983" txt_f="21997"> = .198) with </offsets><italic><offsets xml_i="34250" xml_f="34263" txt_i="21997" txt_f="22010">Harm to other</offsets></italic><offsets xml_i="34272" xml_f="34329" txt_i="22010" txt_f="22067"> group having the highest overall ratings as compared to </offsets><italic><offsets xml_i="34337" xml_f="34348" txt_i="22067" txt_f="22078">Harm to you</offsets></italic><offsets xml_i="34357" xml_f="34362" txt_i="22078" txt_f="22083"> and </offsets><italic><offsets xml_i="34370" xml_f="34379" txt_i="22083" txt_f="22092">Past harm</offsets></italic><offsets xml_i="34388" xml_f="34402" txt_i="22092" txt_f="22106"> groups (both </offsets><italic><offsets xml_i="34410" xml_f="34411" txt_i="22106" txt_f="22107">p</offsets></italic><offsets xml_i="34420" xml_f="34489" txt_i="22107" txt_f="22173">s &lt; .001), with no significant difference between the latter two (</offsets><italic><offsets xml_i="34497" xml_f="34508" txt_i="22173" txt_f="22184">Harm to you</offsets></italic><offsets xml_i="34517" xml_f="34525" txt_i="22184" txt_f="22192"> group: </offsets><italic><offsets xml_i="34533" xml_f="34534" txt_i="22192" txt_f="22193">M</offsets></italic><sub><offsets xml_i="34548" xml_f="34558" txt_i="22193" txt_f="22203">difference</offsets></sub><offsets xml_i="34564" xml_f="34573" txt_i="22203" txt_f="22212"> = 3.31, </offsets><italic><offsets xml_i="34581" xml_f="34583" txt_i="22212" txt_f="22214">SE</offsets></italic><offsets xml_i="34592" xml_f="34600" txt_i="22214" txt_f="22222"> = .03; </offsets><italic><offsets xml_i="34608" xml_f="34617" txt_i="22222" txt_f="22231">Past harm</offsets></italic><offsets xml_i="34626" xml_f="34634" txt_i="22231" txt_f="22239"> group: </offsets><italic><offsets xml_i="34642" xml_f="34643" txt_i="22239" txt_f="22240">M</offsets></italic><sub><offsets xml_i="34657" xml_f="34667" txt_i="22240" txt_f="22250">difference</offsets></sub><offsets xml_i="34673" xml_f="34682" txt_i="22250" txt_f="22259"> = 3.38, </offsets><italic><offsets xml_i="34690" xml_f="34692" txt_i="22259" txt_f="22261">SE</offsets></italic><offsets xml_i="34701" xml_f="34709" txt_i="22261" txt_f="22269"> = .04, </offsets><italic><offsets xml_i="34717" xml_f="34718" txt_i="22269" txt_f="22270">t</offsets></italic><offsets xml_i="34727" xml_f="34741" txt_i="22270" txt_f="22284">(998) = 2.27, </offsets><italic><offsets xml_i="34749" xml_f="34750" txt_i="22284" txt_f="22285">p</offsets></italic><offsets xml_i="34759" xml_f="34829" txt_i="22285" txt_f="22355"> = .066). There was also a significant main effect of image category (</offsets><italic><offsets xml_i="34837" xml_f="34838" txt_i="22355" txt_f="22356">F</offsets></italic><offsets xml_i="34847" xml_f="34865" txt_i="22356" txt_f="22374">(4,495) = 253.31, </offsets><italic><offsets xml_i="34873" xml_f="34874" txt_i="22374" txt_f="22375">p</offsets></italic><offsets xml_i="34883" xml_f="34895" txt_i="22375" txt_f="22384"> &lt; .001, </offsets><italic><offsets xml_i="34903" xml_f="34904" txt_i="22384" txt_f="22385">η</offsets></italic><sup><offsets xml_i="34918" xml_f="34919" txt_i="22385" txt_f="22386">2</offsets></sup><sub><italic><offsets xml_i="34938" xml_f="34939" txt_i="22386" txt_f="22387">p</offsets></italic></sub><offsets xml_i="34954" xml_f="35019" txt_i="22387" txt_f="22452"> = .672). Except for a nonsignificant difference between Direct (</offsets><italic><offsets xml_i="35027" xml_f="35028" txt_i="22452" txt_f="22453">M</offsets></italic><offsets xml_i="35037" xml_f="35046" txt_i="22453" txt_f="22462"> = 3.80, </offsets><italic><offsets xml_i="35054" xml_f="35056" txt_i="22462" txt_f="22464">SE</offsets></italic><offsets xml_i="35065" xml_f="35094" txt_i="22464" txt_f="22493"> = .06) and Indirect Threat (</offsets><italic><offsets xml_i="35102" xml_f="35103" txt_i="22493" txt_f="22494">M</offsets></italic><offsets xml_i="35112" xml_f="35121" txt_i="22494" txt_f="22503"> = 3.70, </offsets><italic><offsets xml_i="35129" xml_f="35131" txt_i="22503" txt_f="22505">SE</offsets></italic><offsets xml_i="35140" xml_f="35160" txt_i="22505" txt_f="22525"> = .08) categories (</offsets><italic><offsets xml_i="35168" xml_f="35169" txt_i="22525" txt_f="22526">t</offsets></italic><offsets xml_i="35178" xml_f="35192" txt_i="22526" txt_f="22540">(294) = 1.29, </offsets><italic><offsets xml_i="35200" xml_f="35201" txt_i="22540" txt_f="22541">p</offsets></italic><offsets xml_i="35210" xml_f="35366" txt_i="22541" txt_f="22697"> = .884), all image categories were significantly different from each other as indicated by post hoc pairwise comparisons with a Bonferroni correction (all </offsets><italic><offsets xml_i="35374" xml_f="35375" txt_i="22697" txt_f="22698">p</offsets></italic><offsets xml_i="35384" xml_f="35656" txt_i="22698" txt_f="22967">s &lt; .001). This nonsignificant difference between Direct Threat and Indirect Threat image categories, collapsing across rating groups, was due to the difference in ratings for these images among all the three groups of participants. Specifically, while participants in </offsets><italic><offsets xml_i="35664" xml_f="35675" txt_i="22967" txt_f="22978">Harm to you</offsets></italic><offsets xml_i="35684" xml_f="35800" txt_i="22978" txt_f="23094"> group rated Direct Threat images higher than Indirect Threat images, the opposite was true for the participants in </offsets><italic><offsets xml_i="35808" xml_f="35821" txt_i="23094" txt_f="23107">Harm to other</offsets></italic><offsets xml_i="35830" xml_f="35835" txt_i="23107" txt_f="23112"> and </offsets><italic><offsets xml_i="35843" xml_f="35852" txt_i="23112" txt_f="23121">Past harm</offsets></italic><offsets xml_i="35861" xml_f="36105" txt_i="23121" txt_f="23365"> groups. Thus, when collapsing across the three groups, the difference between Direct Threat and Indirect Threat image categories was nonsignificant. This is illustrated by a significant interaction between the image category and rating group (</offsets><italic><offsets xml_i="36113" xml_f="36114" txt_i="23365" txt_f="23366">F</offsets></italic><offsets xml_i="36123" xml_f="36141" txt_i="23366" txt_f="23384">(8,990) = 445.96, </offsets><italic><offsets xml_i="36149" xml_f="36150" txt_i="23384" txt_f="23385">p</offsets></italic><offsets xml_i="36159" xml_f="36171" txt_i="23385" txt_f="23394"> &lt; .001, </offsets><italic><offsets xml_i="36179" xml_f="36180" txt_i="23394" txt_f="23395">η</offsets></italic><sup><offsets xml_i="36194" xml_f="36195" txt_i="23395" txt_f="23396">2</offsets></sup><sub><offsets xml_i="36206" xml_f="36207" txt_i="23396" txt_f="23397">p</offsets></sub><offsets xml_i="36213" xml_f="36222" txt_i="23397" txt_f="23406"> = .783; </offsets><xref ref-type="fig" rid="fig4-2041669518755806"><offsets xml_i="36271" xml_f="36279" txt_i="23406" txt_f="23414">Figure 4</offsets></xref><offsets xml_i="36286" xml_f="36289" txt_i="23414" txt_f="23417">). </offsets><italic><offsets xml_i="36297" xml_f="36308" txt_i="23417" txt_f="23428">Harm to you</offsets></italic><offsets xml_i="36317" xml_f="36423" txt_i="23428" txt_f="23534"> group had the highest ratings for the Deadly Threat image category compared to all other categories (all </offsets><italic><offsets xml_i="36431" xml_f="36432" txt_i="23534" txt_f="23535">p</offsets></italic><offsets xml_i="36441" xml_f="36486" txt_i="23535" txt_f="23577">s &lt; .001), followed by Direct Threat (all </offsets><italic><offsets xml_i="36494" xml_f="36495" txt_i="23577" txt_f="23578">p</offsets></italic><offsets xml_i="36504" xml_f="36539" txt_i="23578" txt_f="23610">s &lt; .001), Indirect Threat (all </offsets><italic><offsets xml_i="36547" xml_f="36548" txt_i="23610" txt_f="23611">p</offsets></italic><offsets xml_i="36557" xml_f="36593" txt_i="23611" txt_f="23644">s &lt; .001), Threat Aftermath (all </offsets><italic><offsets xml_i="36601" xml_f="36602" txt_i="23644" txt_f="23645">p</offsets></italic><offsets xml_i="36611" xml_f="36645" txt_i="23645" txt_f="23676">s &lt; .017), and Low Threat (all </offsets><italic><offsets xml_i="36653" xml_f="36654" txt_i="23676" txt_f="23677">p</offsets></italic><offsets xml_i="36663" xml_f="36757" txt_i="23677" txt_f="23768">s &lt; .017) as indicated by pairwise comparisons with a Bonferroni correction. Similarly for </offsets><italic><offsets xml_i="36765" xml_f="36778" txt_i="23768" txt_f="23781">Harm to other</offsets></italic><offsets xml_i="36787" xml_f="36869" txt_i="23781" txt_f="23863"> group, all pairwise comparisons with Bonferroni correction were significant (all </offsets><italic><offsets xml_i="36877" xml_f="36878" txt_i="23863" txt_f="23864">p</offsets></italic><offsets xml_i="36887" xml_f="37046" txt_i="23864" txt_f="24020">s &lt; .001). Participants rated Deadly Threat images the highest followed by Indirect Threat, Direct Threat, Threat Aftermath, and Low Threat categories. For </offsets><italic><offsets xml_i="37054" xml_f="37063" txt_i="24020" txt_f="24029">Past harm</offsets></italic><offsets xml_i="37072" xml_f="37154" txt_i="24029" txt_f="24111"> group, all pairwise comparisons with Bonferroni correction were significant (all </offsets><italic><offsets xml_i="37162" xml_f="37163" txt_i="24111" txt_f="24112">p</offsets></italic><offsets xml_i="37172" xml_f="37239" txt_i="24112" txt_f="24176">s &lt; .043), except for the comparison between the Deadly Threat (</offsets><italic><offsets xml_i="37247" xml_f="37248" txt_i="24176" txt_f="24177">M</offsets></italic><offsets xml_i="37257" xml_f="37266" txt_i="24177" txt_f="24186"> = 4.15, </offsets><italic><offsets xml_i="37274" xml_f="37276" txt_i="24186" txt_f="24188">SE</offsets></italic><offsets xml_i="37285" xml_f="37332" txt_i="24188" txt_f="24235"> = .10) and Threat Aftermath image categories (</offsets><italic><offsets xml_i="37340" xml_f="37341" txt_i="24235" txt_f="24236">M</offsets></italic><offsets xml_i="37350" xml_f="37359" txt_i="24236" txt_f="24245"> = 4.31, </offsets><italic><offsets xml_i="37367" xml_f="37369" txt_i="24245" txt_f="24247">SE</offsets></italic><offsets xml_i="37378" xml_f="37386" txt_i="24247" txt_f="24255"> = .08; </offsets><italic><offsets xml_i="37394" xml_f="37395" txt_i="24255" txt_f="24256">t</offsets></italic><offsets xml_i="37404" xml_f="37418" txt_i="24256" txt_f="24270">(131) = 1.24, </offsets><italic><offsets xml_i="37426" xml_f="37427" txt_i="24270" txt_f="24271">p</offsets></italic><offsets xml_i="37436" xml_f="37591" txt_i="24271" txt_f="24426"> = .908). Participants rated Threat Aftermath and Deadly Threat images the highest, followed by Indirect Threat, Direct Threat, and Low Threat categories.
</offsets><fig id="fig4-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="37670" xml_f="37679" txt_i="24426" txt_f="24435">Figure 4.</offsets></label><caption><p><offsets xml_i="37699" xml_f="38285" txt_i="24435" txt_f="25021">Study 1 results. (a) Results of the scene ratings. The three panels show the results from the three rating groups. Participants in Group 1 (left panel) were asked to rate all images in terms of potential harm to them personally; participants in Group 2 (middle panel) were asked to rate all images in terms of potential harm to someone else; participants in Group 3 (right panel) were asked to rate all images in terms of past harm, but no present harm. 500 images were presented in a randomized mixed sequence. (b) Results of the RT. The error bars indicate standard error of the mean.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig4"></graphic></fig></p></sec><sec id="sec15-2041669518755806"><title><offsets xml_i="38417" xml_f="38431" txt_i="25024" txt_f="25038">Reaction times</offsets></title><p><offsets xml_i="38442" xml_f="38964" txt_i="25039" txt_f="25561">By design, we enforced a 500-ms threshold to discourage participants from speeding through the images; thus, the shortest RT in our collected data was 501 ms. Even though the interpretation of our RT data is limited, we still examined any possible differences in RT between the rating groups as well as image categories by performing a 3 (rating group) × 5 (image category) repeated-measures ANOVA using Type II calculation for obtaining sums of squares. The analysis revealed a significant main effect of image category (</offsets><italic><offsets xml_i="38972" xml_f="38973" txt_i="25561" txt_f="25562">F</offsets></italic><offsets xml_i="38982" xml_f="38999" txt_i="25562" txt_f="25579">(4,495) = 50.39, </offsets><italic><offsets xml_i="39007" xml_f="39008" txt_i="25579" txt_f="25580">p</offsets></italic><offsets xml_i="39017" xml_f="39029" txt_i="25580" txt_f="25589"> &lt; .001, </offsets><italic><offsets xml_i="39037" xml_f="39038" txt_i="25589" txt_f="25590">η</offsets></italic><sup><offsets xml_i="39052" xml_f="39053" txt_i="25590" txt_f="25591">2</offsets></sup><sub><italic><offsets xml_i="39072" xml_f="39073" txt_i="25591" txt_f="25592">p</offsets></italic></sub><offsets xml_i="39088" xml_f="39176" txt_i="25592" txt_f="25680"> = .289). Except for no statistically significant difference between the Direct Threat (</offsets><italic><offsets xml_i="39184" xml_f="39185" txt_i="25680" txt_f="25681">M</offsets></italic><offsets xml_i="39194" xml_f="39203" txt_i="25681" txt_f="25690"> = 2.10, </offsets><italic><offsets xml_i="39211" xml_f="39213" txt_i="25690" txt_f="25692">SE</offsets></italic><offsets xml_i="39222" xml_f="39246" txt_i="25692" txt_f="25716"> = .04) and Low Threat (</offsets><italic><offsets xml_i="39254" xml_f="39255" txt_i="25716" txt_f="25717">M</offsets></italic><offsets xml_i="39264" xml_f="39273" txt_i="25717" txt_f="25726"> = 2.26, </offsets><italic><offsets xml_i="39281" xml_f="39283" txt_i="25726" txt_f="25728">SE</offsets></italic><offsets xml_i="39292" xml_f="39312" txt_i="25728" txt_f="25748"> = .05) categories (</offsets><italic><offsets xml_i="39320" xml_f="39321" txt_i="25748" txt_f="25749">t</offsets></italic><offsets xml_i="39330" xml_f="39344" txt_i="25749" txt_f="25763">(188) = 2.72, </offsets><italic><offsets xml_i="39352" xml_f="39353" txt_i="25763" txt_f="25764">p</offsets></italic><offsets xml_i="39362" xml_f="39518" txt_i="25764" txt_f="25920"> = .064), all image categories were significantly different from each other as indicated by post hoc pairwise comparisons with a Bonferroni correction (all </offsets><italic><offsets xml_i="39526" xml_f="39527" txt_i="25920" txt_f="25921">p</offsets></italic><offsets xml_i="39536" xml_f="39783" txt_i="25921" txt_f="26165">s &lt; .006). Deadly Threat images were rated most quickly, followed by Direct Threat and Low Threat images, Indirect Threat, and finally Threat Aftermath images, which had the longest RT. There was also a significant main effect of rating group (</offsets><italic><offsets xml_i="39791" xml_f="39792" txt_i="26165" txt_f="26166">F</offsets></italic><offsets xml_i="39801" xml_f="39818" txt_i="26166" txt_f="26183">(2,990) = 14.78, </offsets><italic><offsets xml_i="39826" xml_f="39827" txt_i="26183" txt_f="26184">p</offsets></italic><offsets xml_i="39836" xml_f="39848" txt_i="26184" txt_f="26193"> &lt; .001, </offsets><italic><offsets xml_i="39856" xml_f="39857" txt_i="26193" txt_f="26194">η</offsets></italic><sup><offsets xml_i="39871" xml_f="39872" txt_i="26194" txt_f="26195">2</offsets></sup><sub><italic><offsets xml_i="39891" xml_f="39892" txt_i="26195" txt_f="26196">p</offsets></italic></sub><offsets xml_i="39907" xml_f="39922" txt_i="26196" txt_f="26211"> = .029), with </offsets><italic><offsets xml_i="39930" xml_f="39943" txt_i="26211" txt_f="26224">Harm to other</offsets></italic><offsets xml_i="39952" xml_f="40005" txt_i="26224" txt_f="26277"> group having the longest overall RTs as compared to </offsets><italic><offsets xml_i="40013" xml_f="40024" txt_i="26277" txt_f="26288">Harm to you</offsets></italic><offsets xml_i="40033" xml_f="40038" txt_i="26288" txt_f="26293"> and </offsets><italic><offsets xml_i="40046" xml_f="40055" txt_i="26293" txt_f="26302">Past harm</offsets></italic><offsets xml_i="40064" xml_f="40078" txt_i="26302" txt_f="26316"> groups (both </offsets><italic><offsets xml_i="40086" xml_f="40087" txt_i="26316" txt_f="26317">p</offsets></italic><offsets xml_i="40096" xml_f="40165" txt_i="26317" txt_f="26383">s &lt; .001), with no significant difference between the latter two (</offsets><italic><offsets xml_i="40173" xml_f="40184" txt_i="26383" txt_f="26394">Harm to you</offsets></italic><offsets xml_i="40193" xml_f="40201" txt_i="26394" txt_f="26402"> group: </offsets><italic><offsets xml_i="40209" xml_f="40210" txt_i="26402" txt_f="26403">M</offsets></italic><sub><offsets xml_i="40224" xml_f="40234" txt_i="26403" txt_f="26413">difference</offsets></sub><offsets xml_i="40240" xml_f="40249" txt_i="26413" txt_f="26422"> = 2.20, </offsets><italic><offsets xml_i="40257" xml_f="40259" txt_i="26422" txt_f="26424">SE</offsets></italic><offsets xml_i="40268" xml_f="40276" txt_i="26424" txt_f="26432"> = .02; </offsets><italic><offsets xml_i="40284" xml_f="40293" txt_i="26432" txt_f="26441">Past harm</offsets></italic><offsets xml_i="40302" xml_f="40310" txt_i="26441" txt_f="26449"> group: </offsets><italic><offsets xml_i="40318" xml_f="40319" txt_i="26449" txt_f="26450">M</offsets></italic><sub><offsets xml_i="40333" xml_f="40343" txt_i="26450" txt_f="26460">difference</offsets></sub><offsets xml_i="40349" xml_f="40358" txt_i="26460" txt_f="26469"> = 2.25, </offsets><italic><offsets xml_i="40366" xml_f="40368" txt_i="26469" txt_f="26471">SE</offsets></italic><offsets xml_i="40377" xml_f="40385" txt_i="26471" txt_f="26479"> = .03; </offsets><italic><offsets xml_i="40393" xml_f="40394" txt_i="26479" txt_f="26480">t</offsets></italic><offsets xml_i="40403" xml_f="40417" txt_i="26480" txt_f="26494">(998) = 1.88, </offsets><italic><offsets xml_i="40425" xml_f="40426" txt_i="26494" txt_f="26495">p</offsets></italic><offsets xml_i="40435" xml_f="40535" txt_i="26495" txt_f="26595"> = .182). Finally, there was a significant interaction between the image category and rating group (</offsets><italic><offsets xml_i="40543" xml_f="40544" txt_i="26595" txt_f="26596">F</offsets></italic><offsets xml_i="40553" xml_f="40569" txt_i="26596" txt_f="26612">(8,990) = 3.04, </offsets><italic><offsets xml_i="40577" xml_f="40578" txt_i="26612" txt_f="26613">p</offsets></italic><offsets xml_i="40587" xml_f="40596" txt_i="26613" txt_f="26622"> = .002, </offsets><italic><offsets xml_i="40604" xml_f="40605" txt_i="26622" txt_f="26623">η</offsets><sup><offsets xml_i="40610" xml_f="40611" txt_i="26623" txt_f="26624">2</offsets></sup><sub><offsets xml_i="40622" xml_f="40623" txt_i="26624" txt_f="26625">p</offsets></sub></italic><offsets xml_i="40638" xml_f="40647" txt_i="26625" txt_f="26634"> = .024; </offsets><xref ref-type="fig" rid="fig4-2041669518755806"><offsets xml_i="40696" xml_f="40704" txt_i="26634" txt_f="26642">Figure 4</offsets></xref><offsets xml_i="40711" xml_f="40714" txt_i="26642" txt_f="26645">). </offsets><italic><offsets xml_i="40722" xml_f="40733" txt_i="26645" txt_f="26656">Harm to you</offsets></italic><offsets xml_i="40742" xml_f="40817" txt_i="26656" txt_f="26731"> group provided fastest responses to the Deadly Threat image category (all </offsets><italic><offsets xml_i="40825" xml_f="40826" txt_i="26731" txt_f="26732">p</offsets></italic><offsets xml_i="40835" xml_f="40928" txt_i="26732" txt_f="26822">s &lt; .001), followed by equally fast responses to Direct Threat and Low Threat images (all </offsets><italic><offsets xml_i="40936" xml_f="40937" txt_i="26822" txt_f="26823">p</offsets></italic><offsets xml_i="40946" xml_f="41033" txt_i="26823" txt_f="26907">s &lt; .001, except for no statistically significant difference between Direct Threat (</offsets><italic><offsets xml_i="41041" xml_f="41042" txt_i="26907" txt_f="26908">M</offsets></italic><offsets xml_i="41051" xml_f="41060" txt_i="26908" txt_f="26917"> = 2.07, </offsets><italic><offsets xml_i="41068" xml_f="41070" txt_i="26917" txt_f="26919">SE</offsets></italic><offsets xml_i="41079" xml_f="41110" txt_i="26919" txt_f="26950"> = .04) and Low Threat images (</offsets><italic><offsets xml_i="41118" xml_f="41119" txt_i="26950" txt_f="26951">M</offsets></italic><offsets xml_i="41128" xml_f="41137" txt_i="26951" txt_f="26960"> = 2.20, </offsets><italic><offsets xml_i="41145" xml_f="41147" txt_i="26960" txt_f="26962">SE</offsets></italic><offsets xml_i="41156" xml_f="41165" txt_i="26962" txt_f="26971"> = .05), </offsets><italic><offsets xml_i="41173" xml_f="41174" txt_i="26971" txt_f="26972">t</offsets></italic><offsets xml_i="41183" xml_f="41197" txt_i="26972" txt_f="26986">(188) = 1.94, </offsets><italic><offsets xml_i="41205" xml_f="41206" txt_i="26986" txt_f="26987">p</offsets></italic><offsets xml_i="41215" xml_f="41292" txt_i="26987" txt_f="27064"> = .426), and longest RT for Indirect Threat and Threat Aftermath images—all </offsets><italic><offsets xml_i="41300" xml_f="41301" txt_i="27064" txt_f="27065">p</offsets></italic><offsets xml_i="41310" xml_f="41399" txt_i="27065" txt_f="27151">s &lt; .001, except for no statistically significant difference between Indirect Threat (</offsets><italic><offsets xml_i="41407" xml_f="41408" txt_i="27151" txt_f="27152">M</offsets></italic><offsets xml_i="41417" xml_f="41426" txt_i="27152" txt_f="27161"> = 2.46, </offsets><italic><offsets xml_i="41434" xml_f="41436" txt_i="27161" txt_f="27163">SE</offsets></italic><offsets xml_i="41445" xml_f="41475" txt_i="27163" txt_f="27193"> = .03) and Threat Aftermath (</offsets><italic><offsets xml_i="41483" xml_f="41484" txt_i="27193" txt_f="27194">M</offsets></italic><offsets xml_i="41493" xml_f="41502" txt_i="27194" txt_f="27203"> = 2.53, </offsets><italic><offsets xml_i="41510" xml_f="41512" txt_i="27203" txt_f="27205">SE</offsets></italic><offsets xml_i="41521" xml_f="41530" txt_i="27205" txt_f="27214"> = .05), </offsets><italic><offsets xml_i="41538" xml_f="41539" txt_i="27214" txt_f="27215">t</offsets></italic><offsets xml_i="41548" xml_f="41562" txt_i="27215" txt_f="27229">(257) = 1.05, </offsets><italic><offsets xml_i="41570" xml_f="41571" txt_i="27229" txt_f="27230">p</offsets></italic><offsets xml_i="41580" xml_f="41659" txt_i="27230" txt_f="27309"> = .968—as indicated by pairwise comparisons with a Bonferroni correction. For </offsets><italic><offsets xml_i="41667" xml_f="41680" txt_i="27309" txt_f="27322">Harm to other</offsets></italic><offsets xml_i="41689" xml_f="41771" txt_i="27322" txt_f="27404"> group, all pairwise comparisons with Bonferroni correction were significant (all </offsets><italic><offsets xml_i="41779" xml_f="41780" txt_i="27404" txt_f="27405">p</offsets></italic><offsets xml_i="41789" xml_f="41880" txt_i="27405" txt_f="27493">s &lt; .023) except for no statistically significant difference between the Direct Threat (</offsets><italic><offsets xml_i="41888" xml_f="41889" txt_i="27493" txt_f="27494">M</offsets></italic><offsets xml_i="41898" xml_f="41907" txt_i="27494" txt_f="27503"> = 2.16, </offsets><italic><offsets xml_i="41915" xml_f="41917" txt_i="27503" txt_f="27505">SE</offsets></italic><offsets xml_i="41926" xml_f="41950" txt_i="27505" txt_f="27529"> = .05) and Low Threat (</offsets><italic><offsets xml_i="41958" xml_f="41959" txt_i="27529" txt_f="27530">M</offsets></italic><offsets xml_i="41968" xml_f="41977" txt_i="27530" txt_f="27539"> = 2.27, </offsets><italic><offsets xml_i="41985" xml_f="41987" txt_i="27539" txt_f="27541">SE</offsets></italic><offsets xml_i="41996" xml_f="42004" txt_i="27541" txt_f="27549"> = .06; </offsets><italic><offsets xml_i="42012" xml_f="42013" txt_i="27549" txt_f="27550">t</offsets></italic><offsets xml_i="42022" xml_f="42036" txt_i="27550" txt_f="27564">(188) = 1.59, </offsets><italic><offsets xml_i="42044" xml_f="42045" txt_i="27564" txt_f="27565">p</offsets></italic><offsets xml_i="42054" xml_f="42279" txt_i="27565" txt_f="27790"> = .695) categories. Participants rated Deadly Threat images the fastest, followed by equally fast Direct and Low Threat images, followed by Indirect Threat and finally Threat Aftermath images with longest RTs. Similarly for </offsets><italic><offsets xml_i="42287" xml_f="42296" txt_i="27790" txt_f="27799">Past harm</offsets></italic><offsets xml_i="42305" xml_f="42389" txt_i="27799" txt_f="27883"> group, all pairwise comparisons with a Bonferroni correction were significant (all </offsets><italic><offsets xml_i="42397" xml_f="42398" txt_i="27883" txt_f="27884">p</offsets></italic><offsets xml_i="42407" xml_f="42476" txt_i="27884" txt_f="27950">s &lt; .020), except for the comparison between the Indirect Threat (</offsets><italic><offsets xml_i="42484" xml_f="42485" txt_i="27950" txt_f="27951">M</offsets></italic><offsets xml_i="42494" xml_f="42503" txt_i="27951" txt_f="27960"> = 2.39, </offsets><italic><offsets xml_i="42511" xml_f="42513" txt_i="27960" txt_f="27962">SE</offsets></italic><offsets xml_i="42522" xml_f="42546" txt_i="27962" txt_f="27986"> = .04) and Low Threat (</offsets><italic><offsets xml_i="42554" xml_f="42555" txt_i="27986" txt_f="27987">M</offsets></italic><offsets xml_i="42564" xml_f="42573" txt_i="27987" txt_f="27996"> = 2.30, </offsets><italic><offsets xml_i="42581" xml_f="42583" txt_i="27996" txt_f="27998">SE</offsets></italic><offsets xml_i="42592" xml_f="42617" txt_i="27998" txt_f="28023"> = .06) image categories </offsets><italic><offsets xml_i="42625" xml_f="42626" txt_i="28023" txt_f="28024">t</offsets></italic><offsets xml_i="42635" xml_f="42649" txt_i="28024" txt_f="28038">(246) = 1.26, </offsets><italic><offsets xml_i="42657" xml_f="42658" txt_i="28038" txt_f="28039">p</offsets></italic><offsets xml_i="42667" xml_f="42866" txt_i="28039" txt_f="28238"> = .907. Participants again rated the Deadly Threat images the fastest followed by Direct Threat, equally slower Indirect Threat and Low Threat images and finally the slowest Threat Aftermath images.</offsets></p></sec></sec><sec id="sec16-2041669518755806"><title><offsets xml_i="42922" xml_f="42929" txt_i="28241" txt_f="28248">Study 2</offsets></title><p><offsets xml_i="42940" xml_f="43219" txt_i="28249" txt_f="28528">Prior to analyses, valence ratings were reverse coded such that lower ratings would correspond to negative valence, while higher ratings would correspond to positive valence. Interrater reliability for both valence and arousal ratings was excellent (.943 and .959, respectively).</offsets><sup><xref ref-type="fn" rid="fn3-2041669518755806"><offsets xml_i="43271" xml_f="43272" txt_i="28528" txt_f="28529">3</offsets></xref></sup></p><p><offsets xml_i="43292" xml_f="43357" txt_i="28530" txt_f="28595">The relationship between valence and arousal ratings is shown in </offsets><xref ref-type="fig" rid="fig5-2041669518755806"><offsets xml_i="43406" xml_f="43414" txt_i="28595" txt_f="28603">Figure 5</offsets></xref><offsets xml_i="43421" xml_f="43527" txt_i="28603" txt_f="28709">. Overall, there was a strong negative linear relationship between valence and arousal ratings, Pearson’s </offsets><italic><offsets xml_i="43535" xml_f="43536" txt_i="28709" txt_f="28710">r</offsets></italic><offsets xml_i="43545" xml_f="43555" txt_i="28710" txt_f="28720"> = −.816, </offsets><italic><offsets xml_i="43563" xml_f="43564" txt_i="28720" txt_f="28721">p</offsets></italic><offsets xml_i="43573" xml_f="43640" txt_i="28721" txt_f="28785"> &lt; .001. Low Threat images had the highest mean valence rating (</offsets><italic><offsets xml_i="43648" xml_f="43649" txt_i="28785" txt_f="28786">M</offsets></italic><offsets xml_i="43658" xml_f="43667" txt_i="28786" txt_f="28795"> = 4.21, </offsets><italic><offsets xml_i="43675" xml_f="43677" txt_i="28795" txt_f="28797">SE</offsets></italic><offsets xml_i="43686" xml_f="43732" txt_i="28797" txt_f="28843"> = .07), followed by Threat Aftermath images (</offsets><italic><offsets xml_i="43740" xml_f="43741" txt_i="28843" txt_f="28844">M</offsets></italic><offsets xml_i="43750" xml_f="43759" txt_i="28844" txt_f="28853"> = 3.30, </offsets><italic><offsets xml_i="43767" xml_f="43769" txt_i="28853" txt_f="28855">SE</offsets></italic><offsets xml_i="43778" xml_f="43809" txt_i="28855" txt_f="28886"> = .06), Direct Threat images (</offsets><italic><offsets xml_i="43817" xml_f="43818" txt_i="28886" txt_f="28887">M</offsets></italic><offsets xml_i="43827" xml_f="43836" txt_i="28887" txt_f="28896"> = 3.10, </offsets><italic><offsets xml_i="43844" xml_f="43846" txt_i="28896" txt_f="28898">SE</offsets></italic><offsets xml_i="43855" xml_f="43888" txt_i="28898" txt_f="28931"> = .05), Indirect Threat images (</offsets><italic><offsets xml_i="43896" xml_f="43897" txt_i="28931" txt_f="28932">M</offsets></italic><offsets xml_i="43906" xml_f="43915" txt_i="28932" txt_f="28941"> = 2.76, </offsets><italic><offsets xml_i="43923" xml_f="43925" txt_i="28941" txt_f="28943">SD</offsets></italic><offsets xml_i="43934" xml_f="43969" txt_i="28943" txt_f="28978"> = .04), and Deadly Threat images (</offsets><italic><offsets xml_i="43977" xml_f="43978" txt_i="28978" txt_f="28979">M</offsets></italic><offsets xml_i="43987" xml_f="43996" txt_i="28979" txt_f="28988"> = 2.14, </offsets><italic><offsets xml_i="44004" xml_f="44006" txt_i="28988" txt_f="28990">SD</offsets></italic><offsets xml_i="44015" xml_f="44107" txt_i="28990" txt_f="29082"> = .08). On the arousal dimension, Deadly Threat images were rated as most highly arousing (</offsets><italic><offsets xml_i="44115" xml_f="44116" txt_i="29082" txt_f="29083">M</offsets></italic><offsets xml_i="44125" xml_f="44134" txt_i="29083" txt_f="29092"> = 5.57, </offsets><italic><offsets xml_i="44142" xml_f="44144" txt_i="29092" txt_f="29094">SE</offsets></italic><offsets xml_i="44153" xml_f="44198" txt_i="29094" txt_f="29139"> = .08), followed by Indirect Threat images (</offsets><italic><offsets xml_i="44206" xml_f="44207" txt_i="29139" txt_f="29140">M</offsets></italic><offsets xml_i="44216" xml_f="44225" txt_i="29140" txt_f="29149"> = 4.99, </offsets><italic><offsets xml_i="44233" xml_f="44235" txt_i="29149" txt_f="29151">SE</offsets></italic><offsets xml_i="44244" xml_f="44275" txt_i="29151" txt_f="29182"> = .04), Direct Threat images (</offsets><italic><offsets xml_i="44283" xml_f="44284" txt_i="29182" txt_f="29183">M</offsets></italic><offsets xml_i="44293" xml_f="44302" txt_i="29183" txt_f="29192"> = 4.57, </offsets><italic><offsets xml_i="44310" xml_f="44312" txt_i="29192" txt_f="29194">SE</offsets></italic><offsets xml_i="44321" xml_f="44355" txt_i="29194" txt_f="29228"> = .05), Threat Aftermath images (</offsets><italic><offsets xml_i="44363" xml_f="44364" txt_i="29228" txt_f="29229">M</offsets></italic><offsets xml_i="44373" xml_f="44382" txt_i="29229" txt_f="29238"> = 4.28, </offsets><italic><offsets xml_i="44390" xml_f="44392" txt_i="29238" txt_f="29240">SE</offsets></italic><offsets xml_i="44401" xml_f="44433" txt_i="29240" txt_f="29272"> = .06), and Low Threat images (</offsets><italic><offsets xml_i="44441" xml_f="44442" txt_i="29272" txt_f="29273">M</offsets></italic><offsets xml_i="44451" xml_f="44460" txt_i="29273" txt_f="29282"> = 3.48, </offsets><italic><offsets xml_i="44468" xml_f="44470" txt_i="29282" txt_f="29284">SE</offsets></italic><offsets xml_i="44479" xml_f="44488" txt_i="29284" txt_f="29293"> = .07).
</offsets><fig id="fig5-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="44567" xml_f="44576" txt_i="29293" txt_f="29302">Figure 5.</offsets></label><caption><p><offsets xml_i="44596" xml_f="44720" txt_i="29302" txt_f="29426">Study 2 results. The relationship between valence and arousal ratings, with valence (measured on a 1–7 Likert scale) on the </offsets><italic><offsets xml_i="44728" xml_f="44729" txt_i="29426" txt_f="29427">x</offsets></italic><offsets xml_i="44738" xml_f="44801" txt_i="29427" txt_f="29490">-axis and arousal (also measured on a 1–7 Likert scale) on the </offsets><italic><offsets xml_i="44809" xml_f="44810" txt_i="29490" txt_f="29491">y</offsets></italic><offsets xml_i="44819" xml_f="44868" txt_i="29491" txt_f="29540">-axis. The colors correspond to image categories.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig5"></graphic></fig></p></sec><sec id="sec17-2041669518755806"><title><offsets xml_i="45000" xml_f="45054" txt_i="29543" txt_f="29597">Comparison of Line-Drawn and Color Photographic Scenes</offsets></title><p><offsets xml_i="45065" xml_f="45163" txt_i="29598" txt_f="29696">In order to validate our findings, we also reanalyzed the data collected and reported previously (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="45215" xml_f="45235" txt_i="29696" txt_f="29716">Kveraga et al., 2015</offsets></xref><offsets xml_i="45242" xml_f="45875" txt_i="29716" txt_f="30349">) for the color photographic images using the five image categories described above. In the previous study, 27 participants were randomly assigned to rate all color photographic images answering one of three questions: (a) How much harm might you be about to suffer in this scene if this was your view of the scene?; (b) How much harm might someone (not you) be about to suffer in this scene?; and (c) How much harm might someone (not you) have already suffered in this scene? Another 33 participants were asked to rate all the color photographic images on valence and arousal dimensions using 6-point Likert scales (for details see </offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="45927" xml_f="45947" txt_i="30349" txt_f="30369">Kveraga et al., 2015</offsets></xref><offsets xml_i="45954" xml_f="45956" txt_i="30369" txt_f="30371">).</offsets></p><sec id="sec18-2041669518755806"><title><offsets xml_i="46000" xml_f="46007" txt_i="30372" txt_f="30379">Study 1</offsets></title><p><offsets xml_i="46018" xml_f="46246" txt_i="30380" txt_f="30608">A 3 (rating group) × 5 (image category) repeated-measures ANOVA (using Type II calculation for obtaining sums of squares) on color photographic scenes revealed similar pattern of results as reported for the line-drawing images (</offsets><xref ref-type="fig" rid="fig6-2041669518755806"><offsets xml_i="46295" xml_f="46303" txt_i="30608" txt_f="30616">Figure 6</offsets></xref><offsets xml_i="46310" xml_f="46373" txt_i="30616" txt_f="30679">). Descriptive statistics and results summary are presented in </offsets><xref ref-type="table" rid="table1-2041669518755806"><offsets xml_i="46426" xml_f="46433" txt_i="30679" txt_f="30686">Table 1</offsets></xref><offsets xml_i="46440" xml_f="46442" txt_i="30686" txt_f="30688">.
</offsets><fig id="fig6-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="46521" xml_f="46530" txt_i="30688" txt_f="30697">Figure 6.</offsets></label><caption><p><offsets xml_i="46550" xml_f="47282" txt_i="30697" txt_f="31429">Study 1 validation results. (a) Results of the color photographic scene ratings (left). The three panels show the results from the three rating groups. Participants in Group 1 (left panel) were asked to rate all images in terms of potential harm to them personally; participants in Group 2 (middle panel) were asked to rate all images in terms of potential harm to someone else; participants in Group 3 (right panel) were asked to rate all images in terms of past harm, but no present harm. 500 images were presented in a randomized mixed sequence. Results of the line drawings of the matching scenes (Study 1) are presented on the right for the comparison. (b) Results of the RT. The error bars indicate standard error of the mean.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig6"></graphic></fig><offsets xml_i="47364" xml_f="47365" txt_i="31430" txt_f="31431">
</offsets><table-wrap id="table1-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="47453" xml_f="47461" txt_i="31431" txt_f="31439">Table 1.</offsets></label><caption><p><offsets xml_i="47481" xml_f="47742" txt_i="31439" txt_f="31700">Results Summary Tables (a) and Descriptive Statistics (b) for the 3(Rating Group) × 5(Image Category) Repeated Measures ANOVA for Line Drawings (Study 1) and Matching Color Photographic Images (Validation Analysis for Study 1 Ran on Data Previously Reported in </offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="47794" xml_f="47814" txt_i="31700" txt_f="31720">Kveraga et al., 2015</offsets></xref><offsets xml_i="47821" xml_f="47823" txt_i="31720" txt_f="31722">).</offsets></p></caption><alternatives><graphic specific-use="table1-2041669518755806" xlink:href="10.1177_2041669518755806-table1"></graphic><table frame="hsides" rules="groups"><thead align="left" valign="top"><tr><th rowspan="1" colspan="1"><offsets xml_i="48056" xml_f="48057" txt_i="31723" txt_f="31724">
</offsets><bold><offsets xml_i="48063" xml_f="48066" txt_i="31724" txt_f="31727">(a)</offsets></bold><offsets xml_i="48073" xml_f="48074" txt_i="31727" txt_f="31728">
</offsets></th><th colspan="6" rowspan="1"><offsets xml_i="48107" xml_f="48120" txt_i="31728" txt_f="31741">Line drawings</offsets><hr></hr></th><th colspan="5" rowspan="1"><offsets xml_i="48162" xml_f="48179" txt_i="31741" txt_f="31758">Color photographs</offsets><hr></hr></th></tr><tr><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"><offsets xml_i="48296" xml_f="48297" txt_i="31758" txt_f="31759">
</offsets><italic><offsets xml_i="48305" xml_f="48307" txt_i="31759" txt_f="31761">df</offsets></italic><offsets xml_i="48316" xml_f="48317" txt_i="31761" txt_f="31762">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48350" xml_f="48351" txt_i="31762" txt_f="31763">
</offsets><italic><offsets xml_i="48359" xml_f="48360" txt_i="31763" txt_f="31764">F</offsets></italic><offsets xml_i="48369" xml_f="48370" txt_i="31764" txt_f="31765">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48403" xml_f="48407" txt_i="31765" txt_f="31769">Sig.</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48440" xml_f="48441" txt_i="31769" txt_f="31770">η</offsets><sup><offsets xml_i="48446" xml_f="48447" txt_i="31770" txt_f="31771">2</offsets></sup></th><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"><offsets xml_i="48552" xml_f="48553" txt_i="31771" txt_f="31772">
</offsets><italic><offsets xml_i="48561" xml_f="48563" txt_i="31772" txt_f="31774">df</offsets></italic><offsets xml_i="48572" xml_f="48573" txt_i="31774" txt_f="31775">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48606" xml_f="48607" txt_i="31775" txt_f="31776">
</offsets><italic><offsets xml_i="48615" xml_f="48616" txt_i="31776" txt_f="31777">F</offsets></italic><offsets xml_i="48625" xml_f="48626" txt_i="31777" txt_f="31778">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48659" xml_f="48663" txt_i="31778" txt_f="31782">Sig.</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="48696" xml_f="48697" txt_i="31782" txt_f="31783">η</offsets><sup><offsets xml_i="48702" xml_f="48703" txt_i="31783" txt_f="31784">2</offsets></sup></th></tr></thead><tbody align="left" valign="top"><tr><td rowspan="1" colspan="1"><offsets xml_i="48792" xml_f="48798" txt_i="31784" txt_f="31790">Rating</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="48831" xml_f="48836" txt_i="31791" txt_f="31796">Group</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="48869" xml_f="48874" txt_i="31797" txt_f="31802">2,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="48907" xml_f="48913" txt_i="31803" txt_f="31809">122.48</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="48946" xml_f="48954" txt_i="31810" txt_f="31815">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="48987" xml_f="48991" txt_i="31816" txt_f="31820">.198</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49024" xml_f="49030" txt_i="31821" txt_f="31827">Rating</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49063" xml_f="49068" txt_i="31828" txt_f="31833">Group</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49101" xml_f="49106" txt_i="31834" txt_f="31839">2,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49139" xml_f="49145" txt_i="31840" txt_f="31846">159.72</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49178" xml_f="49186" txt_i="31847" txt_f="31852">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49219" xml_f="49223" txt_i="31853" txt_f="31857">.244</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="49298" xml_f="49306" txt_i="31859" txt_f="31867">Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49339" xml_f="49344" txt_i="31868" txt_f="31873">4,495</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49377" xml_f="49383" txt_i="31874" txt_f="31880">253.31</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49416" xml_f="49424" txt_i="31881" txt_f="31886">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49457" xml_f="49461" txt_i="31887" txt_f="31891">.672</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="49527" xml_f="49535" txt_i="31893" txt_f="31901">Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49568" xml_f="49573" txt_i="31902" txt_f="31907">4,495</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49606" xml_f="49612" txt_i="31908" txt_f="31914">114.95</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49645" xml_f="49653" txt_i="31915" txt_f="31920">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49686" xml_f="49690" txt_i="31921" txt_f="31925">.482</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="49765" xml_f="49781" txt_i="31927" txt_f="31943">Group × Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49814" xml_f="49819" txt_i="31944" txt_f="31949">8,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49852" xml_f="49858" txt_i="31950" txt_f="31956">445.96</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49891" xml_f="49899" txt_i="31957" txt_f="31962">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="49932" xml_f="49936" txt_i="31963" txt_f="31967">.783</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="50002" xml_f="50018" txt_i="31969" txt_f="31985">Group × Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50051" xml_f="50056" txt_i="31986" txt_f="31991">8,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50089" xml_f="50095" txt_i="31992" txt_f="31998">114.62</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50128" xml_f="50136" txt_i="31999" txt_f="32004">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50169" xml_f="50173" txt_i="32005" txt_f="32009">.481</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="50215" xml_f="50229" txt_i="32010" txt_f="32024">Reaction times</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50262" xml_f="50267" txt_i="32025" txt_f="32030">Group</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50300" xml_f="50305" txt_i="32031" txt_f="32036">2,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50338" xml_f="50343" txt_i="32037" txt_f="32042">14.82</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50376" xml_f="50384" txt_i="32043" txt_f="32048">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50417" xml_f="50421" txt_i="32049" txt_f="32053">.029</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50454" xml_f="50468" txt_i="32054" txt_f="32068">Reaction times</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50501" xml_f="50506" txt_i="32069" txt_f="32074">Group</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50539" xml_f="50544" txt_i="32075" txt_f="32080">2,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50577" xml_f="50582" txt_i="32081" txt_f="32086">32.81</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50615" xml_f="50623" txt_i="32087" txt_f="32092">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50656" xml_f="50660" txt_i="32093" txt_f="32097">.062</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="50735" xml_f="50743" txt_i="32099" txt_f="32107">Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50776" xml_f="50781" txt_i="32108" txt_f="32113">4,495</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50814" xml_f="50819" txt_i="32114" txt_f="32119">50.39</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50852" xml_f="50860" txt_i="32120" txt_f="32125">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="50893" xml_f="50897" txt_i="32126" txt_f="32130">.289</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="50963" xml_f="50971" txt_i="32132" txt_f="32140">Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51004" xml_f="51009" txt_i="32141" txt_f="32146">4,495</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51042" xml_f="51047" txt_i="32147" txt_f="32152">20.66</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51080" xml_f="51088" txt_i="32153" txt_f="32158">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51121" xml_f="51125" txt_i="32159" txt_f="32163">.143</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="51200" xml_f="51216" txt_i="32165" txt_f="32181">Group × Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51249" xml_f="51254" txt_i="32182" txt_f="32187">8,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51287" xml_f="51291" txt_i="32188" txt_f="32192">3.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51324" xml_f="51328" txt_i="32193" txt_f="32197">.002</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51361" xml_f="51365" txt_i="32198" txt_f="32202">.024</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="51431" xml_f="51447" txt_i="32204" txt_f="32220">Group × Category</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51480" xml_f="51485" txt_i="32221" txt_f="32226">8,990</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51518" xml_f="51522" txt_i="32227" txt_f="32231">6.37</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51555" xml_f="51563" txt_i="32232" txt_f="32237">&lt;.001</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="51596" xml_f="51600" txt_i="32238" txt_f="32242">.049</offsets></td></tr></tbody></table><table frame="hsides" rules="groups"><thead align="left" valign="top"><tr><th colspan="12" rowspan="1"><offsets xml_i="51729" xml_f="51730" txt_i="32243" txt_f="32244">
</offsets><bold><offsets xml_i="51736" xml_f="51739" txt_i="32244" txt_f="32247">(b)</offsets></bold><offsets xml_i="51746" xml_f="51747" txt_i="32247" txt_f="32248">
</offsets><hr></hr><offsets xml_i="51756" xml_f="51757" txt_i="32248" txt_f="32249">
</offsets></th></tr><tr><th rowspan="1" colspan="1"></th><th colspan="6" rowspan="1"><offsets xml_i="51832" xml_f="51845" txt_i="32249" txt_f="32262">Line drawings</offsets><hr></hr></th><th colspan="5" rowspan="1"><offsets xml_i="51887" xml_f="51904" txt_i="32262" txt_f="32279">Color photographs</offsets><hr></hr></th></tr><tr><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"></th><th colspan="2" rowspan="1"><offsets xml_i="52021" xml_f="52027" txt_i="32279" txt_f="32285">Rating</offsets><hr></hr></th><th colspan="2" rowspan="1"><offsets xml_i="52069" xml_f="52083" txt_i="32285" txt_f="32299">Reaction times</offsets><hr></hr></th><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"></th><th colspan="2" rowspan="1"><offsets xml_i="52191" xml_f="52196" txt_i="32299" txt_f="32304">Ratin</offsets><hr></hr><offsets xml_i="52205" xml_f="52206" txt_i="32304" txt_f="32305">g</offsets></th><th colspan="2" rowspan="1"><offsets xml_i="52239" xml_f="52253" txt_i="32305" txt_f="32319">Reaction times</offsets><hr></hr></th></tr><tr><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"><offsets xml_i="52337" xml_f="52342" txt_i="32319" txt_f="32324">Group</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52375" xml_f="52376" txt_i="32324" txt_f="32325">
</offsets><italic><offsets xml_i="52384" xml_f="52385" txt_i="32325" txt_f="32326">M</offsets></italic><offsets xml_i="52394" xml_f="52395" txt_i="32326" txt_f="32327">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52428" xml_f="52429" txt_i="32327" txt_f="32328">
</offsets><italic><offsets xml_i="52437" xml_f="52439" txt_i="32328" txt_f="32330">SE</offsets></italic><offsets xml_i="52448" xml_f="52449" txt_i="32330" txt_f="32331">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52482" xml_f="52483" txt_i="32331" txt_f="32332">
</offsets><italic><offsets xml_i="52491" xml_f="52492" txt_i="32332" txt_f="32333">M</offsets></italic><offsets xml_i="52501" xml_f="52502" txt_i="32333" txt_f="32334">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52535" xml_f="52536" txt_i="32334" txt_f="32335">
</offsets><italic><offsets xml_i="52544" xml_f="52546" txt_i="32335" txt_f="32337">SE</offsets></italic><offsets xml_i="52555" xml_f="52556" txt_i="32337" txt_f="32338">
</offsets></th><th rowspan="1" colspan="1"></th><th rowspan="1" colspan="1"><offsets xml_i="52622" xml_f="52627" txt_i="32338" txt_f="32343">Group</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52660" xml_f="52661" txt_i="32343" txt_f="32344">
</offsets><italic><offsets xml_i="52669" xml_f="52670" txt_i="32344" txt_f="32345">M</offsets></italic><offsets xml_i="52679" xml_f="52680" txt_i="32345" txt_f="32346">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52713" xml_f="52714" txt_i="32346" txt_f="32347">
</offsets><italic><offsets xml_i="52722" xml_f="52724" txt_i="32347" txt_f="32349">SE</offsets></italic><offsets xml_i="52733" xml_f="52734" txt_i="32349" txt_f="32350">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52767" xml_f="52768" txt_i="32350" txt_f="32351">
</offsets><italic><offsets xml_i="52776" xml_f="52777" txt_i="32351" txt_f="32352">M</offsets></italic><offsets xml_i="52786" xml_f="52787" txt_i="32352" txt_f="32353">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="52820" xml_f="52821" txt_i="32353" txt_f="32354">
</offsets><italic><offsets xml_i="52829" xml_f="52831" txt_i="32354" txt_f="32356">SE</offsets></italic><offsets xml_i="52840" xml_f="52841" txt_i="32356" txt_f="32357">
</offsets></th></tr></thead><tbody align="left" valign="top"><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="52957" xml_f="52968" txt_i="32358" txt_f="32369">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53001" xml_f="53005" txt_i="32370" txt_f="32374">3.31</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53038" xml_f="53042" txt_i="32375" txt_f="32379">0.03</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53075" xml_f="53079" txt_i="32380" txt_f="32384">2.20</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53112" xml_f="53116" txt_i="32385" txt_f="32389">0.02</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="53182" xml_f="53193" txt_i="32391" txt_f="32402">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53226" xml_f="53230" txt_i="32403" txt_f="32407">3.02</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53263" xml_f="53267" txt_i="32408" txt_f="32412">0.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53300" xml_f="53304" txt_i="32413" txt_f="32417">2.24</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53337" xml_f="53341" txt_i="32418" txt_f="32422">0.02</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="53416" xml_f="53429" txt_i="32424" txt_f="32437">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53462" xml_f="53466" txt_i="32438" txt_f="32442">3.56</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53499" xml_f="53503" txt_i="32443" txt_f="32447">0.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53536" xml_f="53540" txt_i="32448" txt_f="32452">2.33</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53573" xml_f="53577" txt_i="32453" txt_f="32457">0.02</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="53643" xml_f="53656" txt_i="32459" txt_f="32472">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53689" xml_f="53693" txt_i="32473" txt_f="32477">3.45</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53726" xml_f="53730" txt_i="32478" txt_f="32482">0.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53763" xml_f="53767" txt_i="32483" txt_f="32487">2.41</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53800" xml_f="53804" txt_i="32488" txt_f="32492">0.03</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="53879" xml_f="53888" txt_i="32494" txt_f="32503">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53921" xml_f="53925" txt_i="32504" txt_f="32508">3.38</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53958" xml_f="53962" txt_i="32509" txt_f="32513">0.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="53995" xml_f="53999" txt_i="32514" txt_f="32518">2.25</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54032" xml_f="54036" txt_i="32519" txt_f="32523">0.03</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="54102" xml_f="54111" txt_i="32525" txt_f="32534">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54144" xml_f="54148" txt_i="32535" txt_f="32539">2.76</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54181" xml_f="54185" txt_i="32540" txt_f="32544">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54218" xml_f="54222" txt_i="32545" txt_f="32549">2.22</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54255" xml_f="54259" txt_i="32550" txt_f="32554">0.03</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="54334" xml_f="54335" txt_i="32556" txt_f="32557">
</offsets><bold><offsets xml_i="54341" xml_f="54349" txt_i="32557" txt_f="32565">Category</offsets></bold><offsets xml_i="54356" xml_f="54357" txt_i="32565" txt_f="32566">
</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="54555" xml_f="54556" txt_i="32572" txt_f="32573">
</offsets><bold><offsets xml_i="54562" xml_f="54570" txt_i="32573" txt_f="32581">Category</offsets></bold><offsets xml_i="54577" xml_f="54578" txt_i="32581" txt_f="32582">
</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="54785" xml_f="54798" txt_i="32588" txt_f="32601">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54831" xml_f="54835" txt_i="32602" txt_f="32606">4.95</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54868" xml_f="54872" txt_i="32607" txt_f="32611">0.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54905" xml_f="54909" txt_i="32612" txt_f="32616">1.82</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="54942" xml_f="54946" txt_i="32617" txt_f="32621">0.06</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="55012" xml_f="55025" txt_i="32623" txt_f="32636">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55058" xml_f="55062" txt_i="32637" txt_f="32641">4.17</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55095" xml_f="55099" txt_i="32642" txt_f="32646">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55132" xml_f="55136" txt_i="32647" txt_f="32651">2.14</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55169" xml_f="55173" txt_i="32652" txt_f="32656">0.06</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="55248" xml_f="55261" txt_i="32658" txt_f="32671">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55294" xml_f="55298" txt_i="32672" txt_f="32676">3.80</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55331" xml_f="55335" txt_i="32677" txt_f="32681">0.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55368" xml_f="55372" txt_i="32682" txt_f="32686">2.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55405" xml_f="55409" txt_i="32687" txt_f="32691">0.04</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="55475" xml_f="55488" txt_i="32693" txt_f="32706">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55521" xml_f="55525" txt_i="32707" txt_f="32711">3.02</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55558" xml_f="55562" txt_i="32712" txt_f="32716">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55595" xml_f="55599" txt_i="32717" txt_f="32721">2.18</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55632" xml_f="55636" txt_i="32722" txt_f="32726">0.04</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="55711" xml_f="55726" txt_i="32728" txt_f="32743">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55759" xml_f="55763" txt_i="32744" txt_f="32748">3.70</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55796" xml_f="55800" txt_i="32749" txt_f="32753">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55833" xml_f="55837" txt_i="32754" txt_f="32758">2.45</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55870" xml_f="55874" txt_i="32759" txt_f="32763">0.03</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="55940" xml_f="55955" txt_i="32765" txt_f="32780">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="55988" xml_f="55992" txt_i="32781" txt_f="32785">3.46</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56025" xml_f="56029" txt_i="32786" txt_f="32790">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56062" xml_f="56066" txt_i="32791" txt_f="32795">2.50</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56099" xml_f="56103" txt_i="32796" txt_f="32800">0.03</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="56178" xml_f="56194" txt_i="32802" txt_f="32818">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56227" xml_f="56231" txt_i="32819" txt_f="32823">3.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56264" xml_f="56268" txt_i="32824" txt_f="32828">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56301" xml_f="56305" txt_i="32829" txt_f="32833">2.67</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56338" xml_f="56342" txt_i="32834" txt_f="32838">0.04</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="56408" xml_f="56424" txt_i="32840" txt_f="32856">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56457" xml_f="56461" txt_i="32857" txt_f="32861">3.01</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56494" xml_f="56498" txt_i="32862" txt_f="32866">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56531" xml_f="56535" txt_i="32867" txt_f="32871">2.49</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56568" xml_f="56572" txt_i="32872" txt_f="32876">0.05</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="56647" xml_f="56657" txt_i="32878" txt_f="32888">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56690" xml_f="56694" txt_i="32889" txt_f="32893">1.58</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56727" xml_f="56731" txt_i="32894" txt_f="32898">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56764" xml_f="56768" txt_i="32899" txt_f="32903">2.26</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56801" xml_f="56805" txt_i="32904" txt_f="32908">0.05</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="56871" xml_f="56881" txt_i="32910" txt_f="32920">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56914" xml_f="56918" txt_i="32921" txt_f="32925">1.65</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56951" xml_f="56955" txt_i="32926" txt_f="32930">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="56988" xml_f="56992" txt_i="32931" txt_f="32935">2.15</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57025" xml_f="57029" txt_i="32936" txt_f="32940">0.05</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="57071" xml_f="57072" txt_i="32941" txt_f="32942">
</offsets><bold><offsets xml_i="57078" xml_f="57083" txt_i="32942" txt_f="32947">Group</offsets></bold><offsets xml_i="57090" xml_f="57091" txt_i="32947" txt_f="32948">
</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57124" xml_f="57125" txt_i="32949" txt_f="32950">
</offsets><bold><offsets xml_i="57131" xml_f="57139" txt_i="32950" txt_f="32958">Category</offsets></bold><offsets xml_i="57146" xml_f="57147" txt_i="32958" txt_f="32959">
</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="57312" xml_f="57313" txt_i="32964" txt_f="32965">
</offsets><bold><offsets xml_i="57319" xml_f="57324" txt_i="32965" txt_f="32970">Group</offsets></bold><offsets xml_i="57331" xml_f="57332" txt_i="32970" txt_f="32971">
</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57365" xml_f="57366" txt_i="32972" txt_f="32973">
</offsets><bold><offsets xml_i="57372" xml_f="57380" txt_i="32973" txt_f="32981">Category</offsets></bold><offsets xml_i="57387" xml_f="57388" txt_i="32981" txt_f="32982">
</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="57562" xml_f="57575" txt_i="32987" txt_f="33000">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57608" xml_f="57619" txt_i="33001" txt_f="33012">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57652" xml_f="57656" txt_i="33013" txt_f="33017">5.36</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57689" xml_f="57693" txt_i="33018" txt_f="33022">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57726" xml_f="57730" txt_i="33023" txt_f="33027">1.76</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57763" xml_f="57767" txt_i="33028" txt_f="33032">0.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57800" xml_f="57813" txt_i="33033" txt_f="33046">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57846" xml_f="57857" txt_i="33047" txt_f="33058">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57890" xml_f="57894" txt_i="33059" txt_f="33063">4.68</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57927" xml_f="57931" txt_i="33064" txt_f="33068">0.11</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="57964" xml_f="57968" txt_i="33069" txt_f="33073">2.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58001" xml_f="58005" txt_i="33074" txt_f="33078">0.07</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="58080" xml_f="58093" txt_i="33080" txt_f="33093">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58126" xml_f="58130" txt_i="33094" txt_f="33098">5.33</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58163" xml_f="58167" txt_i="33099" txt_f="33103">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58200" xml_f="58204" txt_i="33104" txt_f="33108">1.91</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58237" xml_f="58241" txt_i="33109" txt_f="33113">0.07</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="58307" xml_f="58320" txt_i="33115" txt_f="33128">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58353" xml_f="58357" txt_i="33129" txt_f="33133">4.78</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58390" xml_f="58394" txt_i="33134" txt_f="33138">0.12</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58427" xml_f="58431" txt_i="33139" txt_f="33143">2.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58464" xml_f="58468" txt_i="33144" txt_f="33148">0.09</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="58543" xml_f="58552" txt_i="33150" txt_f="33159">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58585" xml_f="58589" txt_i="33160" txt_f="33164">4.15</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58622" xml_f="58626" txt_i="33165" txt_f="33169">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58659" xml_f="58663" txt_i="33170" txt_f="33174">1.80</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58696" xml_f="58700" txt_i="33175" txt_f="33179">0.07</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="58766" xml_f="58775" txt_i="33181" txt_f="33190">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58808" xml_f="58812" txt_i="33191" txt_f="33195">3.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58845" xml_f="58849" txt_i="33196" txt_f="33200">0.13</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58882" xml_f="58886" txt_i="33201" txt_f="33205">2.22</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="58919" xml_f="58923" txt_i="33206" txt_f="33210">0.07</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="58965" xml_f="58978" txt_i="33211" txt_f="33224">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59011" xml_f="59022" txt_i="33225" txt_f="33236">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59055" xml_f="59059" txt_i="33237" txt_f="33241">4.70</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59092" xml_f="59096" txt_i="33242" txt_f="33246">0.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59129" xml_f="59133" txt_i="33247" txt_f="33251">2.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59166" xml_f="59170" txt_i="33252" txt_f="33256">0.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59203" xml_f="59216" txt_i="33257" txt_f="33270">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59249" xml_f="59260" txt_i="33271" txt_f="33282">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59293" xml_f="59297" txt_i="33283" txt_f="33287">3.42</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59330" xml_f="59334" txt_i="33288" txt_f="33292">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59367" xml_f="59371" txt_i="33293" txt_f="33297">2.29</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59404" xml_f="59408" txt_i="33298" txt_f="33302">0.05</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="59483" xml_f="59496" txt_i="33304" txt_f="33317">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59529" xml_f="59533" txt_i="33318" txt_f="33322">3.66</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59566" xml_f="59570" txt_i="33323" txt_f="33327">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59603" xml_f="59607" txt_i="33328" txt_f="33332">2.16</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59640" xml_f="59644" txt_i="33333" txt_f="33337">0.05</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="59710" xml_f="59723" txt_i="33339" txt_f="33352">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59756" xml_f="59760" txt_i="33353" txt_f="33357">3.56</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59793" xml_f="59797" txt_i="33358" txt_f="33362">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59830" xml_f="59834" txt_i="33363" txt_f="33367">2.24</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59867" xml_f="59871" txt_i="33368" txt_f="33372">0.06</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="59946" xml_f="59955" txt_i="33374" txt_f="33383">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="59988" xml_f="59992" txt_i="33384" txt_f="33388">3.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60025" xml_f="60029" txt_i="33389" txt_f="33393">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60062" xml_f="60066" txt_i="33394" txt_f="33398">2.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60099" xml_f="60103" txt_i="33399" txt_f="33403">0.05</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="60169" xml_f="60178" txt_i="33405" txt_f="33414">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60211" xml_f="60215" txt_i="33415" txt_f="33419">2.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60248" xml_f="60252" txt_i="33420" txt_f="33424">0.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60285" xml_f="60289" txt_i="33425" txt_f="33429">2.00</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60322" xml_f="60326" txt_i="33430" txt_f="33434">0.05</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="60368" xml_f="60383" txt_i="33435" txt_f="33450">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60416" xml_f="60427" txt_i="33451" txt_f="33462">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60460" xml_f="60464" txt_i="33463" txt_f="33467">2.96</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60497" xml_f="60501" txt_i="33468" txt_f="33472">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60534" xml_f="60538" txt_i="33473" txt_f="33477">2.46</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60571" xml_f="60575" txt_i="33478" txt_f="33482">0.03</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60608" xml_f="60623" txt_i="33483" txt_f="33498">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60656" xml_f="60667" txt_i="33499" txt_f="33510">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60700" xml_f="60704" txt_i="33511" txt_f="33515">3.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60737" xml_f="60741" txt_i="33516" txt_f="33520">0.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60774" xml_f="60778" txt_i="33521" txt_f="33525">2.42</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60811" xml_f="60815" txt_i="33526" txt_f="33530">0.04</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="60890" xml_f="60903" txt_i="33532" txt_f="33545">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60936" xml_f="60940" txt_i="33546" txt_f="33550">4.34</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="60973" xml_f="60977" txt_i="33551" txt_f="33555">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61010" xml_f="61014" txt_i="33556" txt_f="33560">2.51</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61047" xml_f="61051" txt_i="33561" txt_f="33565">0.04</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="61117" xml_f="61130" txt_i="33567" txt_f="33580">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61163" xml_f="61167" txt_i="33581" txt_f="33585">3.96</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61200" xml_f="61204" txt_i="33586" txt_f="33590">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61237" xml_f="61241" txt_i="33591" txt_f="33595">2.64</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61274" xml_f="61278" txt_i="33596" txt_f="33600">0.05</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="61353" xml_f="61362" txt_i="33602" txt_f="33611">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61395" xml_f="61399" txt_i="33612" txt_f="33616">3.82</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61432" xml_f="61436" txt_i="33617" txt_f="33621">0.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61469" xml_f="61473" txt_i="33622" txt_f="33626">2.39</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61506" xml_f="61510" txt_i="33627" txt_f="33631">0.04</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="61576" xml_f="61585" txt_i="33633" txt_f="33642">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61618" xml_f="61622" txt_i="33643" txt_f="33647">3.32</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61655" xml_f="61659" txt_i="33648" txt_f="33652">0.07</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61692" xml_f="61696" txt_i="33653" txt_f="33657">2.42</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61729" xml_f="61733" txt_i="33658" txt_f="33662">0.04</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="61775" xml_f="61791" txt_i="33663" txt_f="33679">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61824" xml_f="61835" txt_i="33680" txt_f="33691">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61868" xml_f="61872" txt_i="33692" txt_f="33696">1.93</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61905" xml_f="61909" txt_i="33697" txt_f="33701">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61942" xml_f="61946" txt_i="33702" txt_f="33706">2.53</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="61979" xml_f="61983" txt_i="33707" txt_f="33711">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62016" xml_f="62032" txt_i="33712" txt_f="33728">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62065" xml_f="62076" txt_i="33729" txt_f="33740">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62109" xml_f="62113" txt_i="33741" txt_f="33745">2.24</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62146" xml_f="62150" txt_i="33746" txt_f="33750">0.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62183" xml_f="62187" txt_i="33751" txt_f="33755">2.37</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62220" xml_f="62224" txt_i="33756" txt_f="33760">0.06</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="62299" xml_f="62312" txt_i="33762" txt_f="33775">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62345" xml_f="62349" txt_i="33776" txt_f="33780">2.91</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62382" xml_f="62386" txt_i="33781" txt_f="33785">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62419" xml_f="62423" txt_i="33786" txt_f="33790">2.80</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62456" xml_f="62460" txt_i="33791" txt_f="33795">0.05</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="62526" xml_f="62539" txt_i="33797" txt_f="33810">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62572" xml_f="62576" txt_i="33811" txt_f="33815">2.94</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62609" xml_f="62613" txt_i="33816" txt_f="33820">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62646" xml_f="62650" txt_i="33821" txt_f="33825">2.74</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62683" xml_f="62687" txt_i="33826" txt_f="33830">0.07</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="62762" xml_f="62771" txt_i="33832" txt_f="33841">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62804" xml_f="62808" txt_i="33842" txt_f="33846">4.31</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62841" xml_f="62845" txt_i="33847" txt_f="33851">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62878" xml_f="62882" txt_i="33852" txt_f="33856">2.69</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="62915" xml_f="62919" txt_i="33857" txt_f="33861">0.06</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="62985" xml_f="62994" txt_i="33863" txt_f="33872">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63027" xml_f="63031" txt_i="33873" txt_f="33877">3.87</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63064" xml_f="63068" txt_i="33878" txt_f="33882">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63101" xml_f="63105" txt_i="33883" txt_f="33887">2.37</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63138" xml_f="63142" txt_i="33888" txt_f="33892">0.06</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="63184" xml_f="63194" txt_i="33893" txt_f="33903">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63227" xml_f="63238" txt_i="33904" txt_f="33915">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63271" xml_f="63275" txt_i="33916" txt_f="33920">1.58</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63308" xml_f="63312" txt_i="33921" txt_f="33925">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63345" xml_f="63349" txt_i="33926" txt_f="33930">2.20</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63382" xml_f="63386" txt_i="33931" txt_f="33935">0.05</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63419" xml_f="63429" txt_i="33936" txt_f="33946">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63462" xml_f="63473" txt_i="33947" txt_f="33958">Harm to you</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63506" xml_f="63510" txt_i="33959" txt_f="33963">1.67</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63543" xml_f="63547" txt_i="33964" txt_f="33968">0.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63580" xml_f="63584" txt_i="33969" txt_f="33973">2.03</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63617" xml_f="63621" txt_i="33974" txt_f="33978">0.06</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="63696" xml_f="63709" txt_i="33980" txt_f="33993">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63742" xml_f="63746" txt_i="33994" txt_f="33998">1.58</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63779" xml_f="63783" txt_i="33999" txt_f="34003">0.08</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63816" xml_f="63820" txt_i="34004" txt_f="34008">2.27</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63853" xml_f="63857" txt_i="34009" txt_f="34013">0.06</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="63923" xml_f="63936" txt_i="34015" txt_f="34028">Harm to other</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="63969" xml_f="63973" txt_i="34029" txt_f="34033">1.81</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64006" xml_f="64010" txt_i="34034" txt_f="34038">0.10</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64043" xml_f="64047" txt_i="34039" txt_f="34043">2.35</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64080" xml_f="64084" txt_i="34044" txt_f="34048">0.07</offsets></td></tr><tr><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="64159" xml_f="64168" txt_i="34050" txt_f="34059">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64201" xml_f="64205" txt_i="34060" txt_f="34064">1.58</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64238" xml_f="64242" txt_i="34065" txt_f="34069">0.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64275" xml_f="64279" txt_i="34070" txt_f="34074">2.30</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64312" xml_f="64316" txt_i="34075" txt_f="34079">0.06</offsets></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"><offsets xml_i="64382" xml_f="64391" txt_i="34081" txt_f="34090">Past harm</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64424" xml_f="64428" txt_i="34091" txt_f="34095">1.47</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64461" xml_f="64465" txt_i="34096" txt_f="34100">0.11</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64498" xml_f="64502" txt_i="34101" txt_f="34105">2.09</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="64535" xml_f="64539" txt_i="34106" txt_f="34110">0.06</offsets></td></tr></tbody></table></alternatives></table-wrap></p></sec><sec id="sec19-2041669518755806"><title><offsets xml_i="64643" xml_f="64650" txt_i="34113" txt_f="34120">Study 2</offsets></title><p><offsets xml_i="64661" xml_f="64846" txt_i="34121" txt_f="34306">Because valence and arousal ratings for the color photographic images were collected on 6-point Likert scales as compared to 7-point Likert scales used in Study 2, all the ratings were </offsets><italic><offsets xml_i="64854" xml_f="64855" txt_i="34306" txt_f="34307">Z</offsets></italic><offsets xml_i="64864" xml_f="64891" txt_i="34307" txt_f="34334">-scored prior to analysis. </offsets><xref ref-type="fig" rid="fig7-2041669518755806"><offsets xml_i="64940" xml_f="64951" txt_i="34334" txt_f="34345">Figure 7(a)</offsets></xref><offsets xml_i="64958" xml_f="65192" txt_i="34345" txt_f="34579"> shows the relationship between valence and arousal ratings of color photographic images. Similarly to line drawings, there was a strong negative linear relationship between valence and arousal ratings of color photographs, Pearson’s </offsets><italic><offsets xml_i="65200" xml_f="65201" txt_i="34579" txt_f="34580">r</offsets></italic><offsets xml_i="65210" xml_f="65220" txt_i="34580" txt_f="34590"> = −.894, </offsets><italic><offsets xml_i="65228" xml_f="65229" txt_i="34590" txt_f="34591">p</offsets></italic><offsets xml_i="65238" xml_f="65517" txt_i="34591" txt_f="34867"> &lt; .001. To directly compare the scenes in color photographic and line drawing form on valence and arousal dimensions, we ran two 2(image type) × 5(image category) repeated measured ANOVAs using Type II calculation for obtaining sums of squares separately for each dimension (</offsets><xref ref-type="fig" rid="fig7-2041669518755806"><offsets xml_i="65566" xml_f="65577" txt_i="34867" txt_f="34878">Figure 7(b)</offsets></xref><offsets xml_i="65584" xml_f="65587" txt_i="34878" txt_f="34881">).
</offsets><fig id="fig7-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="65666" xml_f="65675" txt_i="34881" txt_f="34890">Figure 7.</offsets></label><caption><p><offsets xml_i="65695" xml_f="66000" txt_i="34890" txt_f="35195">Study 2 validation results. (a) The relationship between valence and arousal ratings of color photographic scenes (left) with the relationship between valence and arousal ratings of line drawings of the matching scenes on the right for comparison. The colors correspond to image categories. (b) Means and </offsets><italic><offsets xml_i="66008" xml_f="66010" txt_i="35195" txt_f="35197">SE</offsets></italic><offsets xml_i="66019" xml_f="66163" txt_i="35197" txt_f="35341"> of valence and arousal ratings for each image category for color photographic images and line-drawing images of matching scenes for comparison.</offsets></p></caption><graphic xlink:href="10.1177_2041669518755806-fig7"></graphic></fig></p><p><offsets xml_i="66252" xml_f="66352" txt_i="35343" txt_f="35443">On arousal dimension, the analyses revealed no statistically significant main effect of image type (</offsets><italic><offsets xml_i="66360" xml_f="66361" txt_i="35443" txt_f="35444">F</offsets></italic><offsets xml_i="66370" xml_f="66389" txt_i="35444" txt_f="35460">(1,495) &lt; .001, </offsets><italic><offsets xml_i="66397" xml_f="66398" txt_i="35460" txt_f="35461">p</offsets></italic><offsets xml_i="66407" xml_f="66417" txt_i="35461" txt_f="35471"> = 1.000, </offsets><italic><offsets xml_i="66425" xml_f="66426" txt_i="35471" txt_f="35472">η</offsets><sup><offsets xml_i="66431" xml_f="66432" txt_i="35472" txt_f="35473">2</offsets></sup><sub><offsets xml_i="66443" xml_f="66444" txt_i="35473" txt_f="35474">p</offsets></sub></italic><offsets xml_i="66459" xml_f="66521" txt_i="35474" txt_f="35533"> &lt; .001), but a significant main effect of image category (</offsets><italic><offsets xml_i="66529" xml_f="66530" txt_i="35533" txt_f="35534">F</offsets></italic><offsets xml_i="66539" xml_f="66557" txt_i="35534" txt_f="35552">(4,495) = 179.78, </offsets><italic><offsets xml_i="66565" xml_f="66566" txt_i="35552" txt_f="35553">p</offsets></italic><offsets xml_i="66575" xml_f="66587" txt_i="35553" txt_f="35562"> &lt; .001, </offsets><italic><offsets xml_i="66595" xml_f="66596" txt_i="35562" txt_f="35563">η</offsets><sup><offsets xml_i="66601" xml_f="66602" txt_i="35563" txt_f="35564">2</offsets></sup><sub><offsets xml_i="66613" xml_f="66614" txt_i="35564" txt_f="35565">p</offsets></sub></italic><offsets xml_i="66629" xml_f="66785" txt_i="35565" txt_f="35721"> = .592). All image categories were significantly different from each other as indicated by post hoc pairwise comparisons with a Bonferroni correction (all </offsets><italic><offsets xml_i="66793" xml_f="66794" txt_i="35721" txt_f="35722">p</offsets></italic><offsets xml_i="66803" xml_f="66867" txt_i="35722" txt_f="35783">s &lt; .003). Deadly Threat images were rated as most arousing (</offsets><italic><offsets xml_i="66875" xml_f="66876" txt_i="35783" txt_f="35784">M</offsets></italic><offsets xml_i="66885" xml_f="66894" txt_i="35784" txt_f="35793"> = 1.08, </offsets><italic><offsets xml_i="66902" xml_f="66904" txt_i="35793" txt_f="35795">SE</offsets></italic><offsets xml_i="66913" xml_f="66951" txt_i="35795" txt_f="35833"> = .09), followed by Indirect Threat (</offsets><italic><offsets xml_i="66959" xml_f="66960" txt_i="35833" txt_f="35834">M</offsets></italic><offsets xml_i="66969" xml_f="66977" txt_i="35834" txt_f="35842"> = .46, </offsets><italic><offsets xml_i="66985" xml_f="66987" txt_i="35842" txt_f="35844">SE</offsets></italic><offsets xml_i="66996" xml_f="67020" txt_i="35844" txt_f="35868"> = .05), Direct Threat (</offsets><italic><offsets xml_i="67028" xml_f="67029" txt_i="35868" txt_f="35869">M</offsets></italic><offsets xml_i="67038" xml_f="67047" txt_i="35869" txt_f="35878"> = −.02, </offsets><italic><offsets xml_i="67055" xml_f="67057" txt_i="35878" txt_f="35880">SE</offsets></italic><offsets xml_i="67066" xml_f="67093" txt_i="35880" txt_f="35907"> = .06), Threat Aftermath (</offsets><italic><offsets xml_i="67101" xml_f="67102" txt_i="35907" txt_f="35908">M</offsets></italic><offsets xml_i="67111" xml_f="67120" txt_i="35908" txt_f="35917"> = −.35, </offsets><italic><offsets xml_i="67128" xml_f="67130" txt_i="35917" txt_f="35919">SE</offsets></italic><offsets xml_i="67139" xml_f="67164" txt_i="35919" txt_f="35944"> = .07), and Low Threat (</offsets><italic><offsets xml_i="67172" xml_f="67173" txt_i="35944" txt_f="35945">M</offsets></italic><offsets xml_i="67182" xml_f="67192" txt_i="35945" txt_f="35955"> = −1.50, </offsets><italic><offsets xml_i="67200" xml_f="67202" txt_i="35955" txt_f="35957">SE</offsets></italic><offsets xml_i="67211" xml_f="67304" txt_i="35957" txt_f="36050"> = .07). There was also a significant interaction between the image category and image type (</offsets><italic><offsets xml_i="67312" xml_f="67313" txt_i="36050" txt_f="36051">F</offsets></italic><offsets xml_i="67322" xml_f="67338" txt_i="36051" txt_f="36067">(4,495) = 3.56, </offsets><italic><offsets xml_i="67346" xml_f="67347" txt_i="36067" txt_f="36068">p</offsets></italic><offsets xml_i="67356" xml_f="67365" txt_i="36068" txt_f="36077"> = .007, </offsets><italic><offsets xml_i="67373" xml_f="67374" txt_i="36077" txt_f="36078">η</offsets><sup><offsets xml_i="67379" xml_f="67380" txt_i="36078" txt_f="36079">2</offsets></sup><sub><offsets xml_i="67391" xml_f="67392" txt_i="36079" txt_f="36080">p</offsets></sub></italic><offsets xml_i="67407" xml_f="67598" txt_i="36080" txt_f="36271"> = .028). Pairwise comparisons with a Bonferroni correction revealed that Deadly Threat and Low Threat images were rated as more arousing in line drawing compared to color photographic form (</offsets><italic><offsets xml_i="67606" xml_f="67607" txt_i="36271" txt_f="36272">t</offsets></italic><offsets xml_i="67616" xml_f="67630" txt_i="36272" txt_f="36286">(100) = 2.02, </offsets><italic><offsets xml_i="67638" xml_f="67639" txt_i="36286" txt_f="36287">p</offsets></italic><offsets xml_i="67648" xml_f="67660" txt_i="36287" txt_f="36299"> = .044 and </offsets><italic><offsets xml_i="67668" xml_f="67669" txt_i="36299" txt_f="36300">t</offsets></italic><offsets xml_i="67678" xml_f="67692" txt_i="36300" txt_f="36314">(140) = 2.15, </offsets><italic><offsets xml_i="67700" xml_f="67701" txt_i="36314" txt_f="36315">p</offsets></italic><offsets xml_i="67710" xml_f="67798" txt_i="36315" txt_f="36403"> = .032, respectively) while the opposite was observed for the Threat Aftermath images (</offsets><italic><offsets xml_i="67806" xml_f="67807" txt_i="36403" txt_f="36404">t</offsets></italic><offsets xml_i="67816" xml_f="67830" txt_i="36404" txt_f="36418">(162) = 2.00, </offsets><italic><offsets xml_i="67838" xml_f="67839" txt_i="36418" txt_f="36419">p</offsets></italic><offsets xml_i="67848" xml_f="68012" txt_i="36419" txt_f="36583"> = .046). No statistically significant differences were found between line-drawing and color photographic images for Direct Threat and Indirect Threat images (both </offsets><italic><offsets xml_i="68020" xml_f="68021" txt_i="36583" txt_f="36584">p</offsets></italic><offsets xml_i="68030" xml_f="68047" txt_i="36584" txt_f="36598">s &gt; .229, see </offsets><xref ref-type="table" rid="table2-2041669518755806"><offsets xml_i="68100" xml_f="68107" txt_i="36598" txt_f="36605">Table 2</offsets></xref><offsets xml_i="68114" xml_f="68228" txt_i="36605" txt_f="36719"> for descriptive statistics). It is worth noting that while the interaction effect was statistically significant (</offsets><italic><offsets xml_i="68236" xml_f="68237" txt_i="36719" txt_f="36720">p</offsets></italic><offsets xml_i="68246" xml_f="68292" txt_i="36720" txt_f="36766"> = .007), the effect size observed was small (</offsets><italic><offsets xml_i="68300" xml_f="68301" txt_i="36766" txt_f="36767">η</offsets><sup><offsets xml_i="68306" xml_f="68307" txt_i="36767" txt_f="36768">2</offsets></sup><sub><offsets xml_i="68318" xml_f="68319" txt_i="36768" txt_f="36769">p</offsets></sub></italic><offsets xml_i="68334" xml_f="68412" txt_i="36769" txt_f="36847"> = .028). Thus, the results reported here should be interpreted with caution.
</offsets><table-wrap id="table2-2041669518755806" orientation="portrait" position="float"><label><offsets xml_i="68500" xml_f="68508" txt_i="36847" txt_f="36855">Table 2.</offsets></label><caption><p><offsets xml_i="68528" xml_f="68660" txt_i="36855" txt_f="36987">Descriptive Statistics for Valence and Arousal Ratings for Line Drawings and Color Photographic Images (data previously reported in </offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="68712" xml_f="68732" txt_i="36987" txt_f="37007">Kveraga et al., 2015</offsets></xref><offsets xml_i="68739" xml_f="68741" txt_i="37007" txt_f="37009">).</offsets></p></caption><alternatives><graphic specific-use="table2-2041669518755806" xlink:href="10.1177_2041669518755806-table2"></graphic><table frame="hsides" rules="groups"><thead align="left" valign="top"><tr><th colspan="6" rowspan="1"><offsets xml_i="68974" xml_f="68987" txt_i="37010" txt_f="37023">Line drawings</offsets><hr></hr></th><th rowspan="1" colspan="1"></th><th colspan="5" rowspan="1"><offsets xml_i="69062" xml_f="69079" txt_i="37023" txt_f="37040">Color photographs</offsets><hr></hr></th></tr><tr><th colspan="2" rowspan="2"></th><th colspan="2" rowspan="1"><offsets xml_i="69163" xml_f="69170" txt_i="37040" txt_f="37047">Arousal</offsets><hr></hr></th><th colspan="2" rowspan="1"><offsets xml_i="69212" xml_f="69219" txt_i="37047" txt_f="37054">Valence</offsets><hr></hr></th><th rowspan="2" colspan="1"></th><th rowspan="2" colspan="1"></th><th colspan="2" rowspan="1"><offsets xml_i="69327" xml_f="69334" txt_i="37054" txt_f="37061">Arousal</offsets><hr></hr></th><th colspan="2" rowspan="1"><offsets xml_i="69376" xml_f="69383" txt_i="37061" txt_f="37068">Valence</offsets><hr></hr></th></tr><tr><th rowspan="1" colspan="1"><offsets xml_i="69434" xml_f="69435" txt_i="37068" txt_f="37069">
</offsets><italic><offsets xml_i="69443" xml_f="69444" txt_i="37069" txt_f="37070">M</offsets></italic><offsets xml_i="69453" xml_f="69454" txt_i="37070" txt_f="37071">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69487" xml_f="69488" txt_i="37071" txt_f="37072">
</offsets><italic><offsets xml_i="69496" xml_f="69498" txt_i="37072" txt_f="37074">SD</offsets></italic><offsets xml_i="69507" xml_f="69508" txt_i="37074" txt_f="37075">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69541" xml_f="69542" txt_i="37075" txt_f="37076">
</offsets><italic><offsets xml_i="69550" xml_f="69551" txt_i="37076" txt_f="37077">M</offsets></italic><offsets xml_i="69560" xml_f="69561" txt_i="37077" txt_f="37078">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69594" xml_f="69595" txt_i="37078" txt_f="37079">
</offsets><italic><offsets xml_i="69603" xml_f="69605" txt_i="37079" txt_f="37081">SD</offsets></italic><offsets xml_i="69614" xml_f="69615" txt_i="37081" txt_f="37082">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69648" xml_f="69649" txt_i="37082" txt_f="37083">
</offsets><italic><offsets xml_i="69657" xml_f="69658" txt_i="37083" txt_f="37084">M</offsets></italic><offsets xml_i="69667" xml_f="69668" txt_i="37084" txt_f="37085">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69701" xml_f="69702" txt_i="37085" txt_f="37086">
</offsets><italic><offsets xml_i="69710" xml_f="69712" txt_i="37086" txt_f="37088">SD</offsets></italic><offsets xml_i="69721" xml_f="69722" txt_i="37088" txt_f="37089">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69755" xml_f="69756" txt_i="37089" txt_f="37090">
</offsets><italic><offsets xml_i="69764" xml_f="69765" txt_i="37090" txt_f="37091">M</offsets></italic><offsets xml_i="69774" xml_f="69775" txt_i="37091" txt_f="37092">
</offsets></th><th rowspan="1" colspan="1"><offsets xml_i="69808" xml_f="69809" txt_i="37092" txt_f="37093">
</offsets><italic><offsets xml_i="69817" xml_f="69819" txt_i="37093" txt_f="37095">SD</offsets></italic><offsets xml_i="69828" xml_f="69829" txt_i="37095" txt_f="37096">
</offsets></th></tr></thead><tbody align="left" valign="top"><tr><td rowspan="5" colspan="1"><offsets xml_i="69912" xml_f="69913" txt_i="37096" txt_f="37097">
</offsets><bold><offsets xml_i="69919" xml_f="69927" txt_i="37097" txt_f="37105">Category</offsets></bold><offsets xml_i="69934" xml_f="69935" txt_i="37105" txt_f="37106">
</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="69968" xml_f="69981" txt_i="37107" txt_f="37120">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70014" xml_f="70018" txt_i="37121" txt_f="37125">1.17</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70051" xml_f="70054" txt_i="37126" txt_f="37129">.33</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70087" xml_f="70092" txt_i="37130" txt_f="37135">−1.16</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70125" xml_f="70128" txt_i="37136" txt_f="37139">.37</offsets></td><td rowspan="5" colspan="1"><offsets xml_i="70161" xml_f="70162" txt_i="37140" txt_f="37141">
</offsets><bold><offsets xml_i="70168" xml_f="70176" txt_i="37141" txt_f="37149">Category</offsets></bold><offsets xml_i="70183" xml_f="70184" txt_i="37149" txt_f="37150">
</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70217" xml_f="70230" txt_i="37151" txt_f="37164">Deadly Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70263" xml_f="70266" txt_i="37165" txt_f="37168">.99</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70299" xml_f="70302" txt_i="37169" txt_f="37172">.25</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70335" xml_f="70340" txt_i="37173" txt_f="37178">−1.01</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70373" xml_f="70376" txt_i="37179" txt_f="37182">.24</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="70418" xml_f="70431" txt_i="37183" txt_f="37196">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70464" xml_f="70468" txt_i="37197" txt_f="37201">−.06</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70501" xml_f="70504" txt_i="37202" txt_f="37205">.60</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70537" xml_f="70540" txt_i="37206" txt_f="37209">.04</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70573" xml_f="70576" txt_i="37210" txt_f="37213">.59</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70609" xml_f="70622" txt_i="37214" txt_f="37227">Direct Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70655" xml_f="70658" txt_i="37228" txt_f="37231">.01</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70691" xml_f="70694" txt_i="37232" txt_f="37235">.51</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70727" xml_f="70730" txt_i="37236" txt_f="37239">.35</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70763" xml_f="70766" txt_i="37240" txt_f="37243">.63</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="70808" xml_f="70823" txt_i="37244" txt_f="37259">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70856" xml_f="70859" txt_i="37260" txt_f="37263">.46</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70892" xml_f="70895" txt_i="37264" txt_f="37267">.74</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70928" xml_f="70932" txt_i="37268" txt_f="37272">−.38</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="70965" xml_f="70968" txt_i="37273" txt_f="37276">.79</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71001" xml_f="71016" txt_i="37277" txt_f="37292">Indirect Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71049" xml_f="71052" txt_i="37293" txt_f="37296">.46</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71085" xml_f="71088" txt_i="37297" txt_f="37300">.72</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71121" xml_f="71125" txt_i="37301" txt_f="37305">−.44</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71158" xml_f="71161" txt_i="37306" txt_f="37309">.77</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="71203" xml_f="71219" txt_i="37310" txt_f="37326">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71252" xml_f="71256" txt_i="37327" txt_f="37331">−.42</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71289" xml_f="71292" txt_i="37332" txt_f="37335">.88</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71325" xml_f="71328" txt_i="37336" txt_f="37339">.28</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71361" xml_f="71364" txt_i="37340" txt_f="37343">.82</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71397" xml_f="71413" txt_i="37344" txt_f="37360">Threat Aftermath</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71446" xml_f="71450" txt_i="37361" txt_f="37365">−.28</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71483" xml_f="71486" txt_i="37366" txt_f="37369">.98</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71519" xml_f="71523" txt_i="37370" txt_f="37374">−.12</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71556" xml_f="71559" txt_i="37375" txt_f="37378">.95</offsets></td></tr><tr><td rowspan="1" colspan="1"><offsets xml_i="71601" xml_f="71611" txt_i="37379" txt_f="37389">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71644" xml_f="71649" txt_i="37390" txt_f="37395">−1.41</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71682" xml_f="71685" txt_i="37396" txt_f="37399">.64</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71718" xml_f="71722" txt_i="37400" txt_f="37404">1.42</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71755" xml_f="71758" txt_i="37405" txt_f="37408">.82</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71791" xml_f="71801" txt_i="37409" txt_f="37419">Low Threat</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71834" xml_f="71839" txt_i="37420" txt_f="37425">−1.58</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71872" xml_f="71875" txt_i="37426" txt_f="37429">.62</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71908" xml_f="71912" txt_i="37430" txt_f="37434">1.45</offsets></td><td rowspan="1" colspan="1"><offsets xml_i="71945" xml_f="71948" txt_i="37435" txt_f="37438">.52</offsets></td></tr></tbody></table></alternatives></table-wrap></p><p><offsets xml_i="72009" xml_f="72109" txt_i="37440" txt_f="37540">On valence dimension, the analyses revealed no statistically significant main effect of image type (</offsets><italic><offsets xml_i="72117" xml_f="72118" txt_i="37540" txt_f="37541">F</offsets></italic><offsets xml_i="72127" xml_f="72146" txt_i="37541" txt_f="37557">(1,495) &lt; .001, </offsets><italic><offsets xml_i="72154" xml_f="72155" txt_i="37557" txt_f="37558">p</offsets></italic><offsets xml_i="72164" xml_f="72174" txt_i="37558" txt_f="37568"> = 1.000, </offsets><italic><offsets xml_i="72182" xml_f="72183" txt_i="37568" txt_f="37569">η</offsets><sup><offsets xml_i="72188" xml_f="72189" txt_i="37569" txt_f="37570">2</offsets></sup><sub><offsets xml_i="72200" xml_f="72201" txt_i="37570" txt_f="37571">p</offsets></sub></italic><offsets xml_i="72216" xml_f="72278" txt_i="37571" txt_f="37630"> &lt; .001), but a significant main effect of image category (</offsets><italic><offsets xml_i="72286" xml_f="72287" txt_i="37630" txt_f="37631">F</offsets></italic><offsets xml_i="72296" xml_f="72314" txt_i="37631" txt_f="37649">(4,495) = 145.40, </offsets><italic><offsets xml_i="72322" xml_f="72323" txt_i="37649" txt_f="37650">p</offsets></italic><offsets xml_i="72332" xml_f="72344" txt_i="37650" txt_f="37659"> &lt; .001, </offsets><italic><offsets xml_i="72352" xml_f="72353" txt_i="37659" txt_f="37660">η</offsets><sup><offsets xml_i="72358" xml_f="72359" txt_i="37660" txt_f="37661">2</offsets></sup><sub><offsets xml_i="72370" xml_f="72371" txt_i="37661" txt_f="37662">p</offsets></sub></italic><offsets xml_i="72386" xml_f="72467" txt_i="37662" txt_f="37743"> = .540). All image categories were significantly different from each other (all </offsets><italic><offsets xml_i="72475" xml_f="72476" txt_i="37743" txt_f="37744">p</offsets></italic><offsets xml_i="72485" xml_f="72601" txt_i="37744" txt_f="37857">s &lt; .001), except for no statistically significant difference between Direct Threat and Threat Aftermath images (</offsets><italic><offsets xml_i="72609" xml_f="72610" txt_i="37857" txt_f="37858">t</offsets></italic><offsets xml_i="72619" xml_f="72633" txt_i="37858" txt_f="37872">(199) = 1.55, </offsets><italic><offsets xml_i="72641" xml_f="72642" txt_i="37872" txt_f="37873">p</offsets></italic><offsets xml_i="72651" xml_f="72786" txt_i="37873" txt_f="38008"> = .727) as indicated by post hoc pairwise comparisons with a Bonferroni correction. Deadly Threat images were rated as most negative (</offsets><italic><offsets xml_i="72794" xml_f="72795" txt_i="38008" txt_f="38009">M</offsets></italic><offsets xml_i="72804" xml_f="72814" txt_i="38009" txt_f="38019"> = −1.08, </offsets><italic><offsets xml_i="72822" xml_f="72824" txt_i="38019" txt_f="38021">SE</offsets></italic><offsets xml_i="72833" xml_f="72871" txt_i="38021" txt_f="38059"> = .09), followed by Indirect Threat (</offsets><italic><offsets xml_i="72879" xml_f="72880" txt_i="38059" txt_f="38060">M</offsets></italic><offsets xml_i="72889" xml_f="72898" txt_i="38060" txt_f="38069"> = −.41, </offsets><italic><offsets xml_i="72906" xml_f="72908" txt_i="38069" txt_f="38071">SE</offsets></italic><offsets xml_i="72917" xml_f="72941" txt_i="38071" txt_f="38095"> = .05), Direct Threat (</offsets><italic><offsets xml_i="72949" xml_f="72950" txt_i="38095" txt_f="38096">M</offsets></italic><offsets xml_i="72959" xml_f="72967" txt_i="38096" txt_f="38104"> = .19, </offsets><italic><offsets xml_i="72975" xml_f="72977" txt_i="38104" txt_f="38106">SE</offsets></italic><offsets xml_i="72986" xml_f="73013" txt_i="38106" txt_f="38133"> = .06), Threat Aftermath (</offsets><italic><offsets xml_i="73021" xml_f="73022" txt_i="38133" txt_f="38134">M</offsets></italic><offsets xml_i="73031" xml_f="73039" txt_i="38134" txt_f="38142"> = .05, </offsets><italic><offsets xml_i="73047" xml_f="73049" txt_i="38142" txt_f="38144">SE</offsets></italic><offsets xml_i="73058" xml_f="73083" txt_i="38144" txt_f="38169"> = .07), and Low Threat (</offsets><italic><offsets xml_i="73091" xml_f="73092" txt_i="38169" txt_f="38170">M</offsets></italic><offsets xml_i="73101" xml_f="73110" txt_i="38170" txt_f="38179"> = 1.44, </offsets><italic><offsets xml_i="73118" xml_f="73120" txt_i="38179" txt_f="38181">SE</offsets></italic><offsets xml_i="73129" xml_f="73222" txt_i="38181" txt_f="38274"> = .08). There was also a significant interaction between the image category and image type (</offsets><italic><offsets xml_i="73230" xml_f="73231" txt_i="38274" txt_f="38275">F</offsets></italic><offsets xml_i="73240" xml_f="73257" txt_i="38275" txt_f="38292">(4,495) = 21.34, </offsets><italic><offsets xml_i="73265" xml_f="73266" txt_i="38292" txt_f="38293">p</offsets></italic><offsets xml_i="73275" xml_f="73287" txt_i="38293" txt_f="38302"> &lt; .001, </offsets><italic><offsets xml_i="73295" xml_f="73296" txt_i="38302" txt_f="38303">η</offsets><sup><offsets xml_i="73301" xml_f="73302" txt_i="38303" txt_f="38304">2</offsets></sup><sub><offsets xml_i="73313" xml_f="73314" txt_i="38304" txt_f="38305">p</offsets></sub></italic><offsets xml_i="73329" xml_f="73504" txt_i="38305" txt_f="38480"> = .147). Pairwise comparisons with a Bonferroni correction revealed that Direct Threat images were rated more negatively in line-drawing compared to color photographic form (</offsets><italic><offsets xml_i="73512" xml_f="73513" txt_i="38480" txt_f="38481">t</offsets></italic><offsets xml_i="73522" xml_f="73536" txt_i="38481" txt_f="38495">(236) = 5.69, </offsets><italic><offsets xml_i="73544" xml_f="73545" txt_i="38495" txt_f="38496">p</offsets></italic><offsets xml_i="73554" xml_f="73664" txt_i="38496" txt_f="38603"> &lt; .001). Similar but only marginally statistically significant effect was found for Deadly Threat images (</offsets><italic><offsets xml_i="73672" xml_f="73673" txt_i="38603" txt_f="38604">t</offsets></italic><offsets xml_i="73682" xml_f="73696" txt_i="38604" txt_f="38618">(100) = 1.85, </offsets><italic><offsets xml_i="73704" xml_f="73705" txt_i="38618" txt_f="38619">p</offsets></italic><offsets xml_i="73714" xml_f="73783" txt_i="38619" txt_f="38688"> = .066). The opposite was observed for the Threat Aftermath images (</offsets><italic><offsets xml_i="73791" xml_f="73792" txt_i="38688" txt_f="38689">t</offsets></italic><offsets xml_i="73801" xml_f="73815" txt_i="38689" txt_f="38703">(140) = 6.94, </offsets><italic><offsets xml_i="73823" xml_f="73824" txt_i="38703" txt_f="38704">p</offsets></italic><offsets xml_i="73833" xml_f="74115" txt_i="38704" txt_f="38983"> &lt; .001). Specifically, Threat Aftermath images were rated less negatively in line-drawing compared to color photographic form. No statistically significant differences were found between line-drawing and color photographic images for Indirect Threat and Low Threat images (both </offsets><italic><offsets xml_i="74123" xml_f="74124" txt_i="38983" txt_f="38984">p</offsets></italic><offsets xml_i="74133" xml_f="74150" txt_i="38984" txt_f="38998">s &gt; .214, see </offsets><xref ref-type="table" rid="table2-2041669518755806"><offsets xml_i="74203" xml_f="74210" txt_i="38998" txt_f="39005">Table 2</offsets></xref><offsets xml_i="74217" xml_f="74246" txt_i="39005" txt_f="39034"> for descriptive statistics).</offsets></p></sec></sec></sec><sec sec-type="discussion" id="sec20-2041669518755806"><title><offsets xml_i="74330" xml_f="74340" txt_i="39038" txt_f="39048">Discussion</offsets></title><p><offsets xml_i="74351" xml_f="75372" txt_i="39049" txt_f="40070">In the present study, we demonstrated that human observers are able to finely discriminate different types of threat or merely negative situations from line-drawn scenes, even though line drawings lack many of the defining characteristics seen in the real world (such as color, most texture, most shading, and many background details). Specifically, we found that even though all of the images (with the exception of the Low Threat category) were negative, these scenes were keenly discriminated by the observers based on the perceived target of the threat (spatially directed towards the observer vs. towards someone else in the scene) as well as the temporal proximity of threat (happening right now or about to happen vs. something that happened sometime in the past). Previously, we reported that human observers are sensitive to different types of negative stimuli, with their evaluation of the stimuli differing sharply depending on the spatial and temporal direction of the threat using color photographic images (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="75424" xml_f="75444" txt_i="40070" txt_f="40090">Kveraga et al., 2015</offsets></xref><offsets xml_i="75451" xml_f="75539" txt_i="40090" txt_f="40178">). The present study replicated and extended our previous findings to line-drawn scenes.</offsets></p><p><offsets xml_i="75546" xml_f="76045" txt_i="40179" txt_f="40678">The 500 open-access line-drawn images depicting scenes with different levels of threat created for the present study were rated by a sample of American young adults on three scales capturing spatial and temporal direction of the threat (how much harm there is to you, how much harm there is to someone else, and how much harm has already happened). Based on these ratings, 500 images were divided into five distinct categories: Deadly Threat (depicting humans with weapons pointing at the observer; </offsets><italic><offsets xml_i="76053" xml_f="76054" txt_i="40678" txt_f="40679">n</offsets></italic><offsets xml_i="76063" xml_f="76139" txt_i="40679" txt_f="40755"> = 51), Direct Threat (depicting scenes posing high threat to the observer, </offsets><italic><offsets xml_i="76147" xml_f="76148" txt_i="40755" txt_f="40756">n</offsets></italic><offsets xml_i="76157" xml_f="76236" txt_i="40756" txt_f="40835"> = 119), Indirect Threat (depicting scenes posing high threat to someone else; </offsets><italic><offsets xml_i="76244" xml_f="76245" txt_i="40835" txt_f="40836">n</offsets></italic><offsets xml_i="76254" xml_f="76364" txt_i="40836" txt_f="40946"> = 117), Threat Aftermath (depicting scenes where harm—physical, psychological, or both—has already happened; </offsets><italic><offsets xml_i="76372" xml_f="76373" txt_i="40946" txt_f="40947">n</offsets></italic><offsets xml_i="76382" xml_f="76477" txt_i="40947" txt_f="41042"> = 82), and Low Threat (depicting low level of threat either to the observer, or someone else; </offsets><italic><offsets xml_i="76485" xml_f="76486" txt_i="41042" txt_f="41043">n</offsets></italic><offsets xml_i="76495" xml_f="76502" txt_i="41043" txt_f="41050"> = 71).</offsets></p><p><offsets xml_i="76509" xml_f="76830" txt_i="41051" txt_f="41372">Immediate threats of personal harm should evoke a fight-or-flight response, while threats where the immediate danger has passed, or the threat is to others, might instead evoke an approach response, possibly to render assistance or to gather information that would enable observers to avoid a similar fate in the future (</offsets><xref rid="bibr27-2041669518755806" ref-type="bibr"><offsets xml_i="76882" xml_f="76895" txt_i="41372" txt_f="41385">Kveraga, 2014</offsets></xref><offsets xml_i="76902" xml_f="76904" txt_i="41385" txt_f="41387">; </offsets><xref rid="bibr52-2041669518755806" ref-type="bibr"><offsets xml_i="76956" xml_f="76972" txt_i="41387" txt_f="41403">Oosterwijk, 2017</offsets></xref><offsets xml_i="76979" xml_f="77015" txt_i="41403" txt_f="41439">). The ratings in the three groups (</offsets><italic><offsets xml_i="77023" xml_f="77034" txt_i="41439" txt_f="41450">Harm to you</offsets></italic><offsets xml_i="77043" xml_f="77045" txt_i="41450" txt_f="41452">, </offsets><italic><offsets xml_i="77053" xml_f="77066" txt_i="41452" txt_f="41465">Harm to other</offsets></italic><offsets xml_i="77075" xml_f="77081" txt_i="41465" txt_f="41471">, and </offsets><italic><offsets xml_i="77089" xml_f="77098" txt_i="41471" txt_f="41480">Past harm</offsets></italic><offsets xml_i="77107" xml_f="77914" txt_i="41480" txt_f="42287">) reflected the task, in that the image that received the highest ratings clearly depicted these spatial and temporal threat dimensions, with one exception. All three groups rated the Deadly Threat images (images depicting scenes of humans pointing deadly weapons—mostly guns—at the observer) highly, implying that they pose direct threat to the observer, as well as to someone else, and may have also caused past harm. In addition, Deadly Threat images evoked the lowest RT across all three groups. An alternative explanation of shorter RT could also indicate that the images belonging to the Deadly Threat category are easier to judge than the others, because they are less complex and also because it is easier to evaluate the situation from our point of view than from the point of view of someone else.</offsets></p><p><offsets xml_i="77921" xml_f="78687" txt_i="42288" txt_f="43054">The valence and arousal dimensions had a strong negative linear relationship with each other both for the line-drawing and color photographic form of the matched scenes. Because all the images, with the exception of Low Threat category, were negative with a varying level and type of threat, this relationship is reasonable. The slightly stronger relationship for color photographic images as compared to line drawings of the matching scenes may be due to the fact that while the same participants rated both valence and arousal of the color photographic images, different participants rated valence and arousal of the line-drawing images. Line-drawing images depict the essence of the scene, while color photographic images provide more detail and a richer context.</offsets></p><p><offsets xml_i="78694" xml_f="78871" txt_i="43055" txt_f="43232">It has been demonstrated that humans possess a natural ability to recognize and interpret line drawings and line drawings can evoke similar brain activity as color photographs (</offsets><xref rid="bibr62-2041669518755806" ref-type="bibr"><offsets xml_i="78923" xml_f="78943" txt_i="43232" txt_f="43252">Walther et al., 2011</offsets></xref><offsets xml_i="78950" xml_f="79165" txt_i="43252" txt_f="43467">). Our findings further demonstrate that young human observers show similar sensitivity for threat information in an image, which they can extract quickly whether they are presented with a color photographic image (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="79217" xml_f="79237" txt_i="43467" txt_f="43487">Kveraga et al., 2015</offsets></xref><offsets xml_i="79244" xml_f="79915" txt_i="43487" txt_f="44158">) or a simple line drawing. This indicates that the gist of the scene is extracted and used in categorizing threat and merely negative stimuli, in color photographs and line drawings alike, as the latter are missing much detail, color and background information available in the former. Our findings make sense in light of evolutionary pressures, as the human (and its mammalian predecessors’) visual system had to be able to extract the form of threatening stimuli in widely varying visibility conditions quickly and automatically to promote survival. Among such stimuli, snakes, spiders, and angry faces are thought to be especially important cues of potential danger (</offsets><xref rid="bibr49-2041669518755806" ref-type="bibr"><offsets xml_i="79967" xml_f="79985" txt_i="44158" txt_f="44176">Öhman et al., 2001</offsets></xref><offsets xml_i="79992" xml_f="79994" txt_i="44176" txt_f="44178">; </offsets><xref rid="bibr50-2041669518755806" ref-type="bibr"><offsets xml_i="80046" xml_f="80070" txt_i="44178" txt_f="44198">Öhman &amp; Mineka, 2001</offsets></xref><offsets xml_i="80077" xml_f="80152" txt_i="44198" txt_f="44273">), with snakes being the primary predator of humans’ primate predecessors (</offsets><xref rid="bibr24-2041669518755806" ref-type="bibr"><offsets xml_i="80204" xml_f="80216" txt_i="44273" txt_f="44285">Isbell, 2006</offsets></xref><offsets xml_i="80223" xml_f="80225" txt_i="44285" txt_f="44287">; </offsets><xref rid="bibr34-2041669518755806" ref-type="bibr"><offsets xml_i="80277" xml_f="80292" txt_i="44287" txt_f="44302">Le et al., 2016</offsets></xref><offsets xml_i="80299" xml_f="81106" txt_i="44302" txt_f="45109">). However, our results revealed no natural predators in the Deadly Threat category, which was dominated by images of humans pointing weapons at the observer. While we did not explicitly set out to test whether these stimuli would be recognized faster than natural predators, or unarmed, angry humans, the ratings and the RTs clearly suggest that humans pointing weapons, including guns, are considered significantly more dangerous than natural predators. This may stem from most observers’ surroundings, upbringing and limited experience with natural threats. While they may not have had any personal experience with people pointing guns at them, societal exposure to such stimuli via the media may have been sufficient to encode such evolutionarily modern stimuli as more dangerous than natural predators.</offsets></p><sec id="sec21-2041669518755806"><title><offsets xml_i="81150" xml_f="81223" txt_i="45110" txt_f="45183">Potential Uses of Threat-Depicting and Negative Line Drawings in Research</offsets></title><p><offsets xml_i="81234" xml_f="81428" txt_i="45184" txt_f="45378">Compared to photographic images, line-drawing images are much more easily manipulated without disrupting the natural image statistics, making them a useful tool for studying objects and scenes (</offsets><xref rid="bibr7-2041669518755806" ref-type="bibr"><offsets xml_i="81479" xml_f="81503" txt_i="45378" txt_f="45398">Biederman &amp; Ju, 1988</offsets></xref><offsets xml_i="81510" xml_f="81512" txt_i="45398" txt_f="45400">; </offsets><xref rid="bibr8-2041669518755806" ref-type="bibr"><offsets xml_i="81563" xml_f="81585" txt_i="45400" txt_f="45422">Biederman et al., 1982</offsets></xref><offsets xml_i="81592" xml_f="81594" txt_i="45422" txt_f="45424">; </offsets><xref rid="bibr29-2041669518755806" ref-type="bibr"><offsets xml_i="81646" xml_f="81666" txt_i="45424" txt_f="45444">Kveraga et al., 2007</offsets></xref><offsets xml_i="81673" xml_f="81675" txt_i="45444" txt_f="45446">; </offsets><xref rid="bibr53-2041669518755806" ref-type="bibr"><offsets xml_i="81727" xml_f="81739" txt_i="45446" txt_f="45458">Palmer, 1975</offsets></xref><offsets xml_i="81746" xml_f="81748" txt_i="45458" txt_f="45460">; </offsets><xref rid="bibr59-2041669518755806" ref-type="bibr"><offsets xml_i="81800" xml_f="81832" txt_i="45460" txt_f="45488">Snodgrass &amp; Vanderwart, 1980</offsets></xref><offsets xml_i="81839" xml_f="81841" txt_i="45488" txt_f="45490">; </offsets><xref rid="bibr62-2041669518755806" ref-type="bibr"><offsets xml_i="81893" xml_f="81913" txt_i="45490" txt_f="45510">Walther et al., 2011</offsets></xref><offsets xml_i="81920" xml_f="82797" txt_i="45510" txt_f="46387">). In addition, unlike color photographic scenes, line-drawn scenes offer better control over image statistics across image categories. For example, a color photographic scene depicting a man with a gun pointed at the observer (Deadly Threat) differs from a scene depicting a gravely injured person (Threat Aftermath) not only in the threat context but also in presence (or absence) of color and textural visual cues, such as blood. On the other hand, line-drawn images provide only the gist of the scene across different image categories and thus offer better experimental control. This has been shown to be important in, for example, facial expression research, where anger expressions are detected more quickly when the facial stimuli are identical in their low-level components (e.g., schematic, line-drawn faces), but the evidence is mixed when face photographs are used (</offsets><xref rid="bibr51-2041669518755806" ref-type="bibr"><offsets xml_i="82849" xml_f="82867" txt_i="46387" txt_f="46405">Öhman et al., 2012</offsets></xref><offsets xml_i="82874" xml_f="83045" txt_i="46405" txt_f="46576">). Thus, our line-drawing image set could be used to study threat and emotion perception, either in original or altered form, for example, through visual pathway biasing (</offsets><xref rid="bibr29-2041669518755806" ref-type="bibr"><offsets xml_i="83097" xml_f="83117" txt_i="46576" txt_f="46596">Kveraga et al., 2007</offsets></xref><offsets xml_i="83124" xml_f="83126" txt_i="46596" txt_f="46598">; </offsets><xref rid="bibr60-2041669518755806" ref-type="bibr"><offsets xml_i="83178" xml_f="83228" txt_i="46598" txt_f="46644">Thomas, Kveraga, Huberle, Karnath, &amp; Bar, 2012</offsets></xref><offsets xml_i="83235" xml_f="83251" txt_i="46644" txt_f="46660">), fragmenting (</offsets><xref rid="bibr7-2041669518755806" ref-type="bibr"><offsets xml_i="83302" xml_f="83326" txt_i="46660" txt_f="46680">Biederman &amp; Ju, 1988</offsets></xref><offsets xml_i="83333" xml_f="83374" txt_i="46680" txt_f="46721">), grouping into global/local ensembles (</offsets><xref rid="bibr62-2041669518755806" ref-type="bibr"><offsets xml_i="83426" xml_f="83446" txt_i="46721" txt_f="46741">Walther et al., 2011</offsets></xref><offsets xml_i="83453" xml_f="83485" txt_i="46741" txt_f="46773">), manipulating object-context (</offsets><xref rid="bibr53-2041669518755806" ref-type="bibr"><offsets xml_i="83537" xml_f="83549" txt_i="46773" txt_f="46785">Palmer, 1975</offsets></xref><offsets xml_i="83556" xml_f="83573" txt_i="46785" txt_f="46802">), object-agent (</offsets><xref rid="bibr12-2041669518755806" ref-type="bibr"><offsets xml_i="83625" xml_f="83669" txt_i="46802" txt_f="46842">Correll, Park, Judd, &amp; Wittenbrink, 2002</offsets></xref><offsets xml_i="83676" xml_f="83696" txt_i="46842" txt_f="46862">), object-location (</offsets><xref rid="bibr8-2041669518755806" ref-type="bibr"><offsets xml_i="83747" xml_f="83769" txt_i="46862" txt_f="46884">Biederman et al., 1982</offsets></xref><offsets xml_i="83776" xml_f="83813" txt_i="46884" txt_f="46921">) congruency, or facial expressions (</offsets><xref rid="bibr51-2041669518755806" ref-type="bibr"><offsets xml_i="83865" xml_f="83883" txt_i="46921" txt_f="46939">Öhman et al., 2012</offsets></xref><offsets xml_i="83890" xml_f="83892" txt_i="46939" txt_f="46941">).</offsets></p><p><offsets xml_i="83899" xml_f="84387" txt_i="46942" txt_f="47430">Furthermore, given that our line-drawing image set contains distinct image categories with varying threat loadings, differentiating negative, threatening images (Deadly Threat, Direct Threat, and Indirect Threat) from merely negative images (Threat Aftermath), it may also be useful for studying clinical populations showing abnormal sensitivity to threat stimuli. For example, various studies demonstrated that anxious individuals exhibit selective attention for threat-related stimuli (</offsets><xref rid="bibr19-2041669518755806" ref-type="bibr"><offsets xml_i="84439" xml_f="84484" txt_i="47430" txt_f="47471">Eysenck, Derakshan, Santos, &amp; Calvo, 2007</offsets></xref><offsets xml_i="84491" xml_f="84493" txt_i="47471" txt_f="47473">; </offsets><xref rid="bibr44-2041669518755806" ref-type="bibr"><offsets xml_i="84545" xml_f="84569" txt_i="47473" txt_f="47493">Mogg &amp; Bradley, 1999</offsets></xref><offsets xml_i="84576" xml_f="84578" txt_i="47493" txt_f="47495">; </offsets><xref rid="bibr45-2041669518755806" ref-type="bibr"><offsets xml_i="84630" xml_f="84663" txt_i="47495" txt_f="47524">Mogg, Millar, &amp; Bradley, 2000</offsets></xref><offsets xml_i="84670" xml_f="84706" txt_i="47524" txt_f="47560">), spend more time on such stimuli (</offsets><xref rid="bibr20-2041669518755806" ref-type="bibr"><offsets xml_i="84758" xml_f="84796" txt_i="47560" txt_f="47594">Fox, Russo, Bowles, &amp; Dutton, 2001</offsets></xref><offsets xml_i="84803" xml_f="84872" txt_i="47594" txt_f="47663">), and have difficulty in shifting their attention away from threat (</offsets><xref rid="bibr25-2041669518755806" ref-type="bibr"><offsets xml_i="84924" xml_f="84947" txt_i="47663" txt_f="47682">Klumpp &amp; Amir, 2009</offsets></xref><offsets xml_i="84954" xml_f="84956" txt_i="47682" txt_f="47684">; </offsets><xref rid="bibr64-2041669518755806" ref-type="bibr"><offsets xml_i="85008" xml_f="85033" txt_i="47684" txt_f="47705">Yiend &amp; Mathews, 2001</offsets></xref><offsets xml_i="85040" xml_f="85067" txt_i="47705" txt_f="47732">). In a recent fMRI study (</offsets><xref rid="bibr23-2041669518755806" ref-type="bibr"><offsets xml_i="85119" xml_f="85134" txt_i="47732" txt_f="47747">Im et al., 2017</offsets></xref><offsets xml_i="85141" xml_f="85193" txt_i="47747" txt_f="47799">), we utilized visual pathway biasing manipulation (</offsets><xref rid="bibr29-2041669518755806" ref-type="bibr"><offsets xml_i="85245" xml_f="85265" txt_i="47799" txt_f="47819">Kveraga et al., 2007</offsets></xref><offsets xml_i="85272" xml_f="85274" txt_i="47819" txt_f="47821">; </offsets><xref rid="bibr60-2041669518755806" ref-type="bibr"><offsets xml_i="85326" xml_f="85345" txt_i="47821" txt_f="47840">Thomas et al., 2012</offsets></xref><offsets xml_i="85352" xml_f="85889" txt_i="47840" txt_f="48377">) and found that trait anxiety differentially affected perception of clear and ambiguous threat cues from faces presented to the magnocellular or parvocellular visual pathways and correlated with amygdala activity in lateralized fashion. The reported abnormalities in threat processing by anxious individuals can be studied further by examining their responses to the different types of negative and threatening images (Deadly Threat, Direct Threat and Indirect Threat) compared to responses to merely negative images (Threat Aftermath).</offsets></p></sec><sec id="sec22-2041669518755806"><title><offsets xml_i="85939" xml_f="85972" txt_i="48379" txt_f="48412">Limitations and Future Directions</offsets></title><p><offsets xml_i="85983" xml_f="87016" txt_i="48413" txt_f="49446">Among the limitations of the study is the use of young adult U.S. student samples. Future work should investigate larger scale samples of young, as well as middle-aged and older adults in order to increase generalizability of the findings reported here. In addition, there is an unbalanced number of images per category in the image set described here. However, the set offers a fairly large pool of images to choose from, and a balanced design among the categories can be accomplished by selecting image subsets. Researchers will be able to select a sample of stimuli corresponding to their design needs from the entire image set, either by using the ratings reported here or by rerating the sample in their own population, with the same or new rating parameters relevant to their research question. Furthermore, even though a reasonably stable relationship has been observed between psychophysiological responses such as heart rate, skin conductance, facial EMG, and the startle reflex as compared to subjective affective ratings (</offsets><xref rid="bibr30-2041669518755806" ref-type="bibr"><offsets xml_i="87068" xml_f="87103" txt_i="49446" txt_f="49477">Lang, Bradley, &amp; Cuthbert, 1990</offsets></xref><offsets xml_i="87110" xml_f="87285" txt_i="49477" txt_f="49652">), it is nevertheless necessary to acquire affective responses to our line-drawing images that go beyond self-reported subjective ratings using psychophysiological reactions (</offsets><xref rid="bibr11-2041669518755806" ref-type="bibr"><offsets xml_i="87337" xml_f="87391" txt_i="49652" txt_f="49702">Cacioppo, Berntson, Larsen, Poehlmann, &amp; Ito, 2000</offsets></xref><offsets xml_i="87398" xml_f="87407" txt_i="49702" txt_f="49711">), fMRI (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="87459" xml_f="87479" txt_i="49711" txt_f="49731">Kveraga et al., 2015</offsets></xref><offsets xml_i="87486" xml_f="87488" txt_i="49731" txt_f="49733">; </offsets><xref rid="bibr46-2041669518755806" ref-type="bibr"><offsets xml_i="87540" xml_f="87562" txt_i="49733" txt_f="49755">Moriguchi et al., 2011</offsets></xref><offsets xml_i="87569" xml_f="87605" txt_i="49755" txt_f="49791">), and magnetoencephalography (MEG: </offsets><xref rid="bibr54-2041669518755806" ref-type="bibr"><offsets xml_i="87657" xml_f="87711" txt_i="49791" txt_f="49841">Panichello, Kveraga, Chaumon, Bar, &amp; Barrett, 2017</offsets></xref><offsets xml_i="87718" xml_f="87800" txt_i="49841" txt_f="49923">). Finally, using IAPS images, cross-cultural studies conducted around the world (</offsets><xref rid="bibr14-2041669518755806" ref-type="bibr"><offsets xml_i="87852" xml_f="87884" txt_i="49923" txt_f="49951">Deak, Csenki, &amp; Revesz, 2010</offsets></xref><offsets xml_i="87891" xml_f="87893" txt_i="49951" txt_f="49953">; </offsets><xref rid="bibr15-2041669518755806" ref-type="bibr"><offsets xml_i="87945" xml_f="87990" txt_i="49953" txt_f="49994">Drace, Efendic, Kusturica, &amp; Landzo, 2013</offsets></xref><offsets xml_i="87997" xml_f="87999" txt_i="49994" txt_f="49996">; </offsets><xref rid="bibr17-2041669518755806" ref-type="bibr"><offsets xml_i="88051" xml_f="88086" txt_i="49996" txt_f="50027">Dufey, Fernandez, &amp; Mayol, 2011</offsets></xref><offsets xml_i="88093" xml_f="88095" txt_i="50027" txt_f="50029">; </offsets><xref rid="bibr33-2041669518755806" ref-type="bibr"><offsets xml_i="88147" xml_f="88183" txt_i="50029" txt_f="50061">Lasaitis, Ribeiro, &amp; Bueno, 2008</offsets></xref><offsets xml_i="88190" xml_f="88192" txt_i="50061" txt_f="50063">; </offsets><xref rid="bibr43-2041669518755806" ref-type="bibr"><offsets xml_i="88244" xml_f="88281" txt_i="50063" txt_f="50096">Lohani, Gupta, &amp; Srinivasan, 2013</offsets></xref><offsets xml_i="88288" xml_f="88498" txt_i="50096" txt_f="50306">) revealed major similarities as well as subtle cultural differences in terms of valence and arousal ratings. Thus, future studies will have to evaluate the cross-cultural validity of the current set of images.</offsets></p><p><offsets xml_i="88505" xml_f="89086" txt_i="50307" txt_f="50888">Future work on the line-drawing image set presented here should investigate the following: (a) larger scale samples of young, middle-aged, and older adults that might reveal age-related differences in processing affectively relevant images in the set; (b) the validity and reliability of the set across clinical populations, such as populations suffering from anxiety disorders; (c) the validity and reliability of the set across cultures; and (d) affective responses to the set that go beyond self-reported subjective ratings, such as heart rate, skin conductance, and facial EMG.</offsets></p></sec></sec><sec sec-type="conclusions" id="sec23-2041669518755806"><title><offsets xml_i="89165" xml_f="89176" txt_i="50891" txt_f="50902">Conclusions</offsets></title><p><offsets xml_i="89187" xml_f="89353" txt_i="50903" txt_f="51069">We have previously demonstrated that young human observers are keenly sensitive to the spatial and temporal directions of threat in color photographic visual scenes (</offsets><xref rid="bibr28-2041669518755806" ref-type="bibr"><offsets xml_i="89405" xml_f="89425" txt_i="51069" txt_f="51089">Kveraga et al., 2015</offsets></xref><offsets xml_i="89432" xml_f="90332" txt_i="51089" txt_f="51989">). Here, we extended our previous work by demonstrating that young human observers are just as sensitive to spatial and temporal directions of threat, even when it is presented as hand-traced line drawings of the same visual scenes. This suggests that, even though line drawings are much more visually impoverished as compared to color photographic images, they nevertheless appear to capture essential features that allow human observers to differentiate the scenes according to their threat value. Because a line-drawing format of an image allows for easier manipulation of the image content, our line-drawing stimulus set offers a multitude of possibilities for future research on threat perception. A more nuanced understanding of threat perception is not only of considerable theoretical interest, but has practical implications for the safety and well-being of healthy and clinical populations.</offsets></p></sec><sec sec-type="supplementary-material" specific-use="figshare"><title><offsets xml_i="90412" xml_f="90433" txt_i="51991" txt_f="52012">Supplemental Material</offsets></title><supplementary-material content-type="local-data" id="suppl1-2041669518755806"><caption><title><offsets xml_i="90536" xml_f="90576" txt_i="52013" txt_f="52053">Supplementary Material table and figures</offsets></title></caption><media xlink:href="Supplemental_material_table_and_figures.pdf"><caption><p><offsets xml_i="90670" xml_f="90706" txt_i="52054" txt_f="52090">Click here for additional data file.</offsets></p></caption></media></supplementary-material></sec></body><back><ack><title>Acknowledgements</title><p>The authors thank Joseph Brandenburg for his help with data collection.</p></ack><sec id="sec24-2041669518755806"><title>Author Note</title><p>This work was presented at the seventeenth annual meeting of Vision Sciences Society (VSS 2017) held in St. Pete Beach, FL, in May 2017. Institutional Review Board exemption was obtained before the beginning of the study.</p></sec><sec id="sec25-2041669518755806"><title>Declaration of Conflicting Interests</title><p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></sec><sec id="sec26-2041669518755806"><title>Funding</title><p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The research reported in this article was supported by an NIH K01-MH84011 award to KK and NIH R01-MH101194 grant to KK and RA.</p></sec><sec><title>Supplementary material</title><p>Supplementary material for this article is available online.</p></sec><notes><title>Notes</title><fn-group><fn id="fn1-2041669518755806"><label>1</label><p>The interrater reliability for each rating group before removing data of eight participants (<italic>n</italic> = 20 each) was .972, .969, and .950 respectively.</p></fn><fn id="fn2-2041669518755806"><label>2</label><p>If an image fitted more than one pattern, the pattern producing a more significant fit was selected.</p></fn><fn id="fn3-2041669518755806"><label>3</label><p>For arousal ratings, one participant’s responses were significantly different from the responses of other participants. Thus, data of this participant were removed from further analysis. Interreliability for arousal ratings before removing these data was .956.</p></fn></fn-group></notes><bio id="d35e2937"><title>Author Biographies</title><p>
<fig id="img1-2041669518755806" orientation="portrait" position="anchor"><graphic xlink:href="10.1177_2041669518755806-img1"></graphic></fig>
</p><p><bold>Jasmine Boshyan</bold></p><p>
<fig id="img2-2041669518755806" orientation="portrait" position="anchor"><graphic xlink:href="10.1177_2041669518755806-img2"></graphic></fig>
</p><p><bold>Lisa Feldman Barrett</bold>, PhD, is University Distinguished Professor of Psychology and Director of the Interdisciplinary Affective Science Laboratory (IASLab) at Northeastern University, with research appointments at Harvard Medical School and Massachusetts General Hospital. Her research focuses on the nature of emotion from both psychological and neuroscience perspectives. In addition to publishing over 200 peer reviewed papers and 50 book chapters, Dr. Barrett has testified before US Congress in support of basic behavioral research funding and has edited five volumes, including the 4th edition of the <italic>Handbook of Emotion</italic>, published by Guilford Press. Her book, <italic>How emotions are made: The secret life of the brain</italic> is published by Houghton Mifflin Harcourt.</p><p>
<fig id="img3-2041669518755806" orientation="portrait" position="anchor"><graphic xlink:href="10.1177_2041669518755806-img3"></graphic></fig>
</p><p><bold>Nicole Betz</bold> is a PhD candidate studying Cognitive Psychology at Northeastern University. Her current research focuses on intuitive theories of concepts ranging from emotions to climate change.</p><p>
<fig id="img4-2041669518755806" orientation="portrait" position="anchor"><graphic xlink:href="10.1177_2041669518755806-img4"></graphic></fig>
</p><p><bold>Reginald B. Adams Jr.</bold> is Associate Professor of psychology at the Pennsylvania State University. Much of his work focuses on the combinatorial nature of social perception. Social cues, such as race, gender, age, appearance, eye gaze, and emotion have largely been studied independent of one another, even isolated within separate fields. His research examines how these social cues combine to form the unified representations that guide our impressions of and responses to others. Most recently he has been working on an NIMH R01 examining the neural dynamics of visual compound threat cue processing.</p><p>
<fig id="img5-2041669518755806" orientation="portrait" position="anchor"><graphic xlink:href="10.1177_2041669518755806-img5"></graphic></fig>
</p><p><bold>Kestutis Kveraga</bold> is an Assistant Professor of Radiology at Harvard Medical School and the Athinoula A. Martinos Center for Biomedical Imaging at the Massachusetts General Hospital. He studies behavioral and neural dynamics underlying threat perception in face and scene images using fMRI, MEG and eye-tracking. He is co-editor of a volume on scene perception, <italic>Scene Vision: Making Sense of What We See.</italic></p></bio><ref-list><title>References</title><ref id="bibr1-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bannerman</surname><given-names>R. L.</given-names></name><name><surname>Milders</surname><given-names>M.</given-names></name><name><surname>de Gelder</surname><given-names>B.</given-names></name><name><surname>Sahraie</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>) <article-title>Orienting to threat: Faster localization of fearful facial expressions and body postures revealed by saccadic eye movements</article-title>. <source>Proceedings of the Royal Society of Sciences: B Biological Sciences</source>
<volume>276</volume>: <fpage>1635</fpage>–<lpage>1641</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2008.1744">http://dx.doi.org/10.1098/rspb.2008.1744</ext-link></comment>.</mixed-citation></ref><ref id="bibr2-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>L. F.</given-names></name></person-group> (<year>2006</year>) <article-title>Valence as a basic building block of emotional life</article-title>. <source>Journal of Research in Personality</source>
<volume>40</volume>: <fpage>35</fpage>–<lpage>55</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jrp.2005.08.006">http://dx.doi.org/10.1016/j.jrp.2005.08.006</ext-link></comment>.</mixed-citation></ref><ref id="bibr3-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>L. F.</given-names></name><name><surname>Bliss-Moreau</surname><given-names>E.</given-names></name></person-group> (<year>2009</year>) <article-title>Affect as a psychological primitive</article-title>. <source>Advances in Experimental Social Psychology</source>
<volume>41</volume>: <fpage>167</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0065-2601">https://doi.org/10.1016/S0065-2601</ext-link>(08)00404-8</comment>.<pub-id pub-id-type="pmid">20552040</pub-id></mixed-citation></ref><ref id="bibr4-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>L. F.</given-names></name><name><surname>Russell</surname><given-names>J. A.</given-names></name></person-group> (<year>1999</year>) <article-title>Structure of current affect</article-title>. <source>Current Directions in Psychological Science</source>
<volume>8</volume>: <fpage>10</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-8721.00003">https://doi.org/10.1111/1467-8721.00003</ext-link></comment>.</mixed-citation></ref><ref id="bibr5-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>D. V.</given-names></name><name><surname>Anderson</surname><given-names>U. S.</given-names></name><name><surname>Mortensen</surname><given-names>C. R.</given-names></name><name><surname>Neufeld</surname><given-names>S. L.</given-names></name><name><surname>Neel</surname><given-names>R.</given-names></name></person-group> (<year>2011</year>) <article-title>The face in the crowd effect unconfounded: Happy faces, not angry faces, are more efficiently detected in single- and multiple-target visual search tasks</article-title>. <source>Journal of Experimental Psychology: General</source>
<volume>140</volume>: <fpage>637</fpage>–<lpage>659</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0024060">https://doi.org/10.1037/a0024060</ext-link></comment>.<pub-id pub-id-type="pmid">21744984</pub-id></mixed-citation></ref><ref id="bibr6-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>D. V.</given-names></name><name><surname>Srinivasan</surname><given-names>N.</given-names></name></person-group> (<year>2014</year>) <article-title>The vividness of the happy face</article-title>. <source>Current Directions in Psychological Science</source>
<volume>23</volume>: <fpage>189</fpage>–<lpage>194</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0963721414533702">https://doi.org/10.1177/0963721414533702</ext-link></comment>.</mixed-citation></ref><ref id="bibr7-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biederman</surname><given-names>I.</given-names></name><name><surname>Ju</surname><given-names>G.</given-names></name></person-group> (<year>1988</year>) <article-title>Surface versus edge-based determinants of visual recognition</article-title>. <source>Cognitive Psychology</source>
<volume>14</volume>: <fpage>143</fpage>–<lpage>177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0010-0285">https://doi.org/10.1016/0010-0285</ext-link>(82)90007-X</comment>.</mixed-citation></ref><ref id="bibr8-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biederman</surname><given-names>I.</given-names></name><name><surname>Mezzanotte</surname><given-names>R. J.</given-names></name><name><surname>Rabinowitz</surname><given-names>J. C.</given-names></name></person-group> (<year>1982</year>) <article-title>Scene perception: Detecting and judging objects undergoing relational violations</article-title>. <source>Cognitive Psychology</source>
<volume>14</volume>: <fpage>143</fpage>–<lpage>177</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0010-0285">https://doi.org/10.1016/0010-0285</ext-link>(82)90007-X</comment>.<pub-id pub-id-type="pmid">7083801</pub-id></mixed-citation></ref><ref id="bibr9-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blanchette</surname><given-names>I.</given-names></name></person-group> (<year>2006</year>) <article-title>Snakes, spiders, guns, and syringes: How specific are evolutionary constraints on the detection of threatening stimuli?</article-title>
<source>The Quarterly Journal of Experimental Psychology</source>
<volume>59</volume>: <fpage>1484</fpage>–<lpage>1504</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/02724980543000204">https://doi.org/10.1080/02724980543000204</ext-link></comment>.<pub-id pub-id-type="pmid">16846972</pub-id></mixed-citation></ref><ref id="bibr10-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brosch</surname><given-names>T.</given-names></name><name><surname>Pourtois</surname><given-names>G.</given-names></name><name><surname>Sander</surname><given-names>D.</given-names></name></person-group> (<year>2010</year>) <article-title>The perception and categorisation of emotional stimuli: A review</article-title>. <source>Cognition and Emotion</source>
<volume>24</volume>: <fpage>377</fpage>–<lpage>400</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/02699930902975754">https://doi.org/10.1080/02699930902975754</ext-link></comment>.</mixed-citation></ref><ref id="bibr11-2041669518755806"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cacioppo</surname><given-names>J. T.</given-names></name><name><surname>Berntson</surname><given-names>G. G.</given-names></name><name><surname>Larsen</surname><given-names>J. T.</given-names></name><name><surname>Poehlmann</surname><given-names>K. M.</given-names></name><name><surname>Ito</surname><given-names>T. A.</given-names></name></person-group> (<year>2000</year>) <article-title>The psychophysiology of emotion</article-title>. In: <person-group person-group-type="editor"><name><surname>Lewis</surname><given-names>M.</given-names></name><name><surname>Haviland-Jones</surname><given-names>J. M.</given-names></name></person-group> (eds) <source>Handbook of emotions</source>, <edition>2nd ed</edition>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>, pp. <fpage>173</fpage>–<lpage>191</lpage>.</mixed-citation></ref><ref id="bibr12-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Correll</surname><given-names>J.</given-names></name><name><surname>Park</surname><given-names>B.</given-names></name><name><surname>Judd</surname><given-names>C. M.</given-names></name><name><surname>Wittenbrink</surname><given-names>B.</given-names></name></person-group> (<year>2002</year>) <article-title>The police officer's dilemma: Using ethnicity to disambiguate potentially threatening individuals</article-title>. <source>Journal of Personality and Social Psychology</source>
<volume>83</volume>: <fpage>1314</fpage>–<lpage>1329</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0022-3514.83.6.1314">https://doi.org/10.1037/0022-3514.83.6.1314</ext-link></comment>.<pub-id pub-id-type="pmid">12500813</pub-id></mixed-citation></ref><ref id="bibr13-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dan-Glauser</surname><given-names>E. S.</given-names></name><name><surname>Scherer</surname><given-names>K. R.</given-names></name></person-group> (<year>2011</year>) <article-title>The Geneva affective picture database (GAPED): A new 730-picture database focusing on valence and normative significance</article-title>. <source>Behavioral Research</source>
<volume>43</volume>: <fpage>468</fpage>–<lpage>477</lpage>.</mixed-citation></ref><ref id="bibr14-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deak</surname><given-names>A.</given-names></name><name><surname>Csenki</surname><given-names>L.</given-names></name><name><surname>Revesz</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>) <article-title>Hungarian ratings for the International Affective Picture System (IAPS): A cross-cultural comparison</article-title>. <source>Empirical Text and Culture Research</source>
<volume>4</volume>: <fpage>90</fpage>–<lpage>101</lpage>.</mixed-citation></ref><ref id="bibr15-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drace</surname><given-names>S.</given-names></name><name><surname>Efendic</surname><given-names>E.</given-names></name><name><surname>Kusturica</surname><given-names>M.</given-names></name><name><surname>Landzo</surname><given-names>L.</given-names></name></person-group> (<year>2013</year>) <article-title>Cross-cultural validation of the “International Affective Picture System” (IAPS) on a sample from Bosnia and Herzegovina</article-title>. <source>Psihologija</source>
<volume>46</volume>: <fpage>17</fpage>–<lpage>26</lpage>.</mixed-citation></ref><ref id="bibr16-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duckworth</surname><given-names>K. L.</given-names></name><name><surname>Bargh</surname><given-names>J. A.</given-names></name><name><surname>Garcia</surname><given-names>M.</given-names></name><name><surname>Chaiken</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>) <article-title>The automatic evaluation of novel stimuli</article-title>. <source>Psychological Science</source>
<volume>13</volume>: <fpage>513</fpage>–<lpage>519</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-9280.00490">https://doi.org/10.1111/1467-9280.00490</ext-link></comment>.<pub-id pub-id-type="pmid">12430834</pub-id></mixed-citation></ref><ref id="bibr17-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dufey</surname><given-names>M.</given-names></name><name><surname>Fernandez</surname><given-names>A. M.</given-names></name><name><surname>Mayol</surname><given-names>R.</given-names></name></person-group> (<year>2011</year>) <article-title>Adding support to cross-cultural emotional assessment: Validation of the International Affective Picture System in a Chilean sample</article-title>. <source>Universitas Psychologica</source>
<volume>10</volume>: <fpage>521</fpage>–<lpage>533</lpage>.</mixed-citation></ref><ref id="bibr18-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eastwood</surname><given-names>J. D.</given-names></name><name><surname>Smilek</surname><given-names>D.</given-names></name><name><surname>Merikle</surname><given-names>P. M.</given-names></name></person-group> (<year>2001</year>) <article-title>Differential attentional guidance by unattended faces expressing positive and negative emotion</article-title>. <source>Perception and Psychophysics</source>
<volume>63</volume>: <fpage>1004</fpage>–<lpage>1013</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03194519">https://doi.org/10.3758/BF03194519</ext-link></comment>.<pub-id pub-id-type="pmid">11578045</pub-id></mixed-citation></ref><ref id="bibr19-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eysenck</surname><given-names>M. W.</given-names></name><name><surname>Derakshan</surname><given-names>N.</given-names></name><name><surname>Santos</surname><given-names>R.</given-names></name><name><surname>Calvo</surname><given-names>M. G.</given-names></name></person-group> (<year>2007</year>) <article-title>Anxiety and cognitive performance: Attentional control theory</article-title>. <source>Emotion</source>
<volume>7</volume>: <fpage>336</fpage>–<lpage>353</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/1528-3542.7.2.336">https://doi.org/10.1037/1528-3542.7.2.336</ext-link></comment>.<pub-id pub-id-type="pmid">17516812</pub-id></mixed-citation></ref><ref id="bibr20-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>E.</given-names></name><name><surname>Russo</surname><given-names>R.</given-names></name><name><surname>Bowles</surname><given-names>R. J.</given-names></name><name><surname>Dutton</surname><given-names>K.</given-names></name></person-group> (<year>2001</year>) <article-title>Do threatening stimuli draw or hold visual attentional in subclinical anxiety?</article-title>
<source>Journal of Experimental Psychology: General</source>
<volume>130</volume>: <fpage>681</fpage>–<lpage>700</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-3445.130.4.681">https://doi.org/10.1037/0096-3445.130.4.681</ext-link></comment>.<pub-id pub-id-type="pmid">11757875</pub-id></mixed-citation></ref><ref id="bibr21-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>C. H.</given-names></name><name><surname>Hansen</surname><given-names>R. D.</given-names></name></person-group> (<year>1988</year>) <article-title>Finding the face in the crowd – An anger superiority effect</article-title>. <source>Journal of Personality and Social Pscyhology</source>
<volume>54</volume>: <fpage>917</fpage>–<lpage>924</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0022-3514.54.6.917">https://doi.org/10.1037/0022-3514.54.6.917</ext-link></comment>.</mixed-citation></ref><ref id="bibr22-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horstmann</surname><given-names>G.</given-names></name></person-group> (<year>2007</year>) <article-title>Preattentive face processing: What do visual search experiments with schematic faces tell us?</article-title>
<source>Visual Cognition</source>
<volume>15</volume>: <fpage>799</fpage>–<lpage>833</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/13506280600892798">https://doi.org/10.1080/13506280600892798</ext-link></comment>.</mixed-citation></ref><ref id="bibr23-2041669518755806"><mixed-citation publication-type="other"><comment>Im, H. Y., Adams R. B. Jr., Boshyan, J., Ward, N., Cushing, C. A., &amp; Kveraga, K. (2017). Observer's anxiety facilitates magnocellular processing of clear facial threat cues, but impairs parvocellular processing of ambiguous facial threat cues. <italic>Scientific Reports</italic>, <italic>7</italic>, 15151. doi: 10.1038/s41598-017-15495-2</comment>.</mixed-citation></ref><ref id="bibr24-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isbell</surname><given-names>L. A.</given-names></name></person-group> (<year>2006</year>) <article-title>Snakes as agents of evolutionary change in primate brains</article-title>. <source>Journal of Human Evolution</source>
<volume>51</volume>: <fpage>1</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jhevol.2005.12.012">https://doi.org/10.1016/j.jhevol.2005.12.012</ext-link></comment>.<pub-id pub-id-type="pmid">16545427</pub-id></mixed-citation></ref><ref id="bibr25-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klumpp</surname><given-names>H.</given-names></name><name><surname>Amir</surname><given-names>N.</given-names></name></person-group> (<year>2009</year>) <article-title>Examination of vigilance and disengagement of threat in social anxiety with a probe detection task</article-title>. <source>Anxiety, Stress, and Coping</source>
<volume>22</volume>: <fpage>283</fpage>–<lpage>296</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/10615800802449602">https://doi.org/10.1080/10615800802449602</ext-link></comment>.</mixed-citation></ref><ref id="bibr26-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurdi</surname><given-names>B.</given-names></name><name><surname>Lozano</surname><given-names>S.</given-names></name><name><surname>Banaji</surname><given-names>M. R.</given-names></name></person-group> (<year>2017</year>) <article-title>Introducing the Open Affective Standardized Image Set (OASIS)</article-title>. <source>Behavior Research Methods</source>
<volume>49</volume>: <fpage>457</fpage>–<lpage>470</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/s13428-016-0715-3">http://dx.doi.org/10.3758/s13428-016-0715-3</ext-link></comment>.<pub-id pub-id-type="pmid">26907748</pub-id></mixed-citation></ref><ref id="bibr27-2041669518755806"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kveraga</surname><given-names>K.</given-names></name></person-group> (<year>2014</year>) <article-title>Threat perception in visual scenes: Dimensions, action and neural dynamics</article-title>. In: <person-group person-group-type="editor"><name><surname>Kveraga</surname><given-names>K.</given-names></name><name><surname>Bar</surname><given-names>M.</given-names></name></person-group> (eds) <source>Scene Vision: Making sense of what we see</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>, pp. <fpage>291</fpage>–<lpage>307</lpage>.</mixed-citation></ref><ref id="bibr28-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kveraga</surname><given-names>K.</given-names></name><name><surname>Boshyan</surname><given-names>J.</given-names></name><name><surname>Adams</surname><given-names>R. B.</given-names></name><name><surname>Mote</surname><given-names>J.</given-names></name><name><surname>Betz</surname><given-names>N.</given-names></name><name><surname>Ward</surname><given-names>N.</given-names></name><name><surname>Barrett</surname><given-names>L. F.</given-names></name></person-group> (<year>2015</year>) <article-title>If it bleeds, it leads: Separating threat from mere negativity</article-title>. <source>Social Cognitive Affective Neuroscience</source>
<volume>10</volume>: <fpage>28</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/scan/nsu007">https://doi.org/10.1093/scan/nsu007</ext-link></comment>.<pub-id pub-id-type="pmid">24493851</pub-id></mixed-citation></ref><ref id="bibr29-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kveraga</surname><given-names>K.</given-names></name><name><surname>Boshyan</surname><given-names>J.</given-names></name><name><surname>Bar</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>) <article-title>Magnocellular projections as the trigger of top-down facilitation in recognition</article-title>. <source>Journal of Neuroscience</source>
<volume>27</volume>: <fpage>13232</fpage>–<lpage>13240</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3481-07.2007">https://doi.org/10.1523/JNEUROSCI.3481-07.2007</ext-link></comment>.<pub-id pub-id-type="pmid">18045917</pub-id></mixed-citation></ref><ref id="bibr30-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>P. J.</given-names></name><name><surname>Bradley</surname><given-names>M. M.</given-names></name><name><surname>Cuthbert</surname><given-names>B. N.</given-names></name></person-group> (<year>1990</year>) <article-title>Emotion, attention, and the startle reflex</article-title>. <source>Psychological Review</source>
<volume>97</volume>: <fpage>377</fpage>–<lpage>395</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.97.3.377">https://doi.org/10.1037/0033-295X.97.3.377</ext-link></comment>.<pub-id pub-id-type="pmid">2200076</pub-id></mixed-citation></ref><ref id="bibr31-2041669518755806"><mixed-citation publication-type="other"><comment>Lang, P. J., Bradley, M. M, &amp; Cuthbert, B. N. (2005). <italic>International affective picture system (IAPS): Affective ratings of pictures and instruction manual.</italic> Technical Report No A-6. University of Florida. Gainesville, FL</comment>.</mixed-citation></ref><ref id="bibr32-2041669518755806"><mixed-citation publication-type="other"><comment>Larsen, R. J., &amp; Diener, E. (1992). Promises and problems with the circumplex model of emotion. In M. S. Clark (Ed.), <italic>Review of personality and social psychology: Emotion</italic> (Vol. 13, pp. 25–59). Newbury Park, CA: Sage</comment>.</mixed-citation></ref><ref id="bibr33-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lasaitis</surname><given-names>C.</given-names></name><name><surname>Ribeiro</surname><given-names>R. L.</given-names></name><name><surname>Bueno</surname><given-names>O. F. A.</given-names></name></person-group> (<year>2008</year>) <article-title>Brazilian norms for the International Affective Picture System (IAPS): Comparison of the affective ratings for new stimuli between Brazilian and North-American subjects</article-title>. <source>Jornal Brasileiro De Psiquiatria</source>
<volume>57</volume>: <fpage>270</fpage>–<lpage>275</lpage>.</mixed-citation></ref><ref id="bibr34-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>Q. V.</given-names></name><name><surname>Isbell</surname><given-names>L. A.</given-names></name><name><surname>Matsumoto</surname><given-names>J.</given-names></name><name><surname>Le</surname><given-names>V. Q.</given-names></name><name><surname>Nishimaru</surname><given-names>H.</given-names></name><name><surname>Hori</surname><given-names>E.</given-names></name><name><surname>Nishijo</surname><given-names>H.</given-names></name></person-group> (<year>2016</year>) <article-title>Snakes elicit earlier, and monkey faces, later, gamma oscillations in macaque pulvinar neurons</article-title>. <source>Scientific Reports</source>
<volume>6</volume>: <fpage>20595</fpage>–<lpage>20604</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/srep20595">https://doi.org/10.1038/srep20595</ext-link></comment>.<pub-id pub-id-type="pmid">26854087</pub-id></mixed-citation></ref><ref id="bibr35-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>Q. V.</given-names></name><name><surname>Isbell</surname><given-names>L. A.</given-names></name><name><surname>Matsumoto</surname><given-names>J.</given-names></name><name><surname>Nguyen</surname><given-names>M.</given-names></name><name><surname>Hori</surname><given-names>E.</given-names></name><name><surname>Maior</surname><given-names>R. S.</given-names></name><name><surname>Nishijo</surname><given-names>H.</given-names></name></person-group> (<year>2013</year>) <article-title>Pulvinar neurons reveal neurobiological evidence of past selection for rapid detection of snakes</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>
<volume>110</volume>: <fpage>19000</fpage>–<lpage>19005</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1312648110">https://doi.org/10.1073/pnas.1312648110</ext-link></comment>.<pub-id pub-id-type="pmid">24167268</pub-id></mixed-citation></ref><ref id="bibr36-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeDoux</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>) <article-title>Rethinking the emotional brain</article-title>. <source>Neuron</source>
<volume>73</volume>: <fpage>653</fpage>–<lpage>676</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.02.004">https://doi.org/10.1016/j.neuron.2012.02.004</ext-link></comment>.<pub-id pub-id-type="pmid">22365542</pub-id></mixed-citation></ref><ref id="bibr37-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name></person-group> (<year>2009</year>) <article-title>More than just a face in the crowd: Detection of emotional facial expressions in young children and adults</article-title>. <source>Developmental Science</source>
<volume>12</volume>: <fpage>305</fpage>–<lpage>313</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-7687.2008.00767.x">https://doi.org/10.1111/j.1467-7687.2008.00767.x</ext-link></comment>.<pub-id pub-id-type="pmid">19143803</pub-id></mixed-citation></ref><ref id="bibr38-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name></person-group> (<year>2010</year>a) <article-title>And along came a spider: Superior detection of spiders in children and adults</article-title>. <source>Journal of Experimental Child Psychology</source>
<volume>107</volume>: <fpage>59</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jecp.2010.04.005">https://doi.org/10.1016/j.jecp.2010.04.005</ext-link></comment>.<pub-id pub-id-type="pmid">20529694</pub-id></mixed-citation></ref><ref id="bibr39-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name></person-group> (<year>2010</year>b) <article-title>What's so scary about needles and knives? Examining the role of experience in threat detection</article-title>. <source>Cognition and Emotion</source>
<volume>24</volume>: <fpage>80</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/02699930802542308">https://doi.org/10.1080/02699930802542308</ext-link></comment>.</mixed-citation></ref><ref id="bibr40-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name><name><surname>DeLoache</surname><given-names>J. S.</given-names></name></person-group> (<year>2008</year>) <article-title>Detectiong the snake in the grass: Attention to ffear-relevant stimuli by adults and young children</article-title>. <source>Psychological Science</source>
<volume>19</volume>: <fpage>284</fpage>–<lpage>289</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2008.02081.x">https://doi.org/10.1111/j.1467-9280.2008.02081.x</ext-link></comment>.<pub-id pub-id-type="pmid">18315802</pub-id></mixed-citation></ref><ref id="bibr41-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name><name><surname>DeLoache</surname><given-names>J. S.</given-names></name></person-group> (<year>2010</year>) <article-title>Superior detection of threat-relevant stimuli in infancy</article-title>. <source>Developmental Science</source>
<volume>13</volume>: <fpage>221</fpage>–<lpage>228</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-7687.2009.00872.x">https://doi.org/10.1111/j.1467-7687.2009.00872.x</ext-link></comment>.<pub-id pub-id-type="pmid">20121878</pub-id></mixed-citation></ref><ref id="bibr42-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LoBue</surname><given-names>V.</given-names></name><name><surname>Rakison</surname><given-names>D. H.</given-names></name><name><surname>DeLoache</surname><given-names>J. S.</given-names></name></person-group> (<year>2010</year>) <article-title>Threat perception across the life span: Evidence for multiple converging pathways</article-title>. <source>Current Directions in Psychological Science</source>
<volume>19</volume>: <fpage>375</fpage>–<lpage>379</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0963721410388801">https://doi.org/10.1177/0963721410388801</ext-link></comment>.</mixed-citation></ref><ref id="bibr43-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohani</surname><given-names>M.</given-names></name><name><surname>Gupta</surname><given-names>R.</given-names></name><name><surname>Srinivasan</surname><given-names>N.</given-names></name></person-group> (<year>2013</year>) <article-title>Cross-culturalevaluation of the International Affective Picture System on an Indian sample</article-title>. <source>Psychological Studies</source>
<volume>58</volume>: <fpage>233</fpage>–<lpage>241</lpage>.</mixed-citation></ref><ref id="bibr44-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mogg</surname><given-names>K.</given-names></name><name><surname>Bradley</surname><given-names>B. P.</given-names></name></person-group> (<year>1999</year>) <article-title>Orienting of attention to threatening facial expressions presented under conditions of restricted awarness</article-title>. <source>Cognition and Emotion</source>
<volume>13</volume>: <fpage>713</fpage>–<lpage>740</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/026999399379050">https://doi.org/10.1080/026999399379050</ext-link></comment>.</mixed-citation></ref><ref id="bibr45-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mogg</surname><given-names>K.</given-names></name><name><surname>Millar</surname><given-names>N.</given-names></name><name><surname>Bradley</surname><given-names>B. P.</given-names></name></person-group> (<year>2000</year>) <article-title>Biases in eye movements to threatening facial expressions in feneralized anxiety disorder and depressive disorder</article-title>. <source>Journal of Abnormal Psychology</source>
<volume>109</volume>: <fpage>695</fpage>–<lpage>704</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0021-843X.109.4.695">https://doi.org/10.1037/0021-843X.109.4.695</ext-link></comment>.<pub-id pub-id-type="pmid">11195993</pub-id></mixed-citation></ref><ref id="bibr46-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moriguchi</surname><given-names>Y.</given-names></name><name><surname>Negreira</surname><given-names>A.</given-names></name><name><surname>Weierich</surname><given-names>M.</given-names></name><name><surname>Dautoff</surname><given-names>R.</given-names></name><name><surname>Dickerson</surname><given-names>B. C.</given-names></name><name><surname>Wright</surname><given-names>C. I.</given-names></name><name><surname>Barrett</surname><given-names>L. F.</given-names></name></person-group> (<year>2011</year>) <article-title>Differential hemodynamic response in affective circuitry with aging: An fMRI study of novelty, valence, and arousal</article-title>. <source>Journal of Cognitive Neuroscience</source>
<volume>23</volume>: <fpage>1027</fpage>–<lpage>1041</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2010.21527">https://doi.org/10.1162/jocn.2010.21527</ext-link></comment>.<pub-id pub-id-type="pmid">20521849</pub-id></mixed-citation></ref><ref id="bibr47-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>New</surname><given-names>J.</given-names></name><name><surname>Cosmides</surname><given-names>L.</given-names></name><name><surname>Tooby</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>) <article-title>Category-specific attention for animals reflects ancestral priorities, not expertise</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>
<volume>104</volume>: <fpage>16598</fpage>–<lpage>16603</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0703913104">https://doi.org/10.1073/pnas.0703913104</ext-link></comment>.<pub-id pub-id-type="pmid">17909181</pub-id></mixed-citation></ref><ref id="bibr48-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nummenmaa</surname><given-names>L.</given-names></name><name><surname>Hyona</surname><given-names>J.</given-names></name><name><surname>Calvo</surname><given-names>M. G.</given-names></name></person-group> (<year>2009</year>) <article-title>Emotional scene content drives the saccade generation system reflecively</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>
<volume>35</volume>: <fpage>305</fpage>–<lpage>323</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0013626">https://doi.org/10.1037/a0013626</ext-link></comment>.<pub-id pub-id-type="pmid">19331490</pub-id></mixed-citation></ref><ref id="bibr49-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Öhman</surname><given-names>A.</given-names></name><name><surname>Flykt</surname><given-names>A.</given-names></name><name><surname>Esteves</surname><given-names>F.</given-names></name></person-group> (<year>2001</year>) <article-title>Emotion drives attention: Detecting the snake in the grass</article-title>. <source>Journal of Experimental Psychology: General</source>
<volume>130</volume>: <fpage>466</fpage>–<lpage>478</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-3445.130.3.466">https://doi.org/10.1037/0096-3445.130.3.466</ext-link></comment>.<pub-id pub-id-type="pmid">11561921</pub-id></mixed-citation></ref><ref id="bibr50-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Öhman</surname><given-names>A.</given-names></name><name><surname>Mineka</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>) <article-title>Fears, phobias, and preparedness: Toward an evolved module of fear and fear learning</article-title>. <source>Psychological Review</source>
<volume>108</volume>: <fpage>483</fpage>–<lpage>522</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-295X.108.3.483">https://doi.org/10.1037/0033-295X.108.3.483</ext-link></comment>.<pub-id pub-id-type="pmid">11488376</pub-id></mixed-citation></ref><ref id="bibr51-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Öhman</surname><given-names>A.</given-names></name><name><surname>Soares</surname><given-names>S. C.</given-names></name><name><surname>Juth</surname><given-names>P.</given-names></name><name><surname>Lindström</surname><given-names>B. R.</given-names></name><name><surname>Esteves</surname><given-names>F.</given-names></name></person-group> (<year>2012</year>) <article-title>Evolutionary derived modulations of attention to two common fear stimuli: Serpents and hostile humans</article-title>. <source>Journal of Cognitive Psychology</source>
<volume>24</volume>: <fpage>17</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/20445911.2011.629603">https://doi.org/10.1080/20445911.2011.629603</ext-link></comment>.</mixed-citation></ref><ref id="bibr52-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oosterwijk</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>) <article-title>Choosing the negative: A behavioral demonstration of morbid curiosity</article-title>. <source>PLoS One</source>
<volume>12</volume>: <fpage>e0178399</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0178399">https://doi.org/10.1371/journal.pone.0178399</ext-link></comment>.<pub-id pub-id-type="pmid">28683147</pub-id></mixed-citation></ref><ref id="bibr53-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>S. E.</given-names></name></person-group> (<year>1975</year>) <article-title>The effectsof contextual scenes on the identification of objects</article-title>. <source>Memory &amp; Cognition</source>
<volume>3</volume>: <fpage>519</fpage>–<lpage>526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03197524">https://doi.org/10.3758/BF03197524</ext-link></comment>.<pub-id pub-id-type="pmid">24203874</pub-id></mixed-citation></ref><ref id="bibr54-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panichello</surname><given-names>M. T.</given-names></name><name><surname>Kveraga</surname><given-names>K.</given-names></name><name><surname>Chaumon</surname><given-names>M.</given-names></name><name><surname>Bar</surname><given-names>M.</given-names></name><name><surname>Barrett</surname><given-names>L. F.</given-names></name></person-group> (<year>2017</year>) <article-title>Internal valence modulates the speed of object recognition</article-title>. <source>Scientific Reports</source>. <comment>Advance online publication. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-017-00385-4">https://doi.org/10.1038/s41598-017-00385-4</ext-link></comment>.</mixed-citation></ref><ref id="bibr55-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name></person-group> (<year>1993</year>) <article-title>Methods for dealing with reaction time outliers</article-title>. <source>Psychological Bulletin</source>
<volume>114</volume>: <fpage>510</fpage>–<lpage>532</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.114.3.510">https://doi.org/10.1037/0033-2909.114.3.510</ext-link></comment>.<pub-id pub-id-type="pmid">8272468</pub-id></mixed-citation></ref><ref id="bibr56-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>J. A.</given-names></name></person-group> (<year>1980</year>) <article-title>A circumplex model of affect</article-title>. <source>Journal of Personality and Social Pscyhology</source>
<volume>39</volume>: <fpage>1161</fpage>–<lpage>1178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0077714">https://doi.org/10.1037/h0077714</ext-link></comment>.</mixed-citation></ref><ref id="bibr57-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schupp</surname><given-names>H. T.</given-names></name><name><surname>Öhman</surname><given-names>A.</given-names></name><name><surname>Junghofer</surname><given-names>M.</given-names></name><name><surname>Weike</surname><given-names>A. I.</given-names></name><name><surname>Stockburger</surname><given-names>J.</given-names></name><name><surname>Hamm</surname><given-names>A. O.</given-names></name></person-group> (<year>2004</year>) <article-title>The facilitated processing of threatening faces: An ERP analysis</article-title>. <source>Emotion</source>
<volume>4</volume>: <fpage>189</fpage>–<lpage>200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/1528-3542.4.2.189">https://doi.org/10.1037/1528-3542.4.2.189</ext-link></comment>.<pub-id pub-id-type="pmid">15222855</pub-id></mixed-citation></ref><ref id="bibr58-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seligman</surname><given-names>M. E.</given-names></name></person-group> (<year>1971</year>) <article-title>Phobias and preparedness</article-title>. <source>Behavior Therapy</source>
<volume>2</volume>: <fpage>307</fpage>–<lpage>320</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0005-7894">https://doi.org/10.1016/S0005-7894</ext-link>(71)80064-3</comment>.</mixed-citation></ref><ref id="bibr59-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodgrass</surname><given-names>J. G.</given-names></name><name><surname>Vanderwart</surname><given-names>M.</given-names></name></person-group> (<year>1980</year>) <article-title>A standardized set of 260 pictures: Norms for name agreement, image agreement, familiarity, and visual complexity</article-title>. <source>Journal of Experimental Psychology: Human Learning and Memory</source>
<volume>6</volume>: <fpage>174</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.6.2.174">https://doi.org/10.1037/0278-7393.6.2.174</ext-link></comment>.<pub-id pub-id-type="pmid">7373248</pub-id></mixed-citation></ref><ref id="bibr60-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>C.</given-names></name><name><surname>Kveraga</surname><given-names>K.</given-names></name><name><surname>Huberle</surname><given-names>E.</given-names></name><name><surname>Karnath</surname><given-names>H.-O.</given-names></name><name><surname>Bar</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>) <article-title>Enabling global processing in simultanagnosia by psychophysical biasing of visual pathways</article-title>. <source>Brain</source>
<volume>135</volume>: <fpage>1578</fpage>–<lpage>1585</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/brain/aws066">https://doi.org/10.1093/brain/aws066</ext-link></comment>.<pub-id pub-id-type="pmid">22418740</pub-id></mixed-citation></ref><ref id="bibr61-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tipples</surname><given-names>J.</given-names></name><name><surname>Atkinson</surname><given-names>A. P.</given-names></name><name><surname>Young</surname><given-names>A. W.</given-names></name></person-group> (<year>2002</year>) <article-title>The eyebrow frown: A salient social signal</article-title>. <source>Emotion</source>
<volume>2</volume>: <fpage>288</fpage>–<lpage>296</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/1528-3542.2.3.288">https://doi.org/10.1037/1528-3542.2.3.288</ext-link></comment>.<pub-id pub-id-type="pmid">12899361</pub-id></mixed-citation></ref><ref id="bibr62-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walther</surname><given-names>D. B.</given-names></name><name><surname>Chai</surname><given-names>B.</given-names></name><name><surname>Caddigan</surname><given-names>E.</given-names></name><name><surname>Beck</surname><given-names>D. M.</given-names></name><name><surname>Li</surname><given-names>F.-F.</given-names></name></person-group> (<year>2011</year>) <article-title>Simple line drawings suffice for functional MRI decoding of natural scene categories</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>
<volume>108</volume>: <fpage>9661</fpage>–<lpage>9666</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1015666108">https://doi.org/10.1073/pnas.1015666108</ext-link></comment>.<pub-id pub-id-type="pmid">21593417</pub-id></mixed-citation></ref><ref id="bibr63-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>D.</given-names></name><name><surname>Tellegen</surname><given-names>A.</given-names></name></person-group> (<year>1985</year>) <article-title>Toward a consensual structure of mood</article-title>. <source>Psychological Bulletin</source>
<volume>98</volume>: <fpage>219</fpage>–<lpage>223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0033-2909.98.2.219">https://doi.org/10.1037/0033-2909.98.2.219</ext-link></comment>.<pub-id pub-id-type="pmid">3901060</pub-id></mixed-citation></ref><ref id="bibr64-2041669518755806"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yiend</surname><given-names>J.</given-names></name><name><surname>Mathews</surname><given-names>A.</given-names></name></person-group> (<year>2001</year>) <article-title>Anxiety and attention to threatening pictures</article-title>. <source>Quarterly Journal of Experimental Psychology: A Human Experimental Psychology</source>
<volume>54</volume>: <fpage>665</fpage>–<lpage>681</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/713755991">https://doi.org/10.1080/713755991</ext-link></comment>.<pub-id pub-id-type="pmid">11548029</pub-id></mixed-citation></ref></ref-list></back></article>